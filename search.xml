<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>条件概率</title>
      <link href="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87/"/>
      <url>/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>这边文章中我们给出期末复习第七章的内容，主要就是马尔科夫过程。 <a id="more"></a></p><h1 id="常见定义">常见定义</h1><table><colgroup><col style="width: 11%"><col style="width: 30%"><col style="width: 58%"></colgroup><thead><tr class="header"><th style="text-align: center;">基本概念</th><th style="text-align: center;">定义公式</th><th style="text-align: center;">注意事项</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">条件期望</td><td style="text-align: center;"><span class="math inline">\(EX|Y=\sum_x XP(X|Y)\)</span></td><td style="text-align: center;">条件期望是Y的函数，仍然是一个随机变量，服从随机变量函数的性质</td></tr><tr class="even"><td style="text-align: center;">条件概率</td><td style="text-align: center;"><span class="math inline">\(P(A|B)=\frac{P(A,B)}{P(B)}\)</span></td><td style="text-align: center;"><span class="math inline">\(P(A,B)\)</span>代表两个随机事件同时发生。而<span class="math inline">\(P(A|B)\)</span>是在已知某个事件已经发生的条件下，另外一个事件发生的概率。那么如果毫不相关的事件发生了，一定不会对当前事件发生的概率产生任何影响。</td></tr><tr class="odd"><td style="text-align: center;">条件乘法公式</td><td style="text-align: center;"><span class="math inline">\(P(AC|B)=P(A|CB)P(C|B)\)</span></td><td style="text-align: center;">把<span class="math inline">\(B\)</span>去掉就是经典的乘法公式</td></tr><tr class="even"><td style="text-align: center;">条件独立</td><td style="text-align: center;"><span class="math inline">\(P(A|CB)=P(A|B)\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">全期望公式</td><td style="text-align: center;"><span class="math inline">\(EEX|Y=EX\)</span></td><td style="text-align: center;">期望公式算期望</td></tr><tr class="even"><td style="text-align: center;">全概率公式</td><td style="text-align: center;"><span class="math inline">\(\sum_{B_i}^{U} P(A|B_i)P(B_i)\)</span></td><td style="text-align: center;">概率公式算概率</td></tr><tr class="odd"><td style="text-align: center;">均方估值</td><td style="text-align: center;"><span class="math inline">\(g(X)=EY|X\)</span></td><td style="text-align: center;">其中<span class="math inline">\(g(X)\)</span> 代表对未知序列Y的在均方意义意义下的最优估计。<span class="math inline">\(E Y \mid X\)</span> 是 <span class="math inline">\(Y\)</span> 的最佳均方估计, 称为 <span class="math inline">\(Y\)</span> 关于 <span class="math inline">\(X\)</span> 的回归。 用 <span class="math inline">\(E Y \mid X\)</span> 预测 <span class="math inline">\(Y\)</span> 可使均方误差最小</td></tr></tbody></table><h1 id="常见结论">常见结论</h1><table><thead><tr class="header"><th style="text-align: center;">结论</th><th style="text-align: center;">公式</th><th style="text-align: center;">解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">常数的条件期望</td><td style="text-align: center;"><span class="math inline">\(E(C|X)=C\)</span></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">条件的条件期望</td><td style="text-align: center;"><span class="math inline">\(E(X|X)=X\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">条件确定函数的条件期望</td><td style="text-align: center;"><span class="math inline">\(E(g(X)|X)=g(X)\)</span></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">条件期望线性性质</td><td style="text-align: center;"><span class="math inline">\(E(C_1X_1+C_2X_2|Y)=C_1E(X_1|Y)+C_2E(X_2|Y)\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">条件期望的常数性</td><td style="text-align: center;"><span class="math inline">\(E(g(X)f(Y)|X)=g(X)E[f(Y)|X]\)</span></td><td style="text-align: center;">条件期望的核心在于把条件看成常数</td></tr></tbody></table><h2 id="离散全期望公式证明">离散全期望公式证明</h2><p><span class="math display">\[\begin{aligned}E X &amp;=\sum_{i} x_{i} \operatorname{Pr}\left(X=x_{i}\right)=\sum_{i} x_{i} \sum_{j} \operatorname{Pr}\left(X=x_{i} \mid Y=y_{j}\right) \operatorname{Pr}\left(Y=y_{j}\right) \\&amp;=\sum_{j} \operatorname{Pr}\left(Y=y_{j}\right) \cdot \sum_{i} x_{i} \operatorname{Pr}\left(X=x_{i} \mid Y=y_{j}\right) \\&amp;=\sum_{j} \operatorname{Pr}\left(Y=y_{j}\right) E\left(X \mid Y=y_{j}\right)=E E(X \mid Y) \quad \text { 全期望公式 }\end{aligned}\]</span></p><ul><li>核心在于使用全概率公式计算即可。</li></ul><h2 id="连续全期望公式证明">连续全期望公式证明</h2><p><span class="math display">\[\begin{aligned}E(X \mid Y=y) &amp;=\int_{\mathbb{R}} x d F(X \mid Y=y)=\int_{\mathbb{R}} x f(x \mid y) d x \\E E X \mid Y &amp;=\int_{\mathbb{R}} \int_{\mathbb{R}} x f(x \mid y) d x d F_{Y}(y)=\int_{\mathbb{R}} \int_{\mathbb{R}} x f(x \mid y) f_{Y}(y) d x d y \\&amp;=\int_{\mathbb{R}} \int_{\mathbb{R}} x f(x, y) d x d y=\int_{\mathbb{R}} x f_{X}(x) d x=E X\end{aligned}\]</span></p><h2 id="多元连续全期望公式证明">多元连续全期望公式证明</h2><p><span class="math display">\[E(X|Y_1,Y_2)=\int xdF(X|Y_1,Y_2)\\= \int  x f_{x|y_1,y_2}dx\\EEX|Y_1,Y_2 = \int \int \int x f_{y_1,y_2}f_{x|y_1,y_2}dxdy_1dy_2\\= \int x \int \int f_{y_1,y_2} f_{x|y_1,y_2}dy_1dy_2 dx\\= \int x \int \int f_{x,y_1,y_2}dy_1dy_2dx\\= \int x f_x dx\\= EX\]</span></p><h2 id="一元均方估值证明">一元均方估值证明</h2><blockquote><p><span class="math inline">\(\text { 定理: } E|Y-g(X)|^{2} \geq E|Y-E(Y \mid X)|^{2} \text { i.e. } g^{*}(X)=E Y \mid X\)</span></p></blockquote><p>证: 由于 <span class="math inline">\(E Y \mid X\)</span> 是 <span class="math inline">\(X\)</span> 的函数, 故可令 <span class="math inline">\(E(Y \mid X) \triangleq \hat{g}(x)\)</span> <span class="math inline">\(E|Y-g(X)|^{2}=E|Y-\hat{g}(X)+\hat{g}(X)-g(X)|^{2}\)</span> <span class="math inline">\(=E \mid \underline{Y-\left.\hat{g}(X)\right|^{2}}+E(Y-\hat{g}(X)) \frac{\bar{g}(X)-g(X)}{(\hat{g}(X)-g(X))}\)</span> <span class="math inline">\(+E \overline{(Y-\hat{g}(X))}(\hat{g}(X)-g(X))+E|\hat{g}(X)-g(X)|^{2}\)</span> <span class="math inline">\(\geq E|Y-\hat{g}(X)|^{2}\)</span> 等号在 <span class="math inline">\(E|\hat{g}(X)-g(X)|^{2}=0\)</span> 时成立 <span class="math inline">\(\Leftrightarrow g(X)=E Y \mid X\)</span>, a.e.</p><p>核心在于如下的公式，也就是将目标带入就好了。</p><p>使用全期望公式 <span class="math display">\[\begin{aligned}&amp; E(Y-\hat{g}(X)) \cdot(\overline{\hat{g}(X)-g(X)}) \\=&amp;{ }^{3} E\{E[Y-\hat{g}(X)][\overline{\hat{g}(X)-g(X)}] \mid X\} \\=&amp; E\{[\overline{\hat{g}(X)-g(X)}] E[Y-\hat{g}(X)] \mid X\} \\=&amp; E\{[\overline{\hat{g}(X)-g(X)}][E Y|X-E \hat{g}(X)| X]\} \\=&amp; 0 \quad \text { 其中 } E Y \mid X=\hat{g}(X) \quad \text { 且 } E \hat{g}(X) \mid X=\hat{g}(X)\end{aligned}\]</span></p><h2 id="多元均方估值证明">多元均方估值证明</h2><blockquote><p><span class="math inline">\(\text { 定理（推广）: } Y^{*}=g^{*}\left(X_{n}, \cdots X_{1}\right)=E Y \mid X_{n}, \cdots X_{1}\)</span></p></blockquote><p><span class="math display">\[\begin{aligned}&amp; E|Y-g(X_{1},..,X_{n})|^{2}=E|Y-\hat{g}(X_{1},..,X_{n})+\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n})|^{2} \\=&amp; E|Y-\hat{g}(X_{1},..,X_{n})|^{2}+E(Y-\hat{g}(X_{1},..,X_{n}))\overline{(\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n}))} \\&amp;+E\overline{(Y-\hat{g}(X_{1},..,X_{n}))}(\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n}))+E|\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n})|^{2} \\\geq &amp; E|Y-\hat{g}(X_{1},..,X_{n})|^{2}\end{aligned}\]</span></p><p>其中我们有 <span class="math display">\[\begin{aligned}&amp; E(Y-\hat{g}(X_{1},..,X_{n})) \cdot(\overline{\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n}))} \\=&amp; E\{E[Y-\hat{g}(X_{1},..,X_{n})][\overline{\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n})}] \mid X_{1},..,X_{n}\} \\=&amp; E\{[\overline{\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n})}] E[Y-\hat{g}(X_{1},..,X_{n})] \mid X_{1},..,X_{n}\} \\=&amp; E\{\overline{[\hat{g}(X_{1},..,X_{n})-g(X_{1},..,X_{n})]}[E Y|X_{1},..,X_{n}-E \hat{g}(X_{1},..,X_{n})| X_{1},..,X_{n}]\} \\=&amp; 0 \text { 其中 } E Y \mid X=\hat{g}(X_{1},..,X_{n}) \text { 且 } E \hat{g}(X_{1},..,X_{n}) \mid X_{1},..,X_{n}=\hat{g}(X_{1},..,X_{n})\end{aligned}\]</span> 所以我们可以得到$ Y^{<em>}=g^{</em>}(X_{n}, X_{1})=E Y X_{n}, X_{1}$</p><h1 id="问题">问题</h1><ol type="1"><li>换元之后除了变量长得不一样，还有什么区别吗？变量的定义域变了么？如何确定呢？</li></ol><h1 id="等待解决">等待解决</h1><ol type="1"><li>什么是期望？<ol type="1"><li>普通期望</li><li>条件期望</li></ol></li><li>什么是协方差矩阵？<ol type="1"><li>自协方差</li><li>互协方差</li></ol></li><li>什么是相关函数？<ol type="1"><li>自相关函数</li><li>互相关函数</li></ol></li><li>什么是方差？<ol type="1"><li>普通方差</li><li>条件方差</li></ol></li><li>什么是概率？<ol type="1"><li>普通概率</li><li>条件概率</li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> 清华课程 </category>
          
          <category> 随机随机过程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 清华课程 </tag>
            
            <tag> 随机过程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见数学符号</title>
      <link href="/blog_cn/2022/01/11/test/%E5%B8%B8%E8%A7%81%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7/"/>
      <url>/blog_cn/2022/01/11/test/%E5%B8%B8%E8%A7%81%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>下面进行一些符号渲染测试</p><p><span class="math display">\[\mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix}\mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\\frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\\frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \\\end{vmatrix}\]</span></p>]]></content>
      
      
      
        <tags>
            
            <tag> 服务器测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马尔科夫过程</title>
      <link href="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E8%BF%87%E7%A8%8B/"/>
      <url>/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>这边文章中我们给出期末复习第七章的内容，主要就是马尔科夫过程。 <a id="more"></a></p><h1 id="状态分类">状态分类</h1><p>马尔科夫链的状态常常可以分为常返、非常返、周期、非周期、正常返、零常返</p><table><colgroup><col style="width: 6%"><col style="width: 31%"><col style="width: 31%"><col style="width: 31%"></colgroup><thead><tr class="header"><th style="text-align: center;">概念名称</th><th style="text-align: center;">基本定义</th><th style="text-align: center;">常用判准</th><th style="text-align: center;">解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">可到达</td><td style="text-align: center;"><span class="math inline">\(i\rightarrow j\doteq 存在 n\ge 1, p_{i,j}^{(n)}&gt;0\)</span></td><td style="text-align: center;">根据转移矩阵<span class="math inline">\(P\)</span>判断是否可到达，另外状态转移图也可</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">联通</td><td style="text-align: center;"><span class="math inline">\(i\rightarrow j,j \rightarrow i\)</span></td><td style="text-align: center;">建议直接画状态转移图，就是联通集，矩阵很难直接看出来。</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;"><strong>常</strong>返状态</td><td style="text-align: center;"><span class="math inline">\(f_{ii}=1\)</span></td><td style="text-align: center;"><span class="math inline">\(\sum_{n=0}^{\infty} p_{ii}^{(n)}=\infty\)</span></td><td style="text-align: center;">常返可以解释为有限时间返回原点的概率为1。</td></tr><tr class="even"><td style="text-align: center;">非常返</td><td style="text-align: center;"><span class="math inline">\(f_{ii}&lt;1\)</span></td><td style="text-align: center;"><span class="math inline">\(\sum_{n=0}^{\infty} p_{ii}^{(n)}= 常数\)</span></td><td style="text-align: center;">有限时间内返回原点的概率小于1</td></tr><tr class="odd"><td style="text-align: center;">周期</td><td style="text-align: center;"><span class="math inline">\(gcd\{d,p_{ii}^{(d)}\ge 0\}\)</span></td><td style="text-align: center;"><span class="math inline">\(p_{ii}^{(1)} =0, 存在 d&gt;1, p_{ii}^{(d)}&gt;0\)</span></td><td style="text-align: center;">简单来说能一步自回归的状态为非周期，其余为周期。当然特别的如果回不来，周期就是无穷；周期为d代表着n足够大的时候<span class="math inline">\(p^{nd}_{ii}&gt;0\)</span></td></tr><tr class="even"><td style="text-align: center;">非周期</td><td style="text-align: center;"><span class="math inline">\(gcd\{d,p_{ii}^{(d)}\ge 0\}\)</span></td><td style="text-align: center;"><span class="math inline">\(p_{ii}^{(1)} &gt;0\)</span></td><td style="text-align: center;">一步就能回到自身</td></tr><tr class="odd"><td style="text-align: center;">正常返</td><td style="text-align: center;"><span class="math inline">\(E_{f_{ii}}(n)=\sum_{n=1}^{\infty}nf_{ii}^{(n)} =常数\)</span></td><td style="text-align: center;"><span class="math inline">\(\lim_{k-&gt;\infty}p_{ii}^{(dk)}=\frac{d}{\mu}&gt;0\)</span></td><td style="text-align: center;">平均返回时间的期望存在，主要看期望存不存在</td></tr><tr class="even"><td style="text-align: center;">零常返</td><td style="text-align: center;"><span class="math inline">\(E_{f_{ii}}(n)=\sum_{n=1}^{\infty}nf_{ii}^{(n)} =\infty\)</span></td><td style="text-align: center;"><span class="math inline">\(\lim_{k-&gt;\infty}p_{ii}^{(k)}=\frac{d}{\mu}=0\)</span></td><td style="text-align: center;">平均返回时间的期望为无穷，也就是基本回不来</td></tr><tr class="odd"><td style="text-align: center;">遍历态</td><td style="text-align: center;">非周期+正常返</td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">联通状态</td><td style="text-align: center;">状态的性质完全相同。</td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">闭集</td><td style="text-align: center;">集合中所有状态可以构成一条完整的马氏链。（无法转移到链外状态）</td><td style="text-align: center;">一步转移矩阵中剔除闭集以外的状态（行列都剔除），如果仍是一个随机矩阵，那么就是闭集。</td><td style="text-align: center;">特别的，全集一定是一个闭集</td></tr><tr class="even"><td style="text-align: center;">不可约集</td><td style="text-align: center;">集合中所有状态联通</td><td style="text-align: center;">就是判断这个集合是不是全联通的。</td><td style="text-align: center;">不可约最简单地判断方法就是查看这个闭集内部是否存在闭集，如果不可拆分就不可约。否则可约。</td></tr></tbody></table><h1 id="常见概念">常见概念</h1><table><colgroup><col style="width: 13%"><col style="width: 43%"><col style="width: 43%"></colgroup><thead><tr class="header"><th style="text-align: center;">概念名称</th><th style="text-align: center;">计算表达式</th><th style="text-align: center;">解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">状态的集合</td><td style="text-align: center;"><span class="math inline">\(E=\{s_0,s_1,s_2,...\}\)</span></td><td style="text-align: center;">包含全部状态的集合</td></tr><tr class="even"><td style="text-align: center;">转移概率</td><td style="text-align: center;"><span class="math inline">\(p_{ij}(t,t+n)=P(x(t+n)=j|x(t)=i)\overset{齐次}{=}p_{ij}^{(n)}\)</span></td><td style="text-align: center;">通过n步，从状态i转移到状态j，注意左上角不是幂。</td></tr><tr class="odd"><td style="text-align: center;">转移概率矩阵</td><td style="text-align: center;"><span class="math inline">\(P=\{p_{ij}\}, for \quad i,j \in E\)</span></td><td style="text-align: center;">全状态转移矩阵</td></tr><tr class="even"><td style="text-align: center;">首达概率</td><td style="text-align: center;"><span class="math inline">\(f_{ij}^{(n)}=P(x(n)=j,x(n-1)\ne j,...|x(0)=i)\)</span></td><td style="text-align: center;"><span class="math inline">\(f_{ij}^{(0)}=0 \quad if \ i\ne j \ or\ f_{ij}^{(0)}=1\)</span></td></tr><tr class="odd"><td style="text-align: center;">首次返回自身概率</td><td style="text-align: center;"><span class="math inline">\(f_{ii}^{(n)}=P(x(n)=i,x(n-1)\ne j,...|x(0)=i)\)</span></td><td style="text-align: center;"><span class="math inline">\(f_{ii}^{(0)}=1\)</span></td></tr><tr class="even"><td style="text-align: center;">有限时间内返回概率</td><td style="text-align: center;"><span class="math inline">\(f_{ii}=\sum_{n=1}^\infty f_{ii}^{(n)}\)</span></td><td style="text-align: center;">表示有限时间内自返回的概率</td></tr><tr class="odd"><td style="text-align: center;">CK方程</td><td style="text-align: center;"><span class="math inline">\(p_{ij}^{m+n}=\sum_{k}^{E} p_{ik}^{m}p_{kj}^{n}\)</span></td><td style="text-align: center;">简单来说将i到j分为两步完成，先走m步到达某个中间状态，然后再走n步骤达到j。这里中间状态是不确定的，所以需要遍历所有中间状态。</td></tr><tr class="even"><td style="text-align: center;">母函数</td><td style="text-align: center;"><span class="math inline">\(G(s)=\sum_{k=0}^{\infty}p_k s^k=E[s^k]\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">特征函数</td><td style="text-align: center;"><span class="math inline">\(\Phi_{\xi}(w)=E[\exp(jw\xi)]\)</span></td><td style="text-align: center;">注意特征函数通过<strong>傅里叶正变换</strong>得到概率密度函数</td></tr><tr class="even"><td style="text-align: center;">傅里叶正变换</td><td style="text-align: center;"><span class="math inline">\(F(w)=\int f(t)\exp(-jwt)dt\)</span></td><td style="text-align: center;">注意积分变量是t</td></tr><tr class="odd"><td style="text-align: center;">傅里叶逆变换</td><td style="text-align: center;"><span class="math inline">\(f(t)=\int F(w)\exp(jwt)dw\)</span></td><td style="text-align: center;">注意积分变量是w</td></tr><tr class="even"><td style="text-align: center;">平稳分布</td><td style="text-align: center;"><span class="math inline">\(\pi_j=\lim_{n\rightarrow \infty}p_{ij}^{(n)}=\frac{d}{\mu}\)</span></td><td style="text-align: center;">状态的转移概率会趋于稳定，无论从哪个状态出发，转移到指定状态的概率都是一样的。平稳分布/极限分布都不一定存在</td></tr><tr class="odd"><td style="text-align: center;">极限分布</td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">首达时间</td><td style="text-align: center;"><span class="math inline">\(T_{i j} \triangleq \min \left\{n: n \geq 1, \xi_{0}=i, \xi_{n}=j\right\}\)</span></td><td style="text-align: center;">从状态i首次到达状态j的时间</td></tr></tbody></table><h1 id="常见关系">常见关系</h1><table><colgroup><col style="width: 22%"><col style="width: 44%"><col style="width: 33%"></colgroup><thead><tr class="header"><th style="text-align: center;">概念名称</th><th style="text-align: center;">计算表达式</th><th style="text-align: center;">解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">一步转移概率与首达概率级数关系</td><td style="text-align: center;"><span class="math inline">\(P_{ii}(z)=\frac{1}{1-F_{ii}(z)}\)</span></td><td style="text-align: center;"><span class="math inline">\(P_{ii}(z)=\sum_{k=0}^{\infty}p_{ii}^{(k)}z^k\)</span></td></tr><tr class="even"><td style="text-align: center;">一步转移概率-&gt;首达概率</td><td style="text-align: center;"><span class="math inline">\(f_{ij}^{(n)}=\sum_{k\ne j}p_{ik}f_{kj}^{(n-1) }\)</span></td><td style="text-align: center;">这个是按照状态集合定义</td></tr><tr class="odd"><td style="text-align: center;">首达概率-&gt;n步转移概率</td><td style="text-align: center;"><span class="math inline">\(p_{ij}^{(n)}=\sum_{v=1}^{n}f_{ij}^{(v)}p_{jj}^{(n-v)}\ge f_{ij}^{(n)} \le \sum_{v=1}^{n}f_{ij}^{(v)} \le \sum_{v=1}^{\infty}f_{ij}^{(v)} =f_{ij}\)</span></td><td style="text-align: center;">这个是按照转移的时间定义</td></tr><tr class="even"><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr></tbody></table><h2 id="常见推论">常见推论</h2><table><thead><tr class="header"><th style="text-align: center;">推论</th><th style="text-align: center;">解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><strong>有限马氏链</strong>至少有1个状态是常返的。</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;"><strong>有限不可约马氏链</strong>所有状态常返。</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">有限不可约非周期马氏链所有状态遍历。</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;"><strong>正常返闭集</strong>具有唯一的平稳分布</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">不可约遍历链具有唯一的平稳分布，而且平稳分布就是极限分布</td><td style="text-align: center;">通过求解<span class="math inline">\(\pi=P\pi\)</span>就可以求解平稳分布</td></tr><tr class="even"><td style="text-align: center;">马氏链<strong>严平稳等价于初始分布是平稳分布</strong></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;"><strong>有限不可约（非周期）</strong>号氏链存在唯一的平稳分布。</td><td style="text-align: center;"><span class="math inline">\(\pi_{i}=\frac{1}{\mu_{i}}\)</span></td></tr><tr class="even"><td style="text-align: center;">有限状态马氏链的平稳分布一定存在</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">平稳分布唯一存在 <span class="math inline">\(\Leftrightarrow\)</span> 只有一个基本正常返闭集 <span class="math inline">\(C_{+}=C\)</span></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">有限马氏链中不存在零常返状态</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;"></td><td style="text-align: center;"></td></tr></tbody></table><h1 id="常见题型">常见题型</h1><h2 id="计算极限分布平稳分布">计算极限分布/平稳分布</h2><ul><li>首先需要判断极限分布是否存在</li><li>然后需要判断平稳分布是否存在</li><li>再判断平稳分布是否等于极限分布</li><li>最后计算平稳分布得到极限分布</li></ul><h2 id="判断状态类型">判断状态类型</h2><h3 id="常返非常返">常返/非常返</h3><ul><li>对于每一个不可约（联通）集合可以任意选一个点进行分析，所有点性质完全一样。</li><li>对于每一个连通集中所选状态计算n步转移概率<span class="math inline">\(p_{ii}^{(n)},n\ge0,p_{ii}^{(0)}=1\)</span></li><li>如果<span class="math inline">\(\sum_{n=0}^{\infty}p_{ii}^{(n)}\)</span>等于无穷，那么就是常返状态；否则非常返。</li></ul><h3 id="正常返零常返">正常返/零常返</h3><ul><li>如果是常返状态，那么进一步计算<span class="math inline">\(lim_{n \rightarrow \infty}p_{ii}^{(n)}\)</span>。</li><li>如果 <span class="math inline">\(lim_{n \rightarrow \infty}p_{ii}^{(n)}\)</span>等于0，那么就是零常返，表示平均返回时间的期望是无穷。</li><li>如果 <span class="math inline">\(lim_{n \rightarrow \infty}p_{ii}^{(n)}\)</span>大于0为常数，那么就是正常返。 <span class="math inline">\(lim_{n \rightarrow \infty}p_{ii}^{(n)}=\frac{d}{\mu}\)</span></li></ul><h3 id="周期非周期">周期/非周期</h3><ul><li>如果<span class="math inline">\(p_{ii}^{(1)}\)</span>大于0，那么就是非周期。</li><li>否则就是周期函数，当然不可返回自身的时候周期就是无穷。</li></ul><h2 id="计算转移矩阵">计算转移矩阵</h2><ul><li>根据题意得到状态转移图。</li><li>根据状态转移图绘制状态转移矩阵。</li><li>通过行和为1验证计算是否正确。</li></ul><h2 id="判断验证马尔科夫性">判断/验证马尔科夫性</h2><ul><li><p>马尔科夫性决定了马尔科夫过程的任意维分布函数由状态转移概率和初始状态分布完全定义 <span class="math display">\[f(x_n,x_{n-1},...,x_{1})=f(x_n|x_{n-1})f(x_{n-1}|x_{n-2})...f(x_1)\]</span></p></li><li><p>独立增量过程一定是马尔科夫过程。</p></li></ul><h1 id="问题">问题</h1><ol type="1"><li><p>什么时候是条件？什么时候是乘积？</p></li><li><p><span class="math inline">\(\sum_{i=0}^{\infty} p_{ii}=\infty\)</span> 判断常返，那么我们从1开始可以么？0这个点不耽误吧</p></li><li><p><span class="math inline">\(p_{ii}\)</span>和<span class="math inline">\(f_{ii}\)</span>啥时候会成为概率分布呀？</p></li><li><p>回不到自身的状态，如何定义周期？</p></li><li><p>如何判断正常返和0常返？</p></li><li><p>不可约集合一定是闭集吗？</p></li><li><p>独立增量过程一定是马尔科夫过程。这个我们可以直接用吗？</p></li><li><p>两个联通的状态真的同时非周期吗？</p><pre class="mermaid">   graph TD;a[s0];b[s1];a--1.0-->bb--0.5-->bb--0.5-->a</pre></li><li><p>平稳分布和极限分布有什么区别？</p></li><li><p>这个题目中第二项怎么得到？</p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E8%BF%87%E7%A8%8B/image-20211224152705477.png" alt="image-20211224152705477"><figcaption aria-hidden="true">image-20211224152705477</figcaption></figure><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E8%BF%87%E7%A8%8B/image-20211224152650016.png" alt="image-20211224152650016"><figcaption aria-hidden="true">image-20211224152650016</figcaption></figure></li><li><p>如何判断正常返？ <span class="math display">\[\pi_0 = \frac{1}{1+ \sum_{k=1}^{\infty}\frac{\Pi_{i=0}^{k-1}\lambda_i}{\Pi_{i=1}^k \mu_i}} &gt; 0=\frac{1}{\mu_0}\\\lambda_i=p_{i,i+1},\mu_i=p_{i,i-1}\]</span></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 清华课程 </category>
          
          <category> 随机随机过程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 清华课程 </tag>
            
            <tag> 随机过程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>泊松过程</title>
      <link href="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/"/>
      <url>/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>这边文章中我们给出期末复习第八章的内容，主要就是泊松过程。 <a id="more"></a></p><h1 id="常见分布">常见分布</h1><table><colgroup><col style="width: 9%"><col style="width: 45%"><col style="width: 45%"></colgroup><thead><tr class="header"><th style="text-align: center;">分布</th><th style="text-align: center;">定义公式</th><th style="text-align: center;">参数解释</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">泊松分布</td><td style="text-align: center;"><span class="math inline">\(f_{N}(x)=\frac{\lambda^k}{k!}\exp(-\lambda)\)</span></td><td style="text-align: center;">其中<span class="math inline">\(\lambda\)</span>是参数，可以看出是瞬时泊松强度，简单来说就是事件发生时候的瞬间强度</td></tr><tr class="even"><td style="text-align: center;"><span class="math inline">\(\Gamma\)</span>分布</td><td style="text-align: center;"><span class="math inline">\(f_{S}(x)=\lambda e^{-\lambda x} \frac{(\lambda x)^{r-1}}{(r-1) !}\)</span></td><td style="text-align: center;">泊松分布发生的事件发生的时间点<span class="math inline">\(S_n\)</span>的分布就是<span class="math inline">\(\Gamma\)</span>分布</td></tr><tr class="odd"><td style="text-align: center;">指数分布</td><td style="text-align: center;"><span class="math inline">\(f_{T}(x)=\lambda\exp(-\lambda x)I_{x\ge0}\)</span></td><td style="text-align: center;">泊松分布事件发生的时间间隔<span class="math inline">\(T_n\)</span>的分布就是指数分布</td></tr></tbody></table><p>简单来说<span class="math inline">\(S_n=\sum_{i=1}^{n}T_i\)</span>而且<span class="math inline">\(P(N(t)\le n)=P(S(n)\ge t)\)</span> 注意泊松分布是时间连续的但是状态离散的，伽马分布是时间连续，状态也是连续的。</p><h1 id="常见概念">常见概念</h1><table style="width:100%;"><colgroup><col style="width: 19%"><col style="width: 40%"><col style="width: 40%"></colgroup><thead><tr class="header"><th style="text-align: center;">基本概念</th><th style="text-align: center;">公式</th><th style="text-align: center;">注意事项</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">事件发生的次数</td><td style="text-align: center;"><span class="math inline">\(N(t)=n\)</span>表示<span class="math inline">\([0,t]\)</span>内发生的事件的次数</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">事件发生的间隔</td><td style="text-align: center;"><span class="math inline">\(T_n=\{s-t|N(s)=n,N(t)=n-1\}\)</span>表示第n-1个事件和第n个事件发生的时间差</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">事件发生的时间点</td><td style="text-align: center;"><span class="math inline">\(S_n=\sum_{i=1}^{n}T_i\)</span> 表示第n个事件发生的时间点，如果齐次的话和起始时间无关</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">泊松过程</td><td style="text-align: center;"><span class="math inline">\(P\{N(t_0+t)-N(t_0)=k\}=\frac{(\lambda t)^k}{k!}\exp(-\lambda t)\)</span></td><td style="text-align: center;">简单来说就是在时间t内发生n次事件的概率服从泊松分布，而且这个和起始的时间点<span class="math inline">\(t_0\)</span>无关，参数<span class="math inline">\(\lambda(t)=\lambda\)</span>就是单位时间内时间发生的平均次数</td></tr><tr class="odd"><td style="text-align: center;">状态转移矩阵</td><td style="text-align: center;"><span class="math inline">\(P(t)={p_{ij}(t)}\)</span></td><td style="text-align: center;">这个是齐次的情况，非齐次一般不考虑，齐次就是状态转移矩阵仅仅受转移时间差的影响</td></tr><tr class="even"><td style="text-align: center;">Q矩阵（微分矩阵；转移率矩阵）</td><td style="text-align: center;"><span class="math inline">\(Q=lim_{t-&gt;0}\frac{P(\Delta t)-I}{\Delta t}\)</span></td><td style="text-align: center;">齐次时Q与时间无关；其实Q就是连续情况下的一步转移矩阵</td></tr><tr class="odd"><td style="text-align: center;">后退方程</td><td style="text-align: center;"><span class="math inline">\(\frac{dP(t)}{dt}=QP(t)\)</span></td><td style="text-align: center;">需要注意使用条件</td></tr><tr class="even"><td style="text-align: center;">前进方程</td><td style="text-align: center;"><span class="math inline">\(\frac{dP(t)}{dt}=P(t)Q\)</span></td><td style="text-align: center;">需要注意使用条件</td></tr><tr class="odd"><td style="text-align: center;">转移概率的极限行为</td><td style="text-align: center;"><span class="math inline">\(\lim_{t-&gt;\infty}P(t)\)</span></td><td style="text-align: center;">简单来说就是转移矩阵的极限是否存在</td></tr><tr class="even"><td style="text-align: center;">瞬时分布的极限（稳态）</td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">CK方程</td><td style="text-align: center;"><span class="math inline">\(p_{ij}^{s+t}=\sum_{k}p_{ik}^{s}p_{kj}^{t}\)</span></td><td style="text-align: center;">更简洁的表达形式是<span class="math inline">\(P(s+t)=P(s)P(t)\)</span></td></tr><tr class="even"><td style="text-align: center;">特征函数</td><td style="text-align: center;"><span class="math inline">\(\Phi_{\xi}(w)=E[\exp(jw\xi)]\)</span></td><td style="text-align: center;">注意特征函数通过<strong>傅里叶正变换</strong>得到概率密度函数</td></tr><tr class="odd"><td style="text-align: center;">独立随机变量之和的分布</td><td style="text-align: center;"><span class="math inline">\(\Phi_{\eta}=E[\exp(\sum_i^njw\xi_i)]=\Pi_i^nE[\exp(jw\xi_i)]\)</span></td><td style="text-align: center;"><span class="math inline">\(\eta=\sum_i^n\xi_i\)</span></td></tr><tr class="even"><td style="text-align: center;">随机变量的期望</td><td style="text-align: center;"><span class="math inline">\(\Phi^{(1)}|_{w=0}=jE[x]\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">随机变量的方差</td><td style="text-align: center;"><span class="math inline">\(\Phi^{(2)}|_{w=0}=-E[x^2]\)</span></td><td style="text-align: center;"><span class="math inline">\(D(x)=E(x^2)-E^2(x)\)</span></td></tr><tr class="even"><td style="text-align: center;">顺序统计量</td><td style="text-align: center;">将随机随机变量按照顺序排序后的联合分布</td><td style="text-align: center;">按照顺序排序后重新取值，肯定和排序前有区别。比如原来是<span class="math inline">\(x_1=1\)</span>但是现在可能是<span class="math inline">\(x_n=1\)</span>。</td></tr><tr class="odd"><td style="text-align: center;">到达时间的条件分布</td><td style="text-align: center;"><span class="math inline">\(f(x1,...,xn)=\frac{n!}{t^n}\)</span></td><td style="text-align: center;">已知[0,t]时时间发生的数量为n，那么这n个事件发生的时间点分布。类似均匀分布</td></tr><tr class="even"><td style="text-align: center;">第n个事件达到时间的条件分布</td><td style="text-align: center;"><span class="math inline">\(f(S_n|N(t)=n)=(\frac{s}{t})^n\)</span></td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">非齐次泊松</td><td style="text-align: center;"><span class="math inline">\(P\{N(t_0+t)-N(t_0)=n\}=\frac{(\int_{t}^{t+t_0} \lambda(t) dt )^k}{k!}\exp[-\int_{t}^{t+t_0} \lambda(t) dt]\)</span></td><td style="text-align: center;">所谓的非齐次泊松就是事件发生的速度<span class="math inline">\(E[N(t)]=m(t)=\int\lambda(t)dt\)</span>不再是一个常数而是一个函数<span class="math inline">\(m(t)\)</span></td></tr><tr class="even"><td style="text-align: center;">保守Q矩阵</td><td style="text-align: center;"><span class="math inline">\(\forall i \in I, \sum_{j \neq i} q_{i j}=-q_{i i}&lt;\infty\)</span></td><td style="text-align: center;">有限状态集中Q必保守；对角线元素非正；非对角线元素非负；每行元素和为0</td></tr><tr class="odd"><td style="text-align: center;">福柯普朗克方程</td><td style="text-align: center;"><span class="math inline">\(\frac{r(t)}{dt}=r(t)Q\)</span></td><td style="text-align: center;">其中<span class="math inline">\(r(t)\)</span>是t时刻状态的概率分布，也就是随机过程的一维分布</td></tr><tr class="even"><td style="text-align: center;">极限分布存在引理</td><td style="text-align: center;"><span class="math inline">\(\begin{aligned} &amp;p_{j}(t) \triangleq \operatorname{Pr}\{\xi(t)=j\} \quad p_{i j}(t)=\operatorname{Pr}\{\xi(s+t)=j \mid \xi(s)=i\} \\ &amp;\text { 极限分布 } \lim _{t \rightarrow \infty} p_{j}(t), \lim _{t \rightarrow \infty} p_{i j}(t) \end{aligned}\)</span></td><td style="text-align: center;">引理： <span class="math inline">\(\lim _{t \rightarrow \infty} p_{j}(t)\)</span> 存在且与初始分布 <span class="math inline">\(p_{j}(0)\)</span> 无关, 当且仅当 <span class="math inline">\(\lim _{t \rightarrow \infty} p_{i j}(t)\)</span> 对任何 <span class="math inline">\(i\)</span> 都存在且相等。</td></tr><tr class="odd"><td style="text-align: center;">马尔科夫定理</td><td style="text-align: center;"></td><td style="text-align: center;">有限状态马氏链，如果所有状态联通，那么所有极限分布存在。</td></tr><tr class="even"><td style="text-align: center;"><strong>极限分布的解</strong></td><td style="text-align: center;"><span class="math inline">\(P \cdot Q=0 \\\sum p_i=1\)</span></td><td style="text-align: center;">根据前进方程<span class="math inline">\(\frac{dP(t)}{dt}=P(t)Q\)</span>，令t趋于无穷可以直接得到。注意还有就是概率分布求和为1这个条件一定要有</td></tr><tr class="odd"><td style="text-align: center;">平均人数<span class="math inline">\(L\)</span></td><td style="text-align: center;"><span class="math inline">\(L=\sum_{k=0}^{\infty}kp_k\)</span></td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">平均排队人数<span class="math inline">\(L_Q\)</span></td><td style="text-align: center;"><span class="math inline">\(L=\sum_{k=s}^{\infty}(k-s)p_k\)</span></td><td style="text-align: center;">这里s代表服务台数量。</td></tr><tr class="odd"><td style="text-align: center;">平均服务时间<span class="math inline">\(W\)</span></td><td style="text-align: center;"><span class="math inline">\(W=\frac{L}{\lambda}\)</span></td><td style="text-align: center;"><span class="math inline">\(\lambda\)</span> 系统中人数增加的速度，倒数为顾客平均到达时间</td></tr><tr class="even"><td style="text-align: center;">平均排队时间<span class="math inline">\(W_Q\)</span></td><td style="text-align: center;"><span class="math inline">\(W_Q=\frac{L_Q}{\lambda}\)</span></td><td style="text-align: center;"></td></tr></tbody></table><h1 id="常见q矩阵分析">常见Q矩阵分析</h1><h2 id="排队过程">排队过程</h2><h3 id="mm1-无穷">M|M|1 无穷</h3><p><span class="math display">\[Q = \begin{pmatrix} -\lambda_0 &amp; \lambda_0 &amp; \cdots\\ \mu_1 &amp; -\mu_1-\lambda_1 &amp; \lambda_1 \end{pmatrix}\]</span></p><p>其中<span class="math inline">\(q_{ii-1}=\frac{d p_{ii-1}}{d t}=\mu_i,q_{ii+1}=\frac{d p_{ii+1}}{d t}=\lambda_j,i\in[1,\infty],j\in[0,\infty]\)</span></p><h1 id="常见题型">常见题型</h1><h2 id="q矩阵计算">Q矩阵计算</h2><h3 id="根据状态转移矩阵计算-目前好像都是这么算">根据状态转移矩阵计算 目前好像都是这么算</h3><ul><li>根据题意得到状态转移矩阵</li><li>根据<span class="math inline">\(Q=lim_{t-&gt;0}\frac{P(\Delta t)-I}{\Delta t}\)</span> 分别计算Q中每一个元素</li><li>采用保守矩阵行和为0，以及对角线非正检验计算结果</li></ul><h2 id="极限分布">极限分布</h2><h2 id="线性齐次生灭过程">线性齐次生灭过程</h2><h3 id="极限分布-1">极限分布</h3><p><span class="math display">\[p_{1}=\frac{\lambda_{0}}{\mu_{1}} p_{0}, \quad \ldots, \quad p_{k}=\frac{\lambda_{0} \cdots \lambda_{k-1}}{\mu_{1} \cdots \mu_{k}} p_{0}\]</span></p><p>由 <span class="math inline">\(\sum_{k \in I} p_{k}=1\)</span> 得 <span class="math display">\[p_{0}=\left(1+\sum_{k=1}^{\infty} \frac{\lambda_{0} \cdots \lambda_{k-1}}{\mu_{1} \cdots \mu_{k}}\right)^{-1}\]</span></p><h3 id="灭绝概率">灭绝概率</h3><p>定理: <span class="math inline">\({ }^{11}\{\xi(t), t \geq 0\}\)</span> 齐次线性生灭过程, <span class="math inline">\(\xi(0)=i\)</span>, 参数 <span class="math inline">\(\lambda, \mu\)</span>. 则: <span class="math display">\[p_{i 0}(t)=\alpha^{i}(t)\]</span> 这里的i是初始状态分布</p><p>其中 <span class="math display">\[\alpha(t)=\frac{\mu-\mu e^{(\lambda-\mu) t}}{\mu-\lambda e^{(\lambda-\mu) t}}\]</span> 注： <span class="math inline">\(\lim _{t \rightarrow \infty} p_{i 0}(t)\)</span> 初始状态为 <span class="math inline">\(i\)</span>, 经过长时间后转移到状态 0 (灭绝) <span class="math inline">\(=\lim _{t \rightarrow \infty} \alpha^{i}(t)=\left\{\begin{array}{ll}1 &amp; \lambda&lt;\mu \\ \left(\frac{\mu}{\lambda}\right)^{i} &amp; \lambda&gt;\mu\end{array} \quad i\right.\)</span> 越大, 灭绝的可能性越小。</p><h1 id="常见结论">常见结论</h1><ul><li>马尔科夫过程的研究基本包含三个部分<ul><li>初始状态</li><li>演化过程</li><li>稳定状态/终态</li></ul></li><li>伯努利分布之和是二项分布</li><li>二项分布的极限是泊松分布</li><li>泊松分布的对偶分布（反函数）是<span class="math inline">\(\Gamma\)</span>分布</li><li><span class="math inline">\(\Gamma\)</span>分布的差是指数分布</li><li>指数分布的参数就是事件发生的速度，期望就是事件发生的间隔事件。</li><li>指数分布的条件分布仍然是同参数的指数分布</li><li><span class="math inline">\(\forall i \in I, t \in T, p_{i i}(t)&gt;0\)</span> 这个给出了同状态转移概率的任意时刻的分布特性</li><li><span class="math inline">\(\text { i.e., 若 } p_{i j}\left(t_{0}\right)&gt;0 \text {, 则 } \forall t&gt;t_{0}, p_{i j}(t)&gt;0\)</span> 一次能达到，那么永远能到达。<span class="math inline">\(t_0\)</span>充分大无法到达，那么永远无法到达</li><li><span class="math inline">\(\lim _{t \rightarrow 0} \frac{p_{i j}(t)}{t}\)</span> 极限存在且有限, <span class="math inline">\(i \neq j\)</span> <span class="math inline">\(\lim _{t \rightarrow 0} \frac{p_{i i}(t)-1}{t}\)</span> 极限存在, 但可能是无限, <span class="math inline">\(i=j\)</span> 这个是用于计算Q矩阵的</li></ul><h2 id="泊松分布的条件分布">泊松分布的条件分布</h2><p>设有一泊松过程 <span class="math inline">\(\{N(t), t \geqslant 0\}\)</span>, 若有两时刻 <span class="math inline">\(s, t\)</span>, 且 <span class="math inline">\(s&lt;t\)</span>, 我们有 <span class="math display">\[P\{N(s)=k / N(t)=n\}=\left(\begin{array}{l}n \\k\end{array}\right)\left(\frac{s}{t}\right){*}\left(1-\frac{s}{t}\right)^{n-k}\]</span></p><h1 id="常见数学方法">常见数学方法</h1><h2 id="二项式定理">二项式定理</h2><p><span class="math display">\[(a+b)^{n}=\sum_{r=0}^{n} C_{n}^{r} a^{n-r} b^{r}\]</span></p><h3 id="概率形式">概率形式</h3><p>对于概率形式我们有 <span class="math display">\[(p+q)^{n}=\sum_{r=0}^{n} C_{n}^{r} p^{n-r} q^{r}\]</span> 对于等概率形式我们有 <span class="math display">\[(\frac{1}{2}+\frac{1}{2})^{n}=\sum_{r=0}^{n} C_{n}^{r} (\frac{1}{2})^{n} =1\]</span> 于是我们可以得到 <span class="math display">\[2^n=\sum_{r=0}^{n} C_{n}^{r}\]</span></p><h3 id="特殊形式-1">特殊形式-1</h3><p><span class="math display">\[(a+1)^{n}=\sum_{r=0}^{n} C_{n}^{r} a^{r} = \sum_{r=0}^{n} C_{n}^{r} a^{n-r}\]</span></p><h2 id="泰勒展开">泰勒展开</h2><p><span class="math display">\[e^x = \sum_{k=0}^\infty \frac{x^k}{k!}\]</span></p><h2 id="等价无穷小近似-算q">等价无穷小近似-算Q</h2><p><span class="math display">\[(1-a\Delta t)^k= 1-ak\Delta t\\e^x = 1+x \\e^{-x}=1-x\]</span></p><h2 id="三角不等式">三角不等式</h2><p><span class="math display">\[\frac{1}{4}[1-cos(2\theta)] \le 1-cos(\theta)\]</span></p><h1 id="证明">证明</h1><h2 id="前进后退方程">前进后退方程</h2><p><span class="math display">\[\begin{aligned}\frac{dP(t)}{dt}&amp;=lim_{t-&gt;0} \frac{P(t+\Delta t)-P(t)}{\Delta t}\\&amp;\overset{CK}{=}lim_{t-&gt;0} \frac{P(t)P(\Delta t)-P(t)}{\Delta t}\\&amp;= lim_{t-&gt;0} \frac{P(\Delta t)-I}{\Delta t}P(t)\\&amp;=QP(t) 后退方程\\&amp;=lim_{t-&gt;0} \frac{P(t)P(\Delta t)-P(t)}{\Delta t}\\&amp;=lim_{t-&gt;0} P(t)\frac{P(\Delta t)-I}{\Delta t}\\&amp;=P(t)Q 前进方程\\\end{aligned}\]</span></p><h1 id="问题">问题</h1><ol type="1"><li><p>如果说每个均匀分布并不是相同的，那么如何证明期望仍然是这个?</p><p>期望是线性的，如果仅仅算期望和，那么不用求联合分布。</p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211225143651138.png" alt="image-20211225143651138"><figcaption aria-hidden="true">image-20211225143651138</figcaption></figure></li><li><p>这个求导为啥没有<span class="math inline">\(F&#39;(s)\)</span>？</p><p>不会考察</p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211225150417017.png" alt="image-20211225150417017"><figcaption aria-hidden="true">image-20211225150417017</figcaption></figure></li><li><p>这里应该是乘法吧？</p><p>乘法，答案错了</p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211225174714974.png" alt="image-20211225174714974"><figcaption aria-hidden="true">image-20211225174714974</figcaption></figure></li><li><p>这是个啥玩意？</p><ul><li>一定要注意存在两个<span class="math inline">\(P(S^1_k \le S^2_1)=[\frac{\lambda_1}{\lambda_1+\lambda_2}]^k\)</span></li></ul><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211225175047279.png" alt="image-20211225175047279"><figcaption aria-hidden="true">image-20211225175047279</figcaption></figure></li><li><p>这个事件为啥等价呀？</p><p>这个肯定等价，记住等号是分布列，也就是常说的最小概率单元。不等号是若干个最小概率单元的求和。</p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211226235355718.png" alt="image-20211226235355718"><figcaption aria-hidden="true">image-20211226235355718</figcaption></figure></li><li><p>如何确定这个积分区域？ x&lt;y</p><ul><li>很正常</li></ul><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211227000021359.png" alt="image-20211227000021359"><figcaption aria-hidden="true">image-20211227000021359</figcaption></figure></li><li><p>这两个<span class="math inline">\(S_n\)</span>是同一个意思吗？我感觉下面那个是排序之后的</p><p>这个是说的第n个，也就是有个前提，必须是第n个。而不能是随便的一个，有顺序的。</p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211227002548610.png" alt="image-20211227002548610"><figcaption aria-hidden="true">image-20211227002548610</figcaption></figure></li><li><p>为什么不考虑这个人服务完毕了？ <span class="math inline">\(p_{01}\)</span></p><p>其实一般不用考虑 <span class="math inline">\((\lambda t + o(t))(1-(1-\exp(-\mu t)))=(\lambda t + o(t))(1-\mu t)\)</span></p><figure><img src="/blog_cn/2022/01/11/%E6%B8%85%E5%8D%8E%E8%AF%BE%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B3%8A%E6%9D%BE%E8%BF%87%E7%A8%8B/image-20211227174333756.png" alt="image-20211227174333756"><figcaption aria-hidden="true">image-20211227174333756</figcaption></figure></li></ol><h1 id="待解决">待解决</h1><ol type="1"><li>错位相减</li><li>等价无穷小</li></ol>]]></content>
      
      
      <categories>
          
          <category> 清华课程 </category>
          
          <category> 随机随机过程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 清华课程 </tag>
            
            <tag> 随机过程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pdf测试</title>
      <link href="/blog_cn/2022/01/10/test/pdf%E6%B5%8B%E8%AF%95/"/>
      <url>/blog_cn/2022/01/10/test/pdf%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>下面进行实验</p><a id="more"></a><div class="pdfobject-container" data-target="AAAI.pdf" data-height="500px"></div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>建站记录</title>
      <link href="/blog_cn/2022/01/10/test/%E5%BB%BA%E7%AB%99%E8%AE%B0%E5%BD%95/"/>
      <url>/blog_cn/2022/01/10/test/%E5%BB%BA%E7%AB%99%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>下面是建站记录 <a id="more"></a></p><ul><li>live-2d看板娘</li><li>升级版 有大坑<ul><li>好了，但没完全好，看看后面能不能解决本地无法加载，线上版本不同步的问题</li><li>巨坑有bug，太坑了，路径上不要加'/'</li></ul></li><li>fancybox 图片放大 有坑<ul><li>https://matlab.xyz/2020/07/22/Hexo%E4%BD%BF%E7%94%A8Fancybox%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</li></ul></li><li>代码复制<ul><li>copy_button</li></ul></li><li>darkmode<ul><li>https://www.techgrow.cn/posts/abf4aee1.html#Next-8-x-%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%E5%8F%AF%E5%88%87%E6%8D%A2%E7%9A%84%E6%9A%97%E9%BB%91%E6%A8%A1%E5%BC%8F</li></ul></li><li>加载进度条</li><li>点击特效<ul><li>不要加/坑死了</li></ul></li><li>pdf 预览<ul><li>主页预览存在问题，文章中并没有问题</li></ul></li><li>公式渲染<ul><li>目前采用panoc方案，但是仍然是存在一定概率渲染成功</li></ul></li></ul><h1 id="常用命令">常用命令</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> hexo n &quot;博客名称&quot;  =&gt; hexo new &quot;博客名称&quot;   #这两个都是创建新文章，前者是简写模式</span><br><span class="line">$ hexo p  =&gt; hexo publish</span><br><span class="line">$ hexo g  =&gt; hexo generate  #生成</span><br><span class="line">$ hexo s  =&gt; hexo server  #启动服务预览</span><br><span class="line">$ hexo d  =&gt; hexo deploy  #部署</span><br><span class="line"></span><br><span class="line">$ hexo server   #Hexo 会监视文件变动并自动更新，无须重启服务器。</span><br><span class="line">$ hexo server -s   #静态模式</span><br><span class="line">$ hexo server -p 5000   #更改端口</span><br><span class="line">$ hexo server -i 192.168.1.1   #自定义IP</span><br><span class="line">$ hexo clean   #清除缓存，网页正常情况下可以忽略此条命令</span><br></pre></td></tr></table></figure><h2 id="本地加载">本地加载</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure><h2 id="服务器部署">服务器部署</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo generate &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="创建新的博文">创建新的博文</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo n 名称</span><br></pre></td></tr></table></figure><p>然后自主分类</p><h2 id="阅读全文">阅读全文</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- more --&gt;</span><br></pre></td></tr></table></figure><h2 id="添加pdf文件">添加pdf文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% pdf AAAI.pdf %&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>FFM模型在推荐系统中应用</title>
      <link href="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/"/>
      <url>/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-cce644791141b0a9ab7b761578117628_1440w.jpg" alt="推荐系统召回四模型之：全能的FM模型"><figcaption aria-hidden="true">推荐系统召回四模型之：全能的FM模型</figcaption></figure><blockquote><ul><li>Valar Morghulis （凡人皆有一死)</li><li>Valar Dohaeris （凡人皆须侍奉</li></ul><p>--权力的游戏</p></blockquote><p>但他并未详细解释硬币的用途和这句话的意思。硬币是用来做何用的呢？读完这篇文章你自会知晓答案。至于这句话，前半句好理解，就是字面意思，后半句比较深奥，我也不太懂，我猜大概跟老子说的“天地不仁，以万物为刍狗”意思有点类似吧。</p><p>其实仔细想想，上面这句话送给我们见到的各式算法模型也蛮适合，某个算法甲在某年某月被某人乙发明出来，我们发明出来它，当然也没有事先征求它个人的意见。这就仿佛，我们每个人，明知道这世间事，十有九苦，不也没有征求孩子们的个人意愿，<strong>他们，也包括我们自己，就这么硬生生地被拉入充斥各色人等的人世间，红尘翻滚，遍尝疾苦，作为补偿，生活也许会回馈些许短暂的欢乐，以让我们继续有动力去面对新的难题。</strong></p><a id="more"></a><p>你再想想，算法模型的诞生不也一样吗？它们出生后，如果人们觉得它有用，那它就安心本分地做好自己的工作，好好地服务你我他，如果哪天冒出更活力四射青春逼人的新模型，你觉得它没什么大用了，不也弃之如敝履吗？我们每个人不也是他人疾苦的来源之一吗？</p><p>正所谓：</p><p>模型皆有一死；</p><p>模型皆须侍奉。</p><p>好像也挺有道理的，你说是吗？</p><p>我们说回主题，这篇文章介绍如何用FFM模型来做推荐系统的统一召回。算是召回模型系列四篇的第二篇，之前在“<a href="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/" title="FM模型在推荐系统中的应用">FM模型在推荐系统中的应用</a>”中，介绍了一些基本知识，以及如何用FM模型做统一召回，又及，FM模型是否可以做一体化的单阶段推荐模型。本文为了能够看起来也独立成篇，所以很多前篇文章的基础知识点，仍然会保留。如果比较熟悉的读者，可以直接跳到“<strong>用FM/FFM模型做召回意味着什么</strong>”部分看起。</p><p>这个召回模型系列文章的缘起，来自于我对下列两个不太符合常规做法的推荐技术问题的思考，下面再次复述一遍：</p><p>第一个问题：我们知道在个性化推荐系统里，第一个环节一般是召回阶段，而召回阶段工业界目前常规的做法是多路召回，每一路召回可能采取一个不同的策略。那么打破常规的思考之一是：<strong>是否我们能够使用一个统一的模型，将多路召回改造成单模型单路召回策略？</strong>如果不能，那是为什么？如果能，怎么做才可以？这样做有什么好处和坏处？</p><p>第二个问题：我们同样知道，目前实用化的工业界的推荐系统通常由两个环节构成，召回阶段和排序阶段，那么为什么要这么划分？它们各自的职责是什么？打破常规的另外一个思考是：<strong>是否存在一个模型，这个模型可以将召回阶段和排序阶段统一起来，就是把两阶段推荐环节改成单模型单环节推荐流程</strong>？就是说靠一个模型一个阶段把传统的两阶段推荐系统做的事情一步到位做完？如果不能，为什么不能？如果能，怎么做才可以？什么样的模型才能担当起这种重任呢？而在现实世界里是否存在这个模型？这个思路真的可行吗?</p><p>本文主要探讨FFM模型是否能够解决上述两个问题。我仍然会先简单介绍下推荐系统整体架构以及多路召回的基本模式，然后说明下FFM模型基本思想，之后探讨FFM模型是否能够解决上面提到的两个非常规问题，如果能，该怎么解决？纯属个人思考，非经验分享，天马行空，谬误难免。</p><hr><h2 id="工业界推荐系统整体架构是怎样的"><strong>工业界推荐系统整体架构是怎样的</strong></h2><figure><img src="https://pic1.zhimg.com/80/v2-979ee06266d5d9b21664219d37a4f164_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>一个典型的工业级推荐系统整体架构可以参考上图，一般分为在线部分，近线部分和离线部分。</p><p>对于在线部分来说，一般要经历几个阶段。首先通过召回环节，将给用户推荐的物品降到千以下规模；如果召回阶段返回的物品还是太多，可以加入粗排阶段，这个阶段是可选的，粗排可以通过一些简单排序模型进一步减少往后续环节传递的物品；再往后是精排阶段，这里可以使用复杂的模型来对少量物品精准排序。对某个用户来说，即使精排推荐结果出来了，一般并不会直接展示给用户，可能还要上一些业务策略，比如去已读，推荐多样化，加入广告等各种业务策略。之后形成最终推荐结果，将结果展示给用户。</p><p>对于近线部分来说，主要目的是实时收集用户行为反馈，并选择训练实例，实时抽取拼接特征，并近乎实时地更新在线推荐模型。这样做的好处是用户的最新兴趣能够近乎实时地体现到推荐结果里。</p><p>对于离线部分而言，通过对线上用户点击日志的存储和清理，整理离线训练数据，并周期性地更新推荐模型。对于超大规模数据和机器学习模型来说，往往需要高效地分布式机器学习平台来对离线训练进行支持。</p><figure><img src="https://pic3.zhimg.com/80/v2-cf5154bab9edd7e83ca9976789a6c423_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>因为粗排是可选的，对于大多数推荐系统来说，通常在线部分的主体分为两个阶段就够，第一个阶段是召回，第二个阶段是排序。因为个性化推荐需要给每个用户展现不同的信息流或者物品流，而对于每个用户来说，可供推荐的物品，在具备一定规模的公司里，是百万到千万级别，甚至上亿。所以对于每一个用户，如果对于千万级别物品都使用先进的模型挨个进行排序打分，明显速度上是算不过来的，资源投入考虑这么做也不划算。从这里可以看出，召回阶段的主要职责是：从千万量级的候选物品里，采取简单模型将推荐物品候选集合快速筛减到千级别甚至百级别，这样将候选集合数量降下来，之后在排序阶段就可以上一些复杂模型，细致地对候选集进行个性化排序。</p><p>从上面在线推荐两阶段任务的划分，我们可以看出，召回阶段因为需要计算的候选集合太大，所以要想速度快，就只能上简单模型，使用少量特征，保证泛化能力，尽量让用户感兴趣的物品在这个阶段能够找回来；而排序阶段核心目标是要精准，因为它处理的物品数据量小，所以可以采用尽可能多的特征，使用比较复杂的模型，一切以精准为目标。</p><hr><h2 id="多路召回怎么做"><strong>多路召回怎么做</strong></h2><p>目前工业界推荐系统的召回阶段一般是怎么做的呢？可以用一句江湖气很重的话来总结，请您系好安全带坐稳，怕吓到您，这句话就是：“一只穿云箭，千军万马来相见”。听起来霸气十足是吧？我估计看过古惑仔电影的都熟悉这句话，黑帮集结打群架的时候喜欢引用这句名言，以增加气势，自己给自己打气。如果和推荐系统对应起来理解，这里的“穿云箭”就是召回系统，而千军万马就是各路花式召回策略。</p><figure><img src="https://pic3.zhimg.com/80/v2-4a73106e581ad1d547343197752e028d_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>目前工业界的推荐系统，在召回阶段，一般都采取多路召回策略。上图展示了一个简化版本的例子，以微博信息流排序为例，不同业务召回路数不太一样，但是常用的召回策略，基本都会包含，比如兴趣标签，兴趣Topic，兴趣实体，协同过滤，热门，相同地域等，多者几十路召回，少者也有7／8路召回。</p><p>对于每一路召回，会拉回K条相关物料，这个K值是个超参，需要通过线上AB测试来确定合理的取值范围。如果你对算法敏感的话，会发现这里有个潜在的问题，如果召回路数太多，对应的超参就多，这些超参组合空间很大，如何设定合理的各路召回数量是个问题。另外，如果是多路召回，这个超参往往不太可能是用户个性化的，而是对于所有用户，每一路拉回的数量都是固定的，这里明显有优化空间。按理说，不同用户也许对于每一路内容感兴趣程度是不一样的，更感兴趣的那一路就应该多召回一些，所以如果能把这些超参改为个性化配置是很好的，但是多路召回策略下，虽然也不是不能做，但是即使做，看起来还是很Trick的。有什么好办法能解决这个问题吗？有，本文后面会讲。</p><hr><h2 id="用fmffm模型做召回意味着什么"><strong>用FM/FFM模型做召回意味着什么</strong></h2><p>本文的主体是春节期间写完的，但是这个部分是最近加进来的，因为我发现第一篇介绍FM模型做召回的文章发出去后，很多人反馈有些地方看不懂。这让我一度感到FM那篇文章写得有些失败，通俗易懂一直是我写文章的首要追求，有时候宁肯为了保证这点，牺牲掉很多公式的表达。因为据说每加进一个公式，读者就会跑掉一半。每当我写到公式部分的时候，都会下意识地数数公式数量，当发现读者都已经跑光了的时候，我一般回头会把公式都默默地删掉。说远了，这里增加这个部分，是考虑到上篇介绍FM做召回的文章读者的疑惑，先做些背景说明，以增进理解。</p><p>首先，第一个问题是：FM/FFM模型一般是作为典型的Ranking阶段的模型，怎么理解用它来做召回这件事情呢？</p><figure><img src="https://pic4.zhimg.com/80/v2-d3292c7c2c38cfed8720288d8addc3be_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>上图是目前最常见的多路召回+Ranking的两阶段推荐策略，上面讲过不多说。</p><figure><img src="https://pic4.zhimg.com/80/v2-3e7b9ff55de75fe590ddec2fd4ac4f48_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>如果我们想把一般用来做排序的模型，比如FM、FFM，用来做召回模型。那么一种比较温柔地做法，参考上图，<strong>就是用模型作为一路新的召回策略，或者用模型召回代替掉原先多路召回的一路或者几路召回，这是温柔派的做法。</strong></p><figure><img src="https://pic3.zhimg.com/80/v2-c347eaf45c663c6640a6804b4209eb17_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>你说了，我生性比较凶猛，堪比猛禽，那么怎么做呢？<strong>像上图这么做，用FM/FFM模型代替掉所有原先的多路召回策略。本文明显主要目的之一是这个，从这里好像你很容易推断我也是猛禽派的代表是吧？</strong></p><figure><img src="https://pic3.zhimg.com/80/v2-5fb2c2699289ed6194df229e0970df86_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>你又说了，刚才那个做法也还算温柔吧，我属于飞越疯人院那种风格的，是不是可以做得更生猛些？可以啊，向上图这么做推荐，就是用一个模型把召回和排序两个阶段的事情全做掉。这也是本文要探讨的另外一个要点。嗯，此时，聪明的你肯定又推论出了什么真理是吧？</p><p>上面说的是有困惑的第一个点，可能我之前没讲明白用排序模型做召回是什么意思；第二个问题是：FM/FFM做排序的话，大家都很熟悉怎么用了，那么用这些模型做召回，对它有什么和做排序不同的要求吗？其实把FM/FFM模型用在召回和Ranking这两个不同阶段，差别还是蛮大的。</p><p>如果是在排序阶段使用FM/FFM或者其他模型，因为此时用户已知，要排序的具体是哪篇文章也知道（通过召回阶段拉回来少量的文章），都在模型面前摆着，此时模型的任务是要判断用户是否对某篇文章感兴趣，所以用户特征和物料特征可以同时作为模型的输入。</p><p>而如果是在召回阶段使用FM/FFM模型，首先面临的问题是：我们现在只知道是哪个用户在浏览，用户特征都是全的，但是面对的判断对象是千万量级的文章，汪洋大海，人民战争，而不是某篇具体的文章。模型的任务是：只拿着用户特征，去千万量级的文章库里找出一小批用户可能感兴趣的文章出来，而且速度要够快。这个要求就稍微刁钻一些。</p><p>这是它们最大的不同，一个不同是召回阶段要计算的数据量巨大；另外一个不同是貌似我们手头只有用户特征，此时如何应用模型呢？所以你可以看出来，在召回阶段，使用某个具体的模型，比排序阶段使用这个模型的应用条件更苛刻，需要满足一定的模式，才能把某个模型用到召回阶段。那么，怎么做呢？</p><figure><img src="https://pic1.zhimg.com/80/v2-afac85fc47ad033a9c9ecfd6c71efd30_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>上图展示了一个通用的在召回阶段使用模型的思路，尽管具体采用的模型不同，但是基本都是在这个框架下运转的：因为用户特征和物料特征不能同时作为模型的输入，那么我们需要对它们分别处理。具体做法是，采用某个模型，离线把用户特征打包成用户embedding，代表用户兴趣向量；同时可以离线或者近乎在线地把物料特征也单独打包，打成物料embedding，需要将两类特征分离。</p><p>在使用模型的时候，对于每个用户以及每个物品，我们可以按照上述方法，将每个用户的兴趣向量离线算好，存入在线数据库中比如Redis（用户ID及其对应的embedding），把物品的向量逐一离线算好，存入Faiss(Facebook开源的embedding高效匹配库)数据库中。</p><p>当用户登陆或者刷新页面时，可以根据用户ID取出其对应的兴趣向量embedding，然后和Faiss中存储的物料embedding做内积/Cosine等不同类型的计算，按照得分由高到低返回得分Top K的物料作为召回结果。提交给第二阶段的排序模型进行进一步的排序。</p><p>所以你看到了，在召回阶段是如何使用模型的：首先用户特征和物品特征需要分离打包，这个包怎么打？才能符合FM/FFM的计算原则？这是一个问题。然后通过Faiss解决数据量太大计算速度慢的问题，所以速度问题可以认为已经被解决了。剩下的问题就是Faiss的对用户兴趣embedding和物料embedding做内积计算，这种计算结果，是否符合FM/FFM模型的计算原则？或者其它模型的计算原则？这个也是关键。想明白上述一个问题一个关键，那么完全可以采用新模型来做这个事情。</p><p>此为背景解释，下面进入模型相关内容。</p><hr><h2 id="什么是ffm模型"><strong>什么是FFM模型</strong></h2><p>FFM的全称是Field-aware FM，直观翻译过来，就是能够意识到特征域(Field)的存在的FM模型。那么FFM模型是有第六感吗？它怎么能够感知到特征域的存在呢？这里先不解释，后面会说明。我们先看个例子。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-f78465b7f246cb568751f92eaee63521_1440w-20200913155916034.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>上图是一个人造的广告CTR的数据例子，代表的意思是在某个网站（Publisher）上刊登一则广告（Advertiser），某个用户（用户性别特征Gender）是否会点击某条广告的数据。这个例子中假设包含三个特征域（Field）:网站Publisher(可能的特征值是ESPN、Vogue、NBC)、广告（可能的特征值是Nike、Adidas、Gucci）和性别特征Gender(可能的特征值是Male、Female)。由这个例子可以看出组合特征的重要性：如果在体育网站ESPN上发布Nike的广告，那么100次展现，80次会被点击，而20次不会被点击。意味着组合特征（Publisher=”ESPN” and Advertiser=”Nike”）是个很强的预测用户是否点击的二阶组合特征。上图同时展示了一条用户点击记录。</p><p>我们用这个例子来说明FFM的基本思想，FM模型可以看做是FFM模型的一个特例，所以在说明FFM模型思想之前，我们先用上述例子说明FM的思想，然后通过和FM模型的对比，很容易理解FFM模型的基本思路。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-a5cea9560693a512605062128e845d1d_1440w-20200913155913977.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>FM模型在做二阶特征组合的时候，对于每个二阶组合特征的权重，是根据对应两个特征的Embedding向量内积，来作为这个组合特征重要性的指示。当训练好FM模型后，每个特征都可以学会一个特征embedding向量，参考上图。当做预测的时候，比如我们接收到上面例子的数据，需要预测用户是否会点击这条广告，则对三个特征做两两组合，每个组合特征的权重，可以根据两个对应的特征embedding内积求得，对所有组合特征求和后，套接Sigmoid函数即可做出二分类预测。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-b5cc5b1a27d14181f07b875895bca60b_1440w-20200913155911511.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>对于FM模型来说，每个特征学会唯一的一个特征embedding向量，注意，在这里，和FFM的最大不同点冒出来了。为了更容易向FFM模型理解过渡，我们可以这么理解FM模型中的某个特征的embedding：拿Vespn这个特征作为例子，当这个特征和其它特征域的某个特征进行二阶特征组合的时候，不论哪个特征域的特征和Vespn特征进行组合，Vespn这个特征都反复使用同一个特征embedding去做内积，所以可以理解为Vespn这个特征在和不同特征域特征进行组合的时候，共享了同一个特征向量。</p><p>沿着这个思路思考，我会问出一个问题：我们可以改进下FM模型吗？怎么改进？下图给个提示。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-459a470443a9238aaa8412f2b74a78d1_1440w-20200913155908485.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>如果你对算法敏感的话，你可以这么回答我：既然FM模型的某个特征，在和任意其它特征域的特征进行组合求权重的时候，共享了同一个特征向量。那么，如果我们把这个事情做地更细致些，比如Vespn这个特征，当它和Nike（所属特征域Advertiser）组合的时候用一个特征embedding向量，而当它和Male(所属特征域Gendor)组合的时候，使用另外一个特征embedding向量，这样是否在描述特征组合的时候更细腻一些？也就是说，当Vespn这个特征和属于Advertiser这个域的特征进行组合的时候，用一个特征embedding；和属于Gendor这个特征域的特征进行组合的时候，用另外一个特征embedding。这意味着，如果有F个特征域，那么每个特征由FM模型的一个k维特征embedding，拓展成了（F-1）个k维特征embedding。之所以是F-1，而不是F，是因为特征不和自己组合，所以不用考虑自己。</p><p>这样行吗？</p><p>嗯，你说的很有道理，是的，这其实就是FFM模型的基本思想。所以从上面两个图的示意可以看出，为何说FM模型是FFM模型的特例。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-bf5f4f62caebbc80782c245a5a8eabc8_1440w-20200913155924622.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>我们再回头看下刚才那个点击数据的例子，看看在FFM场景下是怎样应用的，上图展示了这个过程。因为这个例子有三个特征域，所以Vespn有两个特征embedding，当和Nike特征组合的时候，用的是针对Advertisor这个特征域的embedding去做内积；而当和Male这个特征组合的时候，则用的是针对Gendor这个特征域的embedding去做内积。同理，Nike和Male这两个特征也是根据和它组合特征所属特征域的不同，采用不同的特征向量去做内积。而两两特征组合这个事情的做法，FFM和FM则是完全相同的，区别就是每个特征对应的特征embedding个数不同。FM每个特征只有一个共享的embedding向量，而对于FFM的一个特征，则有（F-1）个特征embedding向量，用于和不同的特征域特征组合时使用。</p><p>从上面的模型演化过程，你可以体会到，为何这篇文章的标题将FFM模型称为笨重，它笨重在哪里？说它笨重，是和FM模型相比较而言的。我们可以推出，假设模型具有n个特征，那么FM模型的参数量是n*k（暂时忽略掉一阶特征的参数），其中k是特征向量大小。而FFM模型的参数量呢？因为每个特征具有（F-1）个k维特征向量，所以它的模型参数量是(F-1)*n*k，也就是说参数量比FM模型扩充了(F-1)倍。这意味着，如果我们的任务有100个特征域，FFM模型的参数量就是FM模型的大约100倍。这其实是很恐怖的，因为现实任务中，特征数量n是个很大的数值，特征域几十上百也很常见。另外，我们在上一篇介绍FM模型的文章里也讲过，FM模型可以通过公式改写，把本来看着是n的平方的计算复杂度，降低到 <span class="math inline">\(O(k \cdot n)\)</span> 。而FFM无法做类似的改写，所以它的计算复杂度是 <span class="math inline">\(O(k \cdot n^2)\)</span> ，这明显在计算速度上也比FM模型慢得多。所以，无论是急剧膨胀的参数量，还是变慢的计算速度，无论从哪个角度看，相对FM模型，FFM模型是略显笨重的。</p><p>正因为FFM模型参数量太大，所以在训练FFM模型的时候，很容易过拟合，需要采取早停等防止过拟合的手段。而根据经验，FFM模型的k值可以取得小一些，一般在几千万训练数据规模下，取8到10能取得较好的效果，当然，k具体取哪个数值，这其实跟具体训练数据规模大小有关系，理论上，训练数据集合越大，越不容易过拟合，这个k值可以设置得越大些。</p><p>上面是对FFM模型基本思想的说明，下面我们讨论如何用FFM模型做召回。</p><hr><h2 id="如何用ffm做召回模型"><strong>如何用FFM做召回模型</strong></h2><p>如果要做一个实用化的统一召回模型，要考虑的因素有很多，比如Context上下文特征怎么处理，一阶项特征怎么加入等。为了能够更清楚地说明，我们先从简易模型说起，然后逐步加入必须应该考虑的元素，最后形成一个实用化的FFM版本的召回模型。</p><p>不论是简化版本FFM召回模型，还是完全化版本，首先都需要先做如下两件事情：</p><p>第一，离线训练。这个过程跟在排序阶段采用FFM模型的离线训练过程是一样的，比如可以使用线上收集到的用户点击数据来作为训练数据，线下训练一个完整的FFM模型。在召回阶段，我们想要的其实是：<strong>每个特征和这个特征对应的训练好的（F-1）个embedding向量。这个可以存好待用。</strong></p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-30e4ad00c3824b9ee9417db3eb8b0c66_1440w-20200913155927599.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第二，如果将推荐系统做个很高层级的抽象的话，可以表达成学习如下形式的映射函数： <span class="math display">\[y=F(\text {User, Item, Context})\]</span> 意思是，我们利用用户（User）相关的特征，物品(Item)相关的特征，以及上下文特征（Context,比如何时何地用的什么牌子手机登陆等等）学习一个映射函数F。学好这个函数后，当以后新碰到一个Item，我们把用户特征，物品特征以及用户碰到这个物品时的上下文特征输入F函数，F函数会告诉我们用户是否对这个物品感兴趣。如果他感兴趣，就可以把这个Item作为推荐结果推送给用户。</p><p>说了这么多，第二个我们需要做的事情是：把特征域划分为三个子集合，用户相关特征集合，物品相关特征集合以及上下文相关的特征集合。而用户历史行为类特征，比如用户过去点击物品的特征，可以当作描述用户兴趣的特征，放入用户相关特征集合内。至于为何要这么划分，后面会讲。</p><p>做完上述两项基础工作，我们可以试着用FFM模型来做召回了。</p><h3 id="简易版ffm召回模型">1简易版FFM召回模型</h3><p>我们先来尝试着构建一个简易版的FFM召回模型。</p><p>在本文前面，我新增加了一节内容，专门叙述了如果想要使用类似FM/FFM这种排序模型来做召回，面临哪些约束，以及要解决的一个问题和一个关键点。那么如果你现在的任务是使用FFM模型来做召回，这个问题以及关键点怎么解决？建议你可以想想。下面是我思考的方案。</p><h4 id="问题如何根据ffm计算原则构建用户embedding以及物品embedding">1.1问题：如何根据FFM计算原则构建用户Embedding以及物品Embedding</h4><p>上文简单叙述过，用排序模型做召回的特点。其实，你可以这么理解：把FM/FFM等模型用来做召回，看做原先的“召回+排序”两阶段过程中的第二个过程前置，放到召回阶段来做排序。它本质上其实就是希望同时将两阶段过程用同一个阶段吸收掉。</p><p>只是因为召回阶段面临的待处理物料数量太大，所以依赖一种高效的计算模式，而这个目前看不是问题，成熟的方案就是Faiss的Embedding匹配的模式，速度应该是足够实用化的。</p><p>所以问题就转换成了：如何根据某个模型的计算标准，打出对应的用户侧Embedding，以及物品侧的Embedding。于是，我们可以将召回阶段的FM/FFM或者其它模型看成是一种受约束的排序过程，这里的“约束”，指的是需要明确将FM/FFM召回模型划分为两个阶段：首先需要离线将用户侧特征和物品侧特征进行分离编码，然后在线快速embedding匹配的时候完成模型计算过程。这不像传统的排序阶段使用FM/FFM模型，此时，两侧特征可以同时作为模型的输入，明显更灵活，受约束更小。所以，我们可以把召回阶段采用这种排序模型看成一种受约束的排序。</p><p>我们的主题是利用FFM模型做召回。于是问题转换成了：如何根据FFM模型的计算原则，打出对应的用户侧Embedding，以及物品侧Embedding。怎么做呢？</p><p>我用一个极度简化的例子来说明这个过程：假设在这个例子中，我们只使用五个特征域，用户侧采用两个特征域U1和U2，而物品侧采用三个特征域I1,I2和I3。当面对具体数据实例的时候，对应特征域下会有一个对应的特征值存在。对于某个具体的特征值f1来说，根据FFM的计算原则，它在离线训练阶段会学会4个对应的embedding向量，分别在这个特征和其它特征域的特征进行特征组合的时候使用。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-c0bd21b1e8f43a08063663ad14b7cd4c_1440w-20200913155930356.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>首先，要意识到，<strong>我们当前的任务是希望通过FFM模型来做用户任意特征和物品任意特征的组合</strong>。</p><p>对于用户侧的两个特征，我们取出它们分别用于和对应的三个物品侧特征域组合时要用的embedding向量。比如对于U1来说，我们分别将这三个特征embedding称为U11/U12/U13，U11的两个下标数字的含义是：这是第1个用户侧的特征域U1和第1个物品侧特征域I1进行组合时使用的特征embedding。U12则是第1个用户侧的特征域U1和第2个物品侧特征域I2进行组合时使用的特征embedding。如此处理，于是每个用户侧的特征取出三个特征向量，每个物品侧的特征取出两个特征向量。形成上图的结构。</p><p>根据FFM的计算规则，如果我们希望计算用户侧和物品侧的两两特征组合，需要将特征向量求内积时的对应关系建立起来，图中箭头标出了对应关系。你可能看着有点乱，但是对应关系里面隐藏着一个规律，你可以找找这个规律看。提示下：你可以看看U和I特征向量下标编号，有什么规律性的对应关系吗？U12&lt;--&gt;I21、U23&lt;--&gt;I32……，嗯，我估计你看出来了，规律就是&lt;Uij,Iji&gt;。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-97bc87f3fa1e0f4dc861474d282e8069_1440w-20200913155932133.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>上面那张图的特征向量之间的对应关系，看着确实有点让人眼花缭乱，那么能否让它们的对应关系看上去更简洁直接一些呢？很简单，只需要把物品侧的特征向量重新排下顺序即可。这个重排序的过程，可以看做是：对原先顺序排列的物品侧特征向量矩阵，做了一个转置操作。这样，每个物品侧的特征向量，就和需要求内积的对应用户侧特征向量，形成了整齐的一一对齐的效果了。具体过程参考上图。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-10b600cf6dd26433a5f69273949cc0c8_1440w-20200913155934135.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>我们讲过，模型做召回，要解决的问题是：如何利用FFM原则打出对应的用户侧embedding和物品侧embedding。前面两段所讲的，是根据FFM原则，对应的特征向量应该如何对齐的过程，而如果向量对齐后，怎么打出两个embedding向量？很简单，把刚才对齐的二维向量拉平，顺序concat连接，就形成了展开的一维的用户embedding和物品embedding。</p><p>然后，我们可以把每个物品的embedding离线存入Faiss，用户embedding离线算好，放在内存数据库中。当用户登录或者刷新时，在线根据用户的embedding向量，通过Faiss的快速查询功能，根据内积往回拉取top K物品，返回的物品就是根据FFM模型计算得分最高的推荐结果。</p><h4 id="关键点用户embedding和物品embedding内积计算符合ffm计算原则吗">1.2关键点：用户Embedding和物品Embedding内积计算符合FFM计算原则吗</h4><p>这样，其实就已经完成了一个简易版本的FFM召回模型。我们考虑下之前说的关键点：</p><p>两个拉长版本的User Embeding和Item Embedding，通过Faiss内积计算，最后的得分，是否和标准的FFM计算结果等价？</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-c188e3bf86f198b46d080df4938c6a66_1440w-20200913155937995.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>两者很显然是等价的，&lt;U,I&gt;内积的操作是两个长向量对应位的数值相乘，然后求和，所以拉长向量匹配版本和分拆成子项分别求内积再求和，数值是一样的，从上图示例可以很容易看出这一点。</p><p>从上述说明可以看出，此时我们获得了一个基础版本的FFM召回模型，这个版本的召回模型，只考虑了U和I特征的相互组合，其它的因素还没考虑。</p><p>此时应该回头再想想我们的标题：沉重的FFM。为什么我说FFM沉重呢？你可以算算这个拉平的embedding向量的长度。假设在我们的实际任务中，用户侧有50个特征域（M=50），物品侧有50个特征域(N=50)，每个特征向量的大小k=10，可以很容易推断出用户和物品的embedding长度，它的 size=M<em>N</em>K=50<em>50</em>10=25000，两万五千，“苦不苦，想想红军两万五，累不累，想想革命老前辈”，如果把一个数值位换成一里地，那快赶上长征的距离了。而这对于Faiss来说，如果物品库比较大，速度明显是跟不上的。</p><p>一种直观减小embedding长度的方法是把k值往小放，比如k=2或者4。如果只是使用FFM模型做召回，这个策略是可行的，反正召回阶段不用特别准，推荐结果的准确性靠第二个排序阶段来来保证，召回阶段原则上能把好的物料找回来即可。即使这样，embedding size=50*50*2=5000，长度也还是很长，虽说比不上长征的里程，但是明显比苏小妹的脸还是要长的。</p><p>另外一种思路是把特征域数量降下来，比如M=N=10，就是说用户和物品两侧各有10个特征域，这样的话embedding size=10*10*2=200。嗯，这个基本可以实用化了。如果只是将FFM用来做召回，虽说受限严重，但这么做，也不是不可以。</p><p>但是，我希望FFM不仅能够不受特征域数量限制地做召回，而且最好它还能一阶段地把排序也做掉，所以靠上面两个手段，是不能从根本上解决问题的。有什么加速策略吗？我想了两个方法，后面会分别介绍。</p><p>我们先把速度问题往后放一放，等会再谈。先一步一步优化这个FFM召回模型。</p><p>上面介绍的FFM召回模型，只是个简易版本，和标准FFM模型相比，很多内容它还没有考虑进来，比如用户侧或物品侧内部特征组合问题，一阶项如何引入的问题以及如何融入场景上下文特征问题，如果再将这三者引入，此时应该怎么做呢？</p><h3 id="加入用户侧及物品侧内部特征组合">2.加入用户侧及物品侧内部特征组合</h3><p>上小节所述内容，本质上是在计算用户侧任意特征和物品侧任意特征之间的两两特征组合。到这里你发现，如果希望在召回阶段完整复现FFM模型，还需要考虑用户侧内部两两特征组合，以及物品侧内部两两特征组合。</p><p>至于用户侧或者物品侧内部的两两特征组合的计算方法，可以仿照上述计算用户侧和物品侧特征组合的方法，也可以按照标准的FFM计算流程计算，总之方式比较灵活。关键的问题是：假设用户侧的内部特征两两组合得分Score(User_i*User_j)及Score(Iem_i*Item_j)算出来后，如何把它们集成进入那两个长长的用户embedding和物品embedding中？</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-949c8f23ae88ec9f2fbcf5b22b8b53b7_1440w-20200913155940220.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>可以如上图所示去做，在用户的二阶项embedding后添加两位：一位就是用户侧内部特征组合得分，在对应的物品侧位置，增加一位，值设置为1。这样的话，在Faiss做内积的过程中，就将用户侧内部特征组合得分计入；类似地，在物品侧也可以如此炮制。这样就将U和I的内部特征组合融入FFM召回模型中了，FM模型也是一样的道理。</p><p>理论上来说，如果是只用FM/FFM模型做召回，用户侧内部的特征组合对于返回结果排序没有影响，所以可以不用加入。物品侧内部特征之间的特征组合可能会对返回的物品排序结果有影响，可以考虑引入这种做法，把它统一加进去。而如果是希望用FM/FFM模型一阶段地替代掉“多路召回+Ranking”的两阶段模式，则可以考虑完全复现FM/FFM模型，如此，应将两侧的内部特征组合都考虑进去。</p><h3 id="如何加入一阶项">3.如何加入一阶项</h3><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-acc03d65b554dce141a5c46b38a6c6b4_1440w-20200913155941622.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>我们知道，标准的FM/FFM公式中是包含一阶项的，也就是LR模型。如果我们根据上节方法所述，做出了用户侧和物品侧的二阶项embedding，此时，想要把一阶项加入FM/FFM召回模型，应该怎么做呢？</p><figure><img src="https://pic1.zhimg.com/80/v2-b0c05a59f9f2abc12610e57224f659e1_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>其实很简单，上图展示了一种做法，在用户侧的embedding中增加两位，第一位是属于用户特征域的特征对应的一阶项累加和，相应地，在物品侧对应位置增加一位，设置值为1，这样在Faiss求内积的过程中，就把用户侧的一阶项引入了。类似地，也可以如此加入物品侧的一阶项。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-108656082bb8bc2cb1cea6ca129e5b10_1440w-20200913155946289.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>还有一种做法，如上图所示，不做用户侧和物品侧的一阶项求和，而是直接将用户侧及物品侧对应特征的一阶权重拼接到二阶项的embedding后。同样的，对应的物品侧或用户侧相应位置设置为1。这样，也可以在Faiss求内积过程中，把一阶项算入得分中。</p><p>微博在业务中的实践表明，如果采取FM召回模型，对于有些应用来说，一阶项对于最终效果有明显影响，所以在用FM/FFM做召回的时候，是需要将一阶项考虑进去的，这可能是个别一阶特征比较重要导致的。我们在Criteo数据集合的实验结果也证明：如果是FM模型，一阶项是有用的，去掉一阶项，只保留二阶项，AUC大约会掉1个绝对百分点，对于CTR来说，这个差距还是很明显的；而如果是采用DeepFM模型，则FM部分是否保留一阶项对最终结果没有什么影响，这说明DNN的隐层有效地将一阶项的作用吸收掉了。</p><h3 id="如何加入场景上下文特征">4.如何加入场景上下文特征</h3><p>我们上面说过，抽象的推荐系统除了用户特征及物品特征外，还有一类重要特征，就是用户发生行为的场景上下文特征（比如什么时间在什么地方用的什么设备在刷新），而上面逐步改进版本的FFM召回模型还没有考虑这一块。</p><p>之所以把上下文特征单独拎出来，是因为它有自己的特点，有些上下文特征是近乎实时变化的，比如刷新微博的时间，再比如对于美团嘀嘀这种对地理位置特别敏感的应用，用户所处的地点可能随时也在变化，而这种变化在召回阶段就需要体现出来。所以，上下文特征是不太可能像用户特征离线算好存起来直接使用的，而是用户在每一次刷新可能都需要重新捕获当前的特征值。动态性强是它的特点。</p><p>而考虑进来上下文特征，如果我们希望构造和标准的FFM等价的召回模型，就需要多考虑两个问题：</p><p>问题一：既然部分上下文特征可能是实时变化的，无法离线算好，那么怎么实时地将它融入上文所述的FFM召回计算框架里？</p><p>问题二：我们需要考虑上下文特征C和用户特征U之间的特征组合，也需要考虑C和物品特征I之间的特征组合。上下文特征有时是非常强的特征。那么，如何做能够将这两对特征组合考虑进来呢？</p><p>我们可以这么做：</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-d69687449298efde2add89ac836e653f_1440w-20200913155948279.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>首先，由于上下文特征的动态性，所以给定用户UID后，可以在线查询某个上下文特征对应的（F-1）个embedding向量，F是任务特征域的个数。这（F-1）个特征向量可以分成三组：一组是用于拿Context特征和用户特征域的特征进行特征组合用的，在我们上面给的例子里，有两个；第二组是拿Context特征和物品特征域的特征进行特征组合用的，我们的例子里这个数目是三；第三组是Context特征用于自身内部特征组合用的，这个我们先忽略，因为它的做法和上文所述的用户侧及物品侧求内部特征组合的做法是一样的。</p><p>为了简化说明，我们假设只有一个Context特征，于是它对应了（6-1）=5个embedding向量，其中2个是用于和用户侧特征进行组合的，3个是用于和物品侧特征进行组合的。我们把它们拆分成两组，如上图所示。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-6843a23f66c60f6a7138f46eb71fdf8d_1440w-20200913155952168.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>然后，我们来计算上下文特征和用户侧特征如何进行特征组合。如上图所示，其实这个过程和上文讲的用户侧与物品侧的FFM特征组合过程是一样的。物品侧和上下文侧特征找到对应的embedding向量做内积计算即可。这里不展开讲，如果不理解的话再回头看下上面的叙述。因为这两类特征都在用户发生访问行为的时候能获得，不依赖和物品发生关系，所以这个过程可以在用户侧在线计算完成。</p><p>这个内积数值代表用户特征和上下文特征的二阶特征组合得分，算好备用。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-0f2b0112c651689ae5007fdb33bc8336_1440w-20200913155953842.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>再然后，我们来计算上下文特征和物品侧特征的特征组合，如上图所示。其实很好理解，就相当于在做用户侧特征与物品侧特征组合的时候，在用户侧新加入了几个特征，无非这几个特征是Context特征，而其实不是用户侧的特征，但是做法是完全一样的。这样，就可以将Context特征打入用户侧embedding以及物品侧embedding，于是Context和物品的特征组合问题就解决了。</p><p>利用这个用户侧embedding，用Faiss通过内积方式取出Top K物品。通过这种方式取出的物品同时考虑到了用户和物品的特征组合&lt;U,I&gt;，以及上下文和物品的特征组合&lt;C,I&gt;。</p><p>假设返回的Top K物品都带有内积的得分Score1，再考虑上一步&lt;U,C&gt;的得分Score，将两者相加对物品重排序（&lt;U,C&gt;因为跟物品无关，所以其实不影响物品排序，如果是召回阶段使用FM/FFM，是可以不考虑引入的），就得到了最终结果。而这个最终结果，在遵循FFM计算原则的基础上，考虑了U/I/C两两之间的特征组合。当然，我们可以把上面说的一阶项以及&lt;U,U&gt;/&lt;I,I&gt;内部特征组合也融入这个系统。</p><p>于是我们通过这种手段，构造出了一个完整的FFM召回模型。这个召回模型通过构造user embedding，Context embedding和Item embedding，以及充分利用类似Faiss这种高效embedding计算框架，就构造了高效执行的和FFM计算完全等价的召回系统。</p><p>前文提过，FFM按照上述方法做，打出来的两个embedding长度太长，可能影响Faiss的效率。下面提供两个可能的提速方案。</p><h3 id="沉重的ffm并行拉取提速策略">5.沉重的FFM：并行拉取提速策略</h3><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-810dc780164f722063261689fc763389_1440w-20200913155956860.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>如果用上述方法做FFM召回模型，有可能被拉平的用户embedding以及物品embedding长度太长，这会导致Faiss提取速度变慢，以致这个方法因为速度太慢而变得不可行。那么一种比较直接的提速想法就是：把太长的用户embedding打断成连续片段，物品embedding也相应地打断，同一个物品的embedding片段分别存在不同的Faiss数据库中，这样由于减少了embedding的长度，所以会极大加快Faiss的提取速度。</p><p>在结果返回时，对每个User Embedding片段拉回的Item子集合进行合并，同一个物品，把各自的片段内积得分累加，就得到了这个物品相对用户的FFM最终得分，很容易推断，这种片段得分累加策略，和作为整体计算长向量内积，两者得分是相同的。按照这个得分对返回的物品重排序，于是就得到了最终计算结果。这是一种典型的并行策略。</p><p>虽然，理论上，这个方案能够处理相当长的embedding匹配问题。但是，这个方案有个问题：并不能保证返回结果的最终排序和真实排序是一致的。因为有可能某个综合总得分较高的物品没有被从任何一个Faiss子数据库拉回来，比如这个物品每个片段的得分都不太高也不太低的情况，是可能发生这种漏召回的情况的。</p><h3 id="沉重的ffmfmffm混合提速策略">6.沉重的FFM：（FM+FFM）混合提速策略</h3><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-651706d6025256992460f5699c4a823d_1440w-20200913155959227.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>本系列文章中，上篇在介绍FM召回模型的时候，可以看出，它的一个特别简洁的方式是把用户侧的特征embedding累加，以及物品侧的特征embedding累加，所以FM打出来的两个embedding长度，只跟k相关，跟特征数目没关系，无论多少特征，embedding size恒等于k。所以看着特别简洁，效率也高。</p><p>那么FFM是否能够参照FM的思路，把一部分特征的embedding累加起来，通过这种方式来减小用户侧或物品侧的embedding大小呢？我觉得，结论是这样的：如果你坚持做一个原汁原味版的FFM，是不可能存在类似的特征合并的，因为用户侧和物品侧的做内积的embedding向量都是一一对应的，且无公共因子项可提出，所以没有可能进行特征embedding合并。</p><p>但是，如果我们不是原教旨FFM主义分子，一定坚持计算过程完全符合FFM计算原则，那么这个事情还是可以做的。参考上图，我觉得可以这么做：不同用户侧的特征，对应Fileds的向量直接累加；而在物品侧，则是属于同一个特征域的向量直接累加。这样可以保证用户embedding和物品embedding大小一致。这样的话，用户侧和物品侧的embedding size=M*K，比如M=50,K=10，那么长度是500，这样的长度还是可以把速度做起来的。</p><p>如果参照上面的做法，这其实等价于做了这么个事情：用户侧的特征仍然坚持了FFM的计算原则，就是每个特征针对其它不同特征域的组合，采用了不同的特征向量；但是，物品侧的特征向量，因为同一个特征域的（F-1）个特征域合并成一个，类似于这里采取的是FM的特征embedding思路。所以，这个方法看上去貌似是一个处于FFM和FM模型之间的一种混合模型。至于效果的话，我估计应该比FM好，比FFM不如，很可能也介于两者之间。当然，这只是我的分析结论。实际效果如何要通过实验来证明。</p><p>上面是按照合并物品侧的同一个特征域的特征向量角度来做的。完全也可以反过来，就是去合并用户侧的同一个特征域的特征向量。而如果是那样，则embedding size=N*K。</p><p>好了，经过了一系列补充特性，以及一些性能优化方案，我们就得到了一个完整版本的FFM召回模型。上面所讲都是说如何用FFM模型来做召回，那么下面我们开始探讨本文开头提出的第一个问题：如何用FFM召回模型统一多路召回策略？</p><hr><h2 id="如何利用ffm模型做统一的召回模型">如何利用FFM模型做统一的召回模型</h2><p>上文书提到过，目前工业界推荐系统在召回阶段，大多数采用了多路召回策略，比如典型的召回路有：基于用户兴趣标签的召回；基于协同过滤的召回；基于热点的召回；基于地域的召回；基于Topic的召回；基于命名实体的召回等等，除此外还有很多其它类型的召回路。</p><p>现在我们来探讨下第一个问题：在召回阶段，能否用一个统一的模型把多路召回招安？就是说改造成利用单个模型，单路召回的模式？具体到这篇文章，就是说能否利用FFM模型来把多路召回统一起来？</p><p>在回答上述问题之前，我估计你会提出疑问：目前大家用多路召回用的好好的，为啥要多此一举，用一个模型把多路召回统一起来呢？这个问题非常好，我们确实应该先看这么做的必要性。</p><h3 id="统一召回和多路召回优缺点比较">1.统一召回和多路召回优缺点比较</h3><p>我们先来说明下统一召回和多路召回各自的优缺点，我觉得使用统一召回模式，相对多路召回有如下优点：</p><p>首先，采用多路召回，每一路召回因为采取的策略或者模型不同，所以各自的召回模型得分不可比较，比如利用协同过滤召回找到的候选Item得分，与基于兴趣标签这一路召回找到的候选Item得分，完全是不可比较的。这也是为何要用第二阶段Ranking来将分数统一的原因。而如果采取统一的召回模型，比如FM/FFM模型，那么不论候选项Item来自于哪里，它们在召回阶段的得分是完全可比的。</p><p>其次，貌似在目前“召回+Ranking”两阶段推荐模型下，多路召回分数不可比这个问题不是特别大，因为我们可以依靠Ranking阶段来让它们可比即可。但是其实多路召回分数不可比会直接引发一个问题：对于每一路召回，我们应该返回多少个Item是合适的呢？如果在多路召回模式下，这个问题就很难解决。既然分数不可比，那么每一路召回多少候选项K就成为了超参，需要不断调整这个参数上线做AB测试，才能找到合适的数值。而如果召回路数特别多，于是每一路召回带有一个超参K，就是这一路召回多少条候选项，这样的超参组合空间是非常大的。所以到底哪一组超参是最优的，就很难定。其实现实情况中，很多时候这个超参都是拍脑袋上线测试，找到最优的超参组合概率是很低的。</p><p>而如果假设我们统一用FM/FFM模型来做召回，其实就不存在上面这个问题。这样，我们可以在召回阶段做到更好的个性化，比如有的用户喜欢看热门的内容，那么热门内容在召回阶段返回的比例就高，而其它内容返回比例就低。所以，可以认为各路召回的这组超参数就完全依靠FM模型调整成个性化的了，很明显这是使用单路单模型做召回的一个特别明显的好处。</p><p>再次，对于工业界大型的推荐系统来说，有极大的可能做召回的技术人员和做Ranking的技术人员是两拨人。这里隐含着一个潜在可能会发生的问题，比如召回阶段新增了一路召回，但是做Ranking的哥们不知道这个事情，在Ranking的时候没有把能体现新增召回路特性的特征加到Ranking阶段的特征中。这样体现出来的效果是：新增召回路看上去没什么用，因为即使你找回来了，而且用户真的可能点击，但是在排序阶段死活排不上去。也就是说，在召回和排序之间可能存在信息鸿沟的问题，因为目前召回和排序两者的表达模式差异很大，排序阶段以特征为表达方式，召回则以“路／策略／具体模型”为表达方式，两者之间差异很大，是比较容易产生上述现象的。</p><p>但是如果我们采用FM/FFM模型来做召回的话，新增一路召回就转化为新增特征的问题，而这一点和Ranking阶段在表现形式上是相同的，对于召回和排序两个阶段来说，两者都转化成了新增特征问题，所以两个阶段的改进语言体系统一，就不太容易出现上述现象。</p><p>上面三点，是我能想到的采用统一召回模型，相对多路召回的几个好处。但是是不是多路召回一定不如统一召回呢？其实也不是，很明显多路召回这种策略，上线一个新召回方式比较灵活，对线上的召回系统影响很小，因为不同路召回之间没有耦合关系。但是如果采用统一召回，当想新增一种召回方式的时候，表现为新增一种或者几种特征，可能需要完全重新训练一个新的FM/FFM模型，整个召回系统重新部署上线，灵活性比多路召回要差。</p><p>上面讲的是必要性，讲完了必要性，我们下面探讨如何把多路召回改造成单路召回。</p><h3 id="如何将多路召回融入ffm召回模型">2.如何将多路召回融入FFM召回模型</h3><p>其实，用FFM模型统一多路召回，和FM模型统一多路召回，基本是一样的，只有些许不同。</p><p>我们以目前不同类型推荐系统中共性的一些召回策略来说明这个问题，以信息流推荐为例子，传统的多路召回阶段通常包含以下策略：协同过滤，兴趣分类，兴趣标签，兴趣Topic，兴趣实体，热门物品，相同地域等。这些不同角度的召回策略都是较为常见的。</p><figure><img src="/blog_cn/2020/09/13/recommend_system/FFM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%BA%94%E7%94%A8/v2-00eb67435deac9df8ad0536804b10d65_1440w-20200913160002614.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>我们再将上述不同的召回路分为两大类，可以把协同过滤作为一类，其它的作为一类，协同过滤相对复杂，我们先说下其它类别。</p><p>对于比如兴趣分类，兴趣标签，热门，地域等召回策略，要把这些召回渠道统一到FM/FFM模型相对直观，只需要在训练FM/FFM模型的时候，针对每一路的特性，在用户特征端和物品特征端新增对应特征即可。比如对于地域策略，我们可以把物品所属地域（比如微博所提到的地域）和用户的感兴趣地域都作为特征加入FM/FFM模型即可。兴趣标签，Topic，兴趣实体等都是类似的。所以大多数情况下，在多路召回模式下你加入新的一路召回，在FM/FFM统一召回策略下，对应地转化成了新增特征的方式。</p><p>然后我们再说协同过滤这路召回。其实本质上也是将一路召回转化为新加特征的模式。我们以前提到过：本质上MF模型这种典型的协同过滤策略，是FM模型的一个特例，而FM模型又是FFM模型的特例，所以其实MF模型也是FFM模型的特例。MF可以看作在FM/FFM模型里只有User ID和Item ID这两类（Fields）特征的情形。意思是说，如果我们将user ID和Item ID作为特征放入FFM模型中进行训练，那么FFM模型本身就是包含了协同过滤的思想的。</p><p>当然，对于超大规模的网站，用户以亿计，物品可能也在千万级别，如果直接把ID引入特征可能会面临一些工程效率问题以及数据稀疏的问题。</p><p>FM要想把ID特征融入，应该是可行的，因为毕竟每个特征只需要学习一个k维大小特征向量，虽然ID数量大，但是总还是能接受。但是，如果是在FFM召回模型中融入ID特征，你会发现这里有个严重的问题：因为每个特征要包含（F-1）个k维特征向量，这对于FFM来说，ID特征会有超量的参数需要学习。比如假设F=101,k=10，UID有1亿个不同ID。这意味着光UID特征，就需要1000亿参数，这个……估计你会被吓退。所以，感觉FFM是很难把协同特征引入的，除非，事先通过其它方法对ID进行协同embedding编码，在FFM中直接使用，而不作为它的参数。否则，这在参数量以及存储量上来说，是很难做到的。</p><p>在具体实施统一多路召回的时候，可以沿着这个路径逐步替换线上的多路召回：先用FM/FFM模型替换一路召回，线上替换掉；再新加入某路特征，这样上线，就替换掉了两路召回；如此往复逐渐把每一路召回统一到一个模型里。这是比较稳的一种替换方案。当然如果你是个猛人，直接用完整的FFM召回模型一步替换掉线上的各路召回，也，未尝不可。只要小流量AB测试做好也没啥。</p><hr><h2 id="ffm模型能将召回和排序阶段一体化吗">FFM模型能将召回和排序阶段一体化吗</h2><p>我们在前文讲过，召回和排序各司其职。召回主要考虑泛化性并把候选物品集合数量降下来；排序则主要负责根据用户特征／物品特征／上下文特征对物品进行精准排名。</p><p>那么，我们现在可以来审视下本文开头提出的第二个问题了：FFM模型能否将常见的两阶段模型一体化？即是否能将实用化的推荐系统通过FFM召回模型简化为单阶段模型？意思是推荐系统是否能够只保留FFM召回这个模块，绕过后续的排序阶段，FFM召回模块按照得分排序直接作为推荐结果返回。我们可以这么做吗？</p><p>这取决于FFM召回模型是否能够一并把原先两阶段模型的两个职责都能承担下来。这句话的意思是说，FFM召回模型如果直接输出推荐结果，那么它的速度是否足够快？另外，它的精准程度是否可以跟两阶段模型相媲美？不会因为少了第二阶段的专门排序环节，而导致推荐效果变差？如果上面两个问题的答案都是肯定的，那么很明显FFM模型就能够将现有的两阶段推荐过程一体化。</p><p>在本系列的第一篇介绍FM召回模型的文章里，分析结论是：FM模型无论在推荐精准性，还是推荐速度方面，应该是能够同时承载两阶段模型的功能的。</p><p>那么FFM召回模型也可以担任类似的重任吗？我的答案是：It Depends。要看情况，跟应用的复杂情况有关。</p><p>如果从推荐的精准性角度考虑，假设我们能够把排序阶段的特征都引入FFM召回模型，那么应该能够得到等价的排序结果，这个很好理解，因为这等于你在召回部分复制了一个完全相同的FFM排序模型，类似于把排序功能前置到了召回阶段，所以推荐精准度基本等价。</p><p>看着好像这个事情是能做的是吧？其实不然。</p><p>在前文我们分析过如何用FFM模型来做召回模型，你会再次发现FFM模型的特性，就是太沉重。这种“沉重性”在召回阶段，表现为：用FFM模型打出来的用户Embedding长度太长，如果用户侧有M个特征域，物品侧有N个特征域，单个特征embedding向量大小为K,先不考虑上下文特征域，打出来的用户Embedding size=M<em>N</em>K。而这个长度是很容易失控的。</p><p>如果这个长度太长，意味着单机版本的Faiss速度肯定是跟不上的，那这个事情就得搁浅。而如果长度可以接受，Faiss速度OK，那么这事情就能成。所以关键是这个M<em>N</em>K到底有多长。于是问题转换成了：M、N和K，各自大约有多大？</p><p>我们拿一个工业级的CTR数据Criteo来说明（4500万数据，39个特征域，为了好计算，我们假设是40个特征域）。先说K，这是单个特征向量的大小，在Criteo这种工业级的数据规模下，实验证明，K=8效果最好。如果FFM模型只是用在召回阶段，后面还会再接上排序模型，也就是两阶段模式，k主观随意设置小点，比如2到4，问题不太大，因为推荐的精准性还可以依赖排序模型来保证。而现在我们对FFM模型的期待更多，希望它一步把排序也做掉，于是这个k就不能调小，就得是8，否则推荐效果受影响。</p><p>再来说M和N，我们假设仍然是这个数据集，它有40个域，我们再假设这些特征域在用户侧和物品侧平分，就是:M=N=20。</p><p>于是我们可以算出，如果用FFM模型来做Criteo数据的召回模型，打出来的用户侧embedding大小为：M<em>N</em>k=20<em>20</em>8=3200。如果采用单机版本的Faiss做，这速度估计是跟不上的。如果采用上文讲的对用户侧embedding分布式切割的思路，比如把这个embedding切成10份，那么速度应该是能接受的，但是前面也说过，这可能对推荐精度有损失。</p><p>当然，我们也可以采取上文提到的（FM+FFM）嫁接版本来做，如果是这样，打出来的用户侧embedding size=M*K或N*K。对应Criteo数据来说，这个长度就是160，这对于Faiss来说，速度绝对不是问题，所以是可以充当一体化模型的。但是效果估计比不了原汁原味版本的FFM。</p><p>另外，如果排序包含ID特征，估计FFM召回模型也比较难以承担这个重任。</p><p>从上面这个实际例子来看，是否能使用FFM模型来做一体化推荐模型？这个问题的答案其实取决于任务复杂度，也就是特征域的个数，很明显结论是：如果特征域数量比较少，那么FFM模型是可行的，如果特征域数量比较多，则这事情做不了。除非，你愿意采取embedding分段切割模式损失精度，或者采取（FM+FFM）嫁接版本，而这也可能会损失精度。</p><p>当然，上面都是分析结果，并非实测，所以不能确定实际应用起来也能达到上述理论分析的效果。</p><h2 id="尾声"><strong>尾声</strong></h2><p>在本文开头，我提到过一枚硬币的故事。贾昆非常看好艾莉亚，认为她会成为最出色的无面者，也即刺客，想带走艾莉亚去狭海对面，但被艾莉亚拒绝了。贾昆给了艾莉亚一枚旧硬币，并告诉她，如果有朝一日她要找他，可以把这枚旧硬币交给布拉佛斯的任何一个人，并对他说“Valar Morghulis”。</p><p>两人自此分别，长久未见。在此期间，少女艾莉亚四处漂泊，历经苦厄，当有一天，发现家国残破，亲人或离散无音讯，或死亡不可追。世界虽大，无处容身，想起了贾昆曾经说过的话，于是远涉重洋来到传说中的布拉佛斯，在码头，她将硬币递给一位船夫，并说：“凡人皆有一死”。船夫应答：凡人皆须侍奉，之后将艾莉亚带到布拉夫斯的黑白之院。开门的是一位须发皆白的老人，一番谈话后，当老人撕下面具的时候，露出了贾昆的真面容。艾莉亚惊诧疑惑地问到：“你究竟是谁？”贾昆缓声回答：“无名之辈（No One），而这也是你的宿命”。从跨入黑白之院的大门起，艾莉亚步入了只属于她自己的，历尽艰险，追求成为“No One”的无尽宿命中。</p><p>谜底揭晓，故事也讲完了。</p><p>如果一句话归纳本文头尾故事的话，正所谓：</p><p>少年心事当拿云，谁念幽寒坐呜呃。</p>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
          <category> recommend system </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
            <tag> recommend system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统学习记录</title>
      <link href="/blog_cn/2020/09/13/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
      <url>/blog_cn/2020/09/13/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><figure><img src="https://pic4.zhimg.com/v2-4b94a3d94a0dde0eb6bc7ddef77c359b_r.jpg" alt="知识蒸馏在推荐系统的应用"><figcaption aria-hidden="true">知识蒸馏在推荐系统的应用</figcaption></figure><a id="more"></a><h2 id="常见词汇">常见词汇</h2><ol type="1"><li>多路召回<ol type="1"><li>简单来说就是用多个指标来进行排序筛选，每个指标选前k个作为召回结果。</li><li>所谓多路就是多个判断优先级的指标</li></ol></li></ol><h2 id="重点记录">重点记录</h2><ol type="1"><li>特征组合对于推荐排序是非常非常重要的</li><li>FM模型也直接引入<strong>任意两个特征的二阶特征组合</strong>，和SVM模型最大的不同，在于<strong>特征组合权重的计算方法</strong>。</li><li>这也是目前很多花样的embedding的最核心特点，就是从0/1这种二值硬核匹配，切换为向量软匹配，使得原先匹配不上的，现在能在一定程度上算密切程度了，具备很好的泛化性能。<ol type="1"><li>把0-1匹配转换为各自的embedding向量进行匹配</li></ol></li><li>如果用模型召回，那么多路召回就可以变成多feature的FM模型</li></ol><h2 id="问题汇总">问题汇总</h2><ol type="1"><li>我们能否使用一个统一的模型，将多路召回改造成单模型单路召回策略？</li><li>是否存在一个模型，这个模型可以将召回阶段和排序阶段统一起来，就是把两阶段推荐环节改成单模型单环节推荐流程？</li><li>对于每一路召回，<strong>会拉回K条相关物料</strong>，这个K值是个超参，<strong>需要通过线上AB测试来确定合理的取值范围。</strong><ol type="1"><li>那么显然这个K是需要动态决策的。长得很像multi-bandit。但是显然K是离散决策空间，而且决策空间为[0,inf]</li></ol></li></ol><h2 id="常见模型">常见模型</h2><h3 id="lr模型">LR模型</h3><figure><img src="/blog_cn/2020/09/13/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/image-20200913130215564.png" alt="image-20200913130215564"><figcaption aria-hidden="true">image-20200913130215564</figcaption></figure><h3 id="fm模型">FM模型</h3><p>两句话总结</p><ul><li>采用类似LR的回归模型，只不过加入了二阶交叉项（可以结合泰勒公式）</li><li>二阶交叉项的权重系数由每一个feature的embedding向量的内积组成。<ul><li><span class="math inline">\(\omega_{ij} = v_i \cdot v_j\)</span></li></ul></li></ul><figure><img src="/blog_cn/2020/09/13/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/image-20200913160054347.png" alt="image-20200913160054347"><figcaption aria-hidden="true">image-20200913160054347</figcaption></figure><h2 id="ffm模型">FFM模型</h2><p>简单总结</p><ul><li>大致框架与FM类似</li><li>每一个Feature对于每一个Field有各自的Embedding Vector（比如用户侧的Feature 对其他所有的Field都有一个Vector，而FM模型中每一个Feature都只有一个Vector）</li></ul><figure><img src="/blog_cn/2020/09/13/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/v2-b5cc5b1a27d14181f07b875895bca60b_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><figure><img src="/blog_cn/2020/09/13/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/image-20200913160040161.png" alt="image-20200913160040161"><figcaption aria-hidden="true">image-20200913160040161</figcaption></figure>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
          <category> recommend system </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
            <tag> recommend system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统技术演进趋势</title>
      <link href="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/"/>
      <url>/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-f1c304d0e1c57152fc743416b570e29e_r.png" alt="FFM及DeepFFM模型在推荐系统的探索"><figcaption aria-hidden="true">FFM及DeepFFM模型在推荐系统的探索</figcaption></figure><a id="more"></a><blockquote><p>这一篇主要讲推荐系统的技术趋势和推荐系统的一般步骤</p></blockquote><p>这篇文章我们主要分析一下推荐系统的总体架构，并且从推荐系统的各个部分出发展开分析。希望能够对以后有所帮助。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/1.jpg" alt="1"><figcaption aria-hidden="true">1</figcaption></figure><p>实际的工业推荐系统，如果粗分的化，经常讲的有两个阶段。首先是召回，主要<strong>根据用户部分特征</strong>，从海量的物品库里，<strong>快速</strong>找回一小部分用户<strong>潜在感兴趣的物品</strong>，然后交给<strong>排序环节</strong>，排序环节可以融入较多特征，使用复杂模型，来精准地做个性化推荐。<strong>召回强调快，排序强调准。</strong>当然，这是传统角度看推荐这个事情。</p><blockquote><p>简单总结：</p><ul><li>召回算法强调快速找到用户潜在感兴趣的部分物品，作用在于降低数据规模。</li><li>排序算法强调准确对少量物品进行准确排序。</li></ul></blockquote><p>但是，如果我们更细致地看实用的推荐系统，一般会有<strong>四个环节</strong>，如下图所示：</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-aa3552a6d0c8e8eb94f92ee33db316ca_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>四个环节分别是：<strong>召回、粗排、精排和重排</strong>。</p><ol type="1"><li>召回主要<strong>根据用户部分特征</strong>，从海量的物品库里，<strong>快速</strong>找回一小部分用户<strong>潜在感兴趣的物品</strong>，然后交给<strong>排序环节</strong>。</li><li>有时候因为每个用户召回环节返回的物品数量还是太多，怕排序环节速度跟不上，所以可以在召回和精排之间加入一个粗排环节，通过<strong>少量用户和物品特征</strong>，<strong>简单模型</strong>，来对召回的结果进行个粗略的排序，在保证一定精准的前提下，进一步减少往后传送的物品数量，粗排往往是可选的，可用可不同，跟场景有关。</li><li>然后精排环节，使用你能想到的<strong>任何特征</strong>，可以上你能承受速度极限的复杂模型，尽量精准地对物品进行个性化排序。</li><li>排序完成后，传给重排环节，传统地看，这里往往会上各种技术及业务策略，比如<strong>去已读、去重、打散、多样性保证、固定类型物品插入</strong>等等，主要是技术产品策略主导或者为了改进用户体验的。</li></ol><p>那么，每个环节，从技术发展的角度看，都各自有怎样的发展趋势呢？下面我们分头说明。</p><h1 id="召回技术">召回技术</h1><p>推荐系统的召回阶段是很关键的一个环节，但是客观的说，传统地看，这个环节，技术含量是不太高的，<strong>偏向策略型导向</strong>，往往灵机一动，就能想到一个策略，增加一路新的召回。你在网上搜，发现讲推荐模型的，95%是讲排序阶段的模型，讲召回的别说模型，讲它本身的都很少，这与它的策略导向有关系，大家觉得没什么好讲的。</p><p>总体而言，<strong>召回环节的有监督模型化以及一切Embedding化</strong>，这是两个相辅相成的总体发展趋势。而打embedding的具体方法，则可以有各种选择，比如下面介绍的几个技术发展趋势，可以理解为不同的给用户和物品打embedding的不同方法而已。</p><h2 id="模型召回">模型召回</h2><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-6291a51c3d710a1486a78e546a322627_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>传统的标准召回结构一般是<strong>多路召回</strong>，如上图所示。如果我们根据召回路是否有用户个性化因素存在来划分，可以分成两大类：</p><ol type="1"><li>一类是无个性化因素的召回路，比如热门商品或者热门文章或者历史点击率高的物料的召回；</li><li>另外一类是包含个性化因素的召回路，比如用户兴趣标签召回。</li></ol><p>我们应该怎么看待包含个性化因素的召回路呢？其实吧，你可以这么看，可以把某个召回路看作是：单特征模型排序的排序结果。意思是，可以把某路召回，看成是某个排序模型的排序结果，只不过，这个排序模型，<strong>在用户侧和物品侧只用了一个特征</strong>。比如说，标签召回，其实就是用用户兴趣标签和物品标签进行排序的单特征排序结果；再比如协同召回，可以看成是只包含UID和ItemID的两个特征的排序结果….诸如此类。<strong>我们应该统一从排序的角度来看待推荐系统的各个环节</strong>，这样可能会更好理解本文所讲述的一些技术。</p><p>如果我们换做上面的角度看待有个性化因素召回路，那么在召回阶段引入模型，就是自然而然的一个拓展结果：<strong>无非是把单特征排序，拓展成多特征排序的模型而已；</strong>而多路召回，则可以通过引入多特征，被融入到独立的召回模型中，找到它的替代品。如此而已。所以，随着技术的发展，在embedding基础上的模型化召回，必然是个符合技术发展潮流的方向。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-1c0c206bbe480d618c3f59704bcd3e7b_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>那么如何在召回阶段利用模型来代替多路召回呢？上图展示了一个抽象的模型召回的通用架构，核心思想是：将用户特征和物品特征分离，各自通过某个具体的模型，分别打出用户Embedding以及物品Embedding。在线上，可以根据用户兴趣Embedding，采用类似Faiss等高效Embedding检索工具，快速找出和用户兴趣匹配的物品，这样就等于做出了利用多特征融合的召回模型了。</p><blockquote><p>理论上来说，任何你能见到的有监督模型，都可以用来做这个召回模型，比如FM／FFM／DNN等，<strong>常说的所谓“双塔”模型，指的其实是用户侧和物品侧特征分离分别打Embedding的结构而已，并非具体的模型。</strong></p></blockquote><p>模型召回具备自己独有的好处和优势，比如多路召回每路截断条数的超参个性化问题等会自然被消解掉。当然，它也会带来自己的问题，<strong>比较典型的是召回内容头部问题</strong>，因为之前多路，每路召回个数靠硬性截断，可以根据需要，保证你想要召回的，总能通过某一路拉回来；而由于换成了模型召回，面向海量物料库，<strong>排在前列得分高的可能聚集在几个物料分布比较多的头部领域</strong>。解决这个问题的方法包括比如训练数据对头部领域的降采样，减少某些领域主导，以及在模型角度鼓励多样性等不同的方法。</p><p>另外一点值得注意的是：<strong>如果在召回阶段使用模型召回，理论上也应该同步采用和排序模型相同的优化目标</strong>，尤其是如果排序阶段采用多目标优化的情况下，召回模型也应该对应采取相同的多目标优化。同理，如果整个流程中包含粗排模块，粗排也应该采用和精排相同的多目标优化，几个环节优化目标应保持一致。因为召回和粗排是精排的前置环节，<strong>否则，如果优化目标不一致，很可能会出现高质量精排目标，在前置环节就被过滤掉的可能，影响整体效果。</strong></p><h3 id="典型工作">典型工作</h3><ol type="1"><li>FM模型召回：<a href="#">Post not found: recommend_system/推荐系统召回四模型之：全能的FM模型</a></li><li>DNN双塔召回：Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</li></ol><h2 id="用户行为序列召回">用户行为序列召回</h2><p>用户在使用APP或者网站的时候，<strong>一般会产生一些针对物品的行为，比如点击一些感兴趣的物品，收藏或者互动行为，或者是购买商品等。</strong>而一般用户之所以会对物品发生行为，往往意味着这些物品是符合用户兴趣的，而不同类型的行为，可能代表了不同程度的兴趣。比如购买就是比点击更能表征用户兴趣的行为。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-d94e57b170233564c6bf10a89f0d7870_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>而用户行为过的物品序列，其实是具备表征用户兴趣的非常有价值的信息，而且这种兴趣表征，是细粒度的用户兴趣，所以对于刻画用户兴趣具备特别的价值。利用用户行为过的物品序列，来表征用户兴趣，具备很好的实用价值。</p><p>如果我们抽象地来看的话，利用用户行为过的物品序列对用户兴趣建模，本质上就是这么个过程：输入是用户行为过的物品序列，可以只用物品ID表征，也可以融入物品的Side Information比如名称，描述，图片等，现在我们需要一个函数Fun，这个函数以这些物品为输入，<strong>需要通过一定的方法把这些进行糅合到一个embedding里，而这个糅合好的embedding，就代表了用户兴趣。</strong>无论是在召回过程，还是排序过程，都可以融入用户行为序列。<strong>在召回阶段，我们可以用用户兴趣Embedding采取向量召回，而在排序阶段，这个embedding则可以作为用户侧的特征。</strong></p><p>所以，核心在于：这个物品聚合函数Fun如何定义的问题。<strong>这里需要注意的一点是：用户行为序列中的物品，是有时间顺序的。</strong>理论上，任何能够体现时序特点或特征局部性关联的模型，都比较适合应用在这里，典型的比如CNN、RNN、Transformer等，都比较适合用来集成用户行为序列信息。而目前的很多试验结果证明，GRU（RNN的变体模型）可能是聚合用户行为序列效果最好又比较简单的模型。当然，RNN不能并行的低效率，那是另外一个问题。</p><p>在召回阶段，如何根据用户行为序列打embedding，可以采取有监督的模型，比如Next Item Prediction的预测方式即可；也可以采用无监督的方式，比如物品只要能打出embedding，就能无监督集成用户行为序列内容，例如Sum Pooling。<strong>而排序侧，必然是有监督的模式。</strong>需要注意的是：排序侧表征用户特征的时候，可以只用用户行为过的物品序列，也可以混合用户其它特征，比如群体属性特征等一起来表征用户兴趣，方式比较灵活。比如DIEN，就是典型的采用混合模式的方法。</p><h3 id="典型工作-1">典型工作</h3><ol type="1"><li>GRU：Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</li><li>CNN：Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding</li><li>Transformer: Self-Attentive Sequential Recommendation</li></ol><h2 id="用户多兴趣拆分"><strong>用户多兴趣拆分</strong></h2><p>上文讲了利用<strong>用户行为物品序列</strong>，打出用户兴趣Embedding的做法。但是，另外一个现实是：<strong>用户往往是多兴趣的，比如可能同时对娱乐、体育、收藏感兴趣。</strong>这些不同的兴趣也能从用户行为序列的物品构成上看出来，比如行为序列中大部分是娱乐类，一部分体育类，少部分收藏类等。那么能否把用户行为序列物品中，这种不同类型的用户兴趣细分，而不是都笼统地打到一个用户兴趣Embedding里呢？用户多兴趣拆分就是解决这类更细致刻画用户兴趣的方向。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-b10c809b2c34d7044277cdfd3f9f30b3_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>用户多兴趣拆分，本质上是上文所叙述的用户行为序列打embedding方向的一个细化，无非上文说的是：以用户行为序列物品作为输入，通过一些能体现时序特点的模型，映射成一个用户兴趣embedding。<strong>而用户多兴趣拆分，输入是一样的，输出不同，无非由输出单独一个用户embedding，换成输出多个用户兴趣embedding而已。</strong>虽说道理如此，但是在具体技术使用方向上却不太一样，对于单用户兴趣embedding来说，只需要考虑信息有效集成即可；而对于多用户兴趣拆分来说，需要多做些事情，多做什么事情呢？<strong>本质上，把用户行为序列打到多个embedding上，实际它是个类似聚类的过程，就是把不同的Item，聚类到不同的兴趣类别里去。</strong>目前常用的拆分用户兴趣embedding的方法，主要是<strong>胶囊网络和Memory Network</strong>，但是理论上，很多类似聚类的方法应该都是有效的，所以完全可以在这块替换成你自己的能产生聚类效果的方法来做。</p><p>说到这里，有同学会问了：把用户行为序列拆分到不同的embedding里，有这个必要吗？反正不论怎样，即使是一个embedding，信息都已经包含到里面了，并未有什么信息损失问题呀。这个问题很好。我的个人感觉是：<strong>在召回阶段，把用户兴趣拆分成多个embedding是有直接价值和意义的，前面我们说过，召回阶段有时候容易碰到头部问题，就是比如通过用户兴趣embedding拉回来的物料，可能集中在头部优势领域中，造成弱势兴趣不太能体现出来的问题。</strong>而如果把用户兴趣进行拆分，每个兴趣embedding各自拉回部分相关的物料，则可以很大程度缓解召回的头部问题。所以我感觉，这种兴趣拆分，在召回阶段是很合适的，可以定向解决它面临的一些实际问题。</p><p>对于排序环节，是否有必要把用户兴趣拆分成多个，我倒觉得必要性不是太大，很难直观感受这样做背后发生作用的机理是怎样的。我能想到的，在排序环节使用多兴趣Embedding能发生作用的地方，好像有一个：因为我们在计算user对某个item是否感兴趣的时候，对于用户行为序列物品，<strong>往往计算目标item和行为序列物品的Attention是有帮助的，</strong>因为用户兴趣是多样的，物品Item的类型归属往往是唯一的，所以行为序列里面只有一部分物品和当前要判断的Item是类型相关的，这会对判断有作用，其它的无关物品其实没啥用，于是Attention就是必要的，可以减少那些无关物品对当前物品判断的影响。而当行为序列物品太多的时候，我们知道，Atttention计算是非常耗时的操作，如果我们把这种Attention计算，放到聚类完的几个兴趣embedding维度计算，无疑能极大提升训练和预测的速度。貌似这个优点还是成立的。</p><h3 id="典型工作-2">典型工作</h3><ol type="1"><li>召回：Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</li><li>排序：Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction</li></ol><h2 id="知识图谱融合召回"><strong>知识图谱融合召回</strong></h2><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-8d73fc677393bd7d5d41108b12f20013_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>推荐系统中，<strong>最核心的数据是用户对物品的行为数据</strong>，因为这直接表明了用户兴趣所在。如上图所示，如果把用户放在一侧，物品放在另一侧，若用户对某物品有行为产生，则建立一条边，这样就构建了用户-物品交互的二分图。其实，有另外一种隐藏在冰山之下的数据，那就是物品之间是有一些知识联系存在的，就是我们常说的知识图谱，而这类数据是可以考虑用来增强推荐效果的，尤其是对于用户行为数据稀疏的场景，或者冷启动场景。以上图例子说明，用户点击过电影“泰坦尼克号”，这是用户行为数据，我们知道，电影“泰坦尼克号”的主演是莱昂纳多，于是可以推荐其它由莱昂纳多主演的电影给这个用户。<strong>后面这几步操作，利用的是电影领域的知识图谱数据，通过知识图谱中的“电影1—&gt;主演—&gt;电影2”的图路径给出的推荐结果。</strong></p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-de3554a6fe4f1c92fb23addbc0288ddf_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>用于做推荐，一般有两大类知识图谱融合模式：<strong>知识图谱Embedding模式（KGE）及图路径模式。</strong></p><p>知识图谱Embedding模式首先根据TransE等对知识图谱进行Embedding化编码的工具，将节点和边转换成Embedding表征方式。然后根据用户行为过的物品，以及物品在知识图谱中的Embedding和知识图谱中其它知识embedding的距离，来扩展物品的信息含量，或者扩充用户行为数据，类似用已知的用户行为数据，在知识图谱辅助下进行外扩。知识图谱的Embedding模式在可解释性方面比较弱，因为知识之间的关联是通过Embedding计算出来的，不好解释为什么从这个知识跳到那个知识；</p><p>图路径模式则是根据物品属性之间的关联等人工定义好的所谓Meta-Path，也就是人工定义的知识图谱中知识的关联和传播模式，通过中间属性来对知识传播进行路径搭建，具体例子就是上面说的“电影1主演电影2”，这就是人事先定义好的Meta-Path，也就是人把自己的经验写成规则，来利用知识图谱里的数据。图路径模式在可解释性方面效果较好，因为是人工定义的传播路径，所以非常好理解知识传播关系，但是往往实际应用效果并不好。</p><p>知识图谱是一种信息拓展的模式，很明显，对知识进行近距离的拓展，这可能会带来信息补充作用，<strong>但是如果拓展的比较远，或者拓展不当，反而可能会引入噪音，这个道理好理解。</strong>所以，我的感觉是，知识图谱在排序侧并不是特别好用，<strong>如果想用的化，比较适合用户行为数据非常稀疏以及用户冷启动的场景，也就是说如果用户数据太少，需要拓展，可以考虑使用它。</strong>另外，知识图谱还有一个普适性的问题，完全通用的知识图谱在特定场景下是否好用，对此我是有疑问的，而专业性的知识图谱，还有一个如何构建以及构建成本问题；而且很多时候，所谓的知识传播，是可以通过添加属性特征来解决的，比如：电影1—&gt;主演—&gt;电影2这种知识传播路径，完全可以通过把主演作为电影这个实体的属性特征加入常规排序模型，来达到类似知识近距离传播的目的，所以感觉也不是很有必要在排序侧专门去做知识图谱拓展这种事情。</p><p>这种知识拓展，可能比较适合用在召回阶段，因为对于传统观点的召回来说，精准并不是最重要的目标，<strong>找出和用户兴趣有一定程度相关性但是又具备泛化性能的物品是召回侧的重点，所以可能知识图谱的模式更适合将知识图谱放在召回侧。</strong></p><p>当然，知识图谱有一个独有的优势和价值，那就是对于推荐结果的可解释性；比如推荐给用户某个物品，可以在知识图谱里通过物品的关键关联路径给出合理解释，这对于推荐结果的解释性来说是很好的，因为知识图谱说到底是人编码出来让自己容易理解的一套知识体系，所以人非常容易理解其间的关系。但是，在推荐领域目前的工作中，知识图谱的可解释性往往是和图路径方法关联在一起的，而Path类方法，很多实验证明了，在排序角度来看，是效果最差的一类方法。所以，我觉得，应该把知识图谱的可解释性优势从具体方法中独立出来，专门用它来做推荐结果的可解释性，这样就能独立发挥它自身的优势；</p><p>至于如何利用知识图谱做召回，其实很直观，比如可以采取如下的无监督学习版本：例如，推荐系统里对用户感兴趣的实体比如某个或者某些明星，往往是个单独的召回路，而可以根据用户的兴趣实体，通过知识图谱的实体Embedding化表达后（或者直接在知识图谱节点上外扩），通过知识外扩或者可以根据Embedding相似性，拓展出相关实体。形成另外一路相关性弱，但是泛化能力强的Knowledge融合召回路。</p><h3 id="典型工作-3">典型工作</h3><ol type="1"><li>KGAT: Knowledge Graph Attention Network for Recommendation</li><li>RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems</li></ol><h2 id="图神经网络模型召回"><strong>图神经网络模型召回</strong></h2><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-136c94fa2227dcd9b33188d4fbad15df_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>严格来说，知识图谱其实是图神经网络的一个比较特殊的具体实例，但是，<strong>知识图谱因为编码的是静态知识</strong>，而不是用户比较直接的行为数据，和具体应用距离比较远，这可能是导致两者在推荐领域表现差异的主要原因。</p><p>图神经网络中的图结构，可以是上面介绍知识图谱时候说过的“用户-物品”二分图，也可以是我们常见的有向图或者无向图，<strong>图中的节点是各种不同类型的物品及用户</strong>，边往往是通过用户行为建立起来的，可以是具体用户的具体行为，也可以是所有用户的群体统计行为，比如物品1—&gt;物品2可以有边，边还可以带上权重，如果越多的用户对物品1进行行为后对物品2进行行为，则这条边的权重越大。而且对于用户或者物品来说，其属性也可以体现在图中，比如对于一个微博，它的文本内容、图片内容、发布者等等属性都可以引入到图中，比如挂接到物品上，或者建立独立的节点也是可以的，这取决于具体的做法。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-8b415f36b04c6b2b9a5a0da99a946dec_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>图神经网络的最终目的是要通过一定技术手段，获得图中节点的embedding编码。最常用的embedding聚合工具是CNN，对于某个图节点来说，它的输入可以有两类信息，一类是自身的属性信息，比如上面举的微博的例子；另外一类是图结构信息，就是和当前节点有直接边关联的其它节点信息。通过CNN，可以对两类信息进行编码和聚合，形成图节点的embedding。通过CNN等信息聚合器，在图节点上进行计算，并反复迭代更新图节点的embedding，就能够最终获得可靠的图节点embedding信息，而这种迭代过程，其实体现的是远距离的节点将信息逐步通过图结构传递信息的过程，所以图结构是可以进行知识传递和补充的。</p><p>我们可以进一步思考下，<strong>图节点因为可以带有属性信息，比如物品的Content信息，所以明显这对于解决物品侧的冷启动问题有帮助；</strong>而因为它也允许知识在图中远距离进行传递，所以比如对于用户行为比较少的场景，可以形成知识传递和补充，这说明它也比较适合用于数据稀疏的推荐场景；<strong>另外一面，图中的边往往是通过用户行为构建的，而用户行为，在统计层面来看，本质上是一种协同信息，比如我们常说的“A物品协同B物品”，本质上就是说很多用户行为了物品A后，大概率会去对物品B进行行为；</strong></p><p>所以图具备的一个很好的优势是：<strong>它比较便于把协同信息、用户行为信息、内容属性信息等各种异质信息在一个统一的框架里进行融合，并统一表征为embedding的形式，这是它独有的一个优势，做起来比较自然。</strong>另外的一个特有优势，就是信息在图中的传播性，所以对于推荐的冷启动以及数据稀疏场景应该特别有用。</p><p>因为图神经网络，最终获得的往往是图中节点的embedding，这个embedding，就像我们上面说的，其实融合了各种异质信息。<strong>所以它是特别适合用来做召回的，比如拿到图网络中用户的embedding和物品embedding，可以直接用来做向量召回。</strong>当然，物品和用户的embedding也可以作为特征，引入排序模型中，这都是比较自然的。有些推荐场景也可以直接根据embedding计算user to user/item to item的推荐结果，比如看了又看这种推荐场景。</p><p>早期的图神经网络做推荐，因为需要全局信息，所以计算速度是个问题，往往图规模都非常小，不具备实战价值。而GraphSAGE则通过一些手段比如从临近节点进行采样等减少计算规模，加快计算速度，很多后期改进计算效率的方法都是从这个工作衍生的；而PinSage在GraphSAGE基础上（这是同一拨人做的），进一步采取大规模分布式计算，拓展了图计算的实用性，可以计算Pinterest的30亿规模节点、180亿规模边的巨型图，并产生了较好的落地效果。所以这两个工作可以重点借鉴一下。</p><blockquote><p>总体而言，图模型召回，是个很有前景的值得探索的方向。</p></blockquote><h3 id="典型工作-4">典型工作</h3><ol type="1"><li>GraphSAGE: Inductive Representation Learning on Large Graphs</li><li>PinSage: Graph Convolutional Neural Networks for Web-Scale Recommender Systems</li></ol><h1 id="排序模型技术演进趋势"><strong>排序模型技术演进趋势</strong></h1><p>排序环节是推荐系统最关键，也是最具有技术含量的部分，目前大多数推荐技术其实都聚焦在这块。下面我们从模型表达能力、模型优化目标以及特征及信息三个角度分述推荐排序模型的技术发展趋势。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-e31323d2a6402552de70d38c2fe343e3_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><ul><li>模型表达能力代表了模型<strong>是否具备充分利用有效特征及特征组合的能力</strong>，其中显示特征组合、新型特征抽取器、强化学习技术应用以及AutoML自动探索模型结构是这方面明显的技术进化方向；</li><li>模型优化目标则体现了我们希望推荐系统去做好什么，往往跟业务目标有关联，这里我们主要从技术角度来探讨，而多目标优化以及ListWise最优是目前最常见的技术进化方向，ListWise优化目标在排序阶段和重排阶段都可采用，我们把它放到重排部分去讲，这里主要介绍多目标优化；</li><li>从特征和信息角度，如何采用更丰富的新类型特征，以及信息和特征的扩充及融合是主要技术进化方向，用户长短期兴趣分离、用户行为序列数据的使用、图神经网络以及多模态融合等是这方面的主要技术趋势，因为用户行为序列以及图神经网络在召回部分介绍过，这些点同样可以应用在排序部分，所以这里不再叙述这两点。</li></ul><h2 id="显式特征组合"><strong>显式特征组合</strong></h2><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-ee243788c8280f64d6bb2702fa448c61_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>如果归纳下工业界CTR模型的演化历史的话，你会发现，<strong>特征工程及特征组合的自动化</strong>，一直是推动实用化推荐系统技术演进最主要的方向，而且没有之一。最早的LR模型，基本是人工特征工程及人工进行特征组合的，简单有效但是费时费力；再发展到LR+GBDT的高阶特征组合自动化，以及FM模型的二阶特征组合自动化；再往后就是DNN模型的引入，纯粹的简单DNN模型本质上其实是在FM模型的特征Embedding化基础上，添加几层MLP隐层来进行隐式的特征非线性自动组合而已。所谓隐式，意思是并没有明确的网络结构对特征的二阶组合、三阶组合进行直接建模，只是通过MLP，让不同特征发生交互，至于怎么发生交互的，怎么进行特征组合的，谁也说不清楚，这是MLP结构隐式特征组合的作用，<strong>当然由于MLP的引入，也会在特征组合时候考虑进入了特征间的非线性关系。</strong></p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-2a89b76aaf1098df6b9e67145dfb3854_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>明白了隐式特征组合，也就明白了什么是显式特征组合。就是在模型结构中，<strong>明确设计一些子网络或者子结构，对二阶特征组合、三阶特征组合，甚至更高阶的特征组合进行表征。</strong>比如说DeepFM，Deep部分就是个典型的DNN模型，这个大家基本都会用，而FM部分则是明确对特征二阶组合进行建模的子模型。这就是一个典型的显式二阶特征组合的模型。而如果进一步拓展的话，很自然想到的一个改进思路是：除了明确的把特征二阶组合做一个子结构，还可以把特征三阶特征组合，更高阶特征组合…..分别做一个模型子结构。融合这些子结构一起来做预测。这就是显式特征组合的含义，其实这条线的发展脉络是异常清晰的。典型的对高阶特征组合建模的比如Deep&amp; Cross、XDeepFM模型等，就是这么个思路。</p><p>在两年多前，我一直以为这个方向是CTR或者推荐模型的关键所在，而且可能如何简洁融入更多特征组合是最重要且最有前景的方向。但是后来发现可能错了，目前基本对这个方向改变了看法。目前我对这个方向的看法是：这个方向确实很重要，但是未来可挖掘的潜力和空间很有限，在这条路上继续行进，应该不会走得太远。原因在于，目前基本很多经验已经证明了，显式的二阶特征组合是非常重要的，三阶特征组合对不同类型任务基本都有帮助。四阶特征组合已经说不清楚是否有用了，跟数据集有关系，有些数据集合引入显式4阶特征组合有帮助，有些数据集合没什么用。至于更高阶的特征组合，明确用对应的子结构建模，基本已经没什么用了，甚至是负面作用。这说明：我们在实际做事情的时候，其实显式结构把三阶特征组合引入，已经基本足够了。这是为什么说这条路继续往后走潜力不大的原因。</p><h3 id="典型工作-5">典型工作</h3><ol type="1"><li>Deep&amp; Cross: Deep &amp; Cross Network for Ad Click Predictions</li><li>XDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems</li></ol><h2 id="特征抽取器的进化">特征抽取器的进化</h2><p>​ 从特征抽取器的角度来看，目前主流的DNN 排序模型，最常用的特征抽取器仍然是MLP结构，通常是两层或者三层的MLP隐层。<strong>目前也有理论研究表明：MLP结构用来捕获特征组合，是效率比较低下的，除非把隐层神经元个数急剧放大，而这又会急剧增加参数规模。</strong>与自然语言处理和图像处理比较，推荐领域的特征抽取器仍然处于非常初级的发展阶段。所以，<strong>探寻新型特征抽取器</strong>，对于推荐模型的进化是个非常重要的发展方向。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-45d02e9e9dfd4b95061e05d526a2491d_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>目前其它AI领域里，常用的特征抽取器包括图像领域的CNN、NLP领域的RNN和Transformer。这些新型特征抽取器，在推荐领域最近两年也逐步开始尝试使用，但是宏观地看，在推荐领域，<strong>相对MLP结构并未取得明显优势</strong>，这里的原因比较复杂。</p><p>CNN捕获局部特征关联是非常有效的结构，但是并不太适合做纯特征输入的推荐模型，因为推荐领域的特征之间，在输入顺序上并无必然的序列关系，基本属于人工定义随机顺序，<strong>而CNN处理这种远距离特征关系能力薄弱</strong>，所以并不是特别适合用来处理特征级的推荐模型。当然，对于行为序列数据，因为本身带有序列属性，所以CNN和RNN都是非常适合应用在行为序列结构上的，也是有一定应用历史的典型工具，但是对于没有序关系存在的特征来说，<strong>这两个模型的优势不能发挥出来，反而会放大各自的劣势，比如CNN的捕获远距离特征关系能力差的弱点，以及RNN的不可并行处理、所以速度慢的劣势等</strong>。</p><p>Transformer作为NLP领域最新型也是最有效的特征抽取器，从其工作机制来说，其实是非常适合用来做推荐的。为什么这么说呢？核心在于Transformer的<strong>Multi-Head Self Attention</strong>机制上。MHA结构在NLP里面，会对输入句子中任意两个单词的相关程度作出判断，而如果把这种关系套用到推荐领域，就是通过MHA来对任意特征进行特征组合，而上文说过，特征组合对于推荐是个很重要的环节，所以从这个角度来说，Transformer是特别适合来对特征组合进行建模的，一层Transformer Block代表了特征的二阶组合，更多的Transformer Block代表了更高阶的特征组合。但是，实际上如果应用Transformer来做推荐，其应用效果并没有体现出明显优势，甚至没有体现出什么优势，基本稍微好于或者类似于典型的MLP结构的效果。<strong>这意味着，可能我们需要针对推荐领域特点，对Transformer需要进行针对性的改造，而不是完全直接照搬NLP里的结构。</strong></p><h3 id="典型工作-6">典型工作</h3><ol type="1"><li>AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks</li><li>DeepFM: An End-to-End Wide &amp; Deep Learning Framework for CTR Prediction</li></ol><h2 id="automl在推荐的应用"><strong>AutoML在推荐的应用</strong></h2><p>AutoML在17年初开始出现，最近三年蓬勃发展，在比如图像领域、NLP领域等都有非常重要的研究进展，在这些领域，目前都能通过AutoML找到比人设计的效果更好的模型结构。AutoML作为算法方向最大的领域趋势之一，能否在不同领域超过人类专家的表现？这应该不是一个需要回答“会不会”的问题，而是应该回答“什么时间会”的问题。<strong>原因很简单，AutoML通过各种基础算子的任意组合，在超大的算子组合空间内，寻找性能表现最好的模型</strong>，几乎可以达到穷举遍历的效果，<strong>而人类专家设计出来的最好的模型，无非是算子组合空间中的一个点而已</strong>，而且人类专家设计的那个模型，是最好模型的可能性是很低的。如果设计精良的AutoML，一定可以自己找到超过目前人类专家设计的最好的那个模型，这基本不会有什么疑问，就像人类就算不是2017年，也会是某一年，下围棋下不过机器，道理其实是一样的，因为AutoML在巨大的算子组合空间里寻找最优模型，跟围棋在无穷的棋盘空间寻找胜利的盘面，本质上是一个事情。无非，现在AutoML的不成熟，体现在需要搜索的空间太大，比较消耗计算资源方面而已，随着技术的不断成熟，搜索成本越来越低，AutoML在很多算法方向超过人类表现只是个时间问题。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-085414cb1cc7edbce840c25f37229b09_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-ee9c2dcc7a23ac8a9d0c7da7bc2fef8a_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-03bb278fcb40ade16d82078e9fbf8eb1_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>在推荐领域，采用AutoML做网络结构的工作还很少，这里面有很多原因。由于我一直以来特别看好这个方向，<strong>所以在18年的时候，我们也尝试过利用AutoML来自动探索推荐系统的网络结构，这里非常简略地介绍下过程及结果</strong>（参考上面三图）。我们用ENAS作为网络搜索工具，设计了推荐领域网络结构自动探索的尝试。ENAS是个非常高效率的AutoML工具，可以做到单GPU半天搜索找到最优的网络结构，但是它定义的主要是CNN结构和RNN结构搜索。我们对ENAS进行了改造，包括算子定义，优化目标以及评价指标定义等。DNN排序模型因为模型比较单一，所以算子是比较好找的，我们定义了推荐领域的常用算子，然后在这些算子组合空间内通过ENAS自动寻找效果最优的网络结构，最终找到的一个表现最好的网络结构如下图所示：</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-35a6d77b9db6a6f544e8b595f03409e8_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>首先是特征onehot到embedding的映射，我们把这层固定住了，不作为模型结构探索因子。在特征embedding之上，有三个并行结构，其中两个是包含两个隐层的MLP结构，另外一个是特征双线性组合模块（Each Fields Type，具体含义可以参考下面的FibiNet）。<strong>其表现超过了DeepFM等人工结构，但是并未超过很多。</strong></p><p>总体而言，目前AutoML来做推荐模型，还很不成熟，找出的结构相对人工设计结构效果优势也不是太明显。这与DNN Ranking模型比较简单，算子类型太少以及模型深度做不起来也有很大关系。但是，我相信这里可以有更进一步的工作可做。</p><h3 id="典型工作-7">典型工作</h3><ol type="1"><li>ENAS结构搜索：</li><li>双线性特征组合: FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction</li></ol><h2 id="强化学习在推荐中的应用">强化学习在推荐中的应用</h2><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-dfa0c1e77f8a039acf49a57bf7e85ab5_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>​ 强化学习其实是比较吻合推荐场景建模的。一般而言，强化学习有几个关键要素：<strong>状态、行为以及回报</strong>。</p><blockquote><p>在推荐场景下，我们可以把状态St定义为用户的行为历史物品集合；推荐系统可选的行为空间则是根据用户当前状态St推荐给用户的推荐结果列表，这里可以看出，推荐场景下，用户行为空间是巨大无比的，这制约了很多无法对巨大行为空间建模的强化学习方法的应用；而回报呢，则是用户对推荐系统给出的列表内容进行互动的行为价值，比如可以定义点击了某个物品，则回报是1，购买了某个物品，回报是5….诸如此类。有了这几个要素的场景定义，就可以用典型的强化学习来对推荐进行建模。</p></blockquote><p>利用强化学习来做推荐系统，有几个显而易见的好处，比如：</p><ol type="1"><li><strong>比较容易对“利用-探索”（Exploitation/Exploration）建模。</strong>所谓利用，就是推荐给用户当前收益最大的物品，一般推荐模型都是优化这个目标；所谓探索，就是随机推给用户一些物品，以此来探测用户潜在感兴趣的东西。如果要进行探索，往往会牺牲推荐系统的当前总体收益，毕竟探索效率比较低，相当的通过探索渠道推给用户的物品，用户其实并不感兴趣，浪费了推荐位。但是，利用-探索的均衡，是比较容易通过调节强化学习的回报（Reward）来体现这个事情的，比较自然；</li><li><strong>比较容易体现用户兴趣的动态变化。</strong>我们知道，用户兴趣有长期稳定的，也有不断变化的。而强化学习比较容易通过用户行为和反馈的物品对应的回报的重要性，而动态对推荐结果产生变化，所以是比较容易融入体现用户兴趣变化这个特点的。</li><li><strong>有利于推荐系统长期收益建模。</strong>这点是强化学习做推荐最有优势的一个点。我们优化推荐系统，往往会有一些短期的目标比如增加点击率等，但是长期目标比如用户体验或者用户活跃留存等指标，一般不太好直接优化，<strong>而强化学习模型比较容易对长期收益目标来进行建模。</strong></li></ol><p>说了这么多优点，貌似强化学习应该重点投入去做，是吧？我的意见正好相反，觉得从实际落地角度来看，推荐系统里要尝试强化学习方法，如果你有这个冲动，最好还是抑制一下。主要原因是，貌似强化学习是技术落地投入产出比非常低的技术点。首先投入高，要想把强化学习做work，意味着有很多大坑在等着你去踩，数据怎么做、模型怎么写、回报怎么拍，长期收益怎么定义、建模并拆解成回报…….超大规模实际场景的用户和物品，强化学习这么复杂的模型，系统怎么才能真的落地并撑住流量…..很多坑在里面；其次，貌似目前看到的文献看，貌似很少见到真的把强化学习大规模推到真实线上系统，并产生很好的收益的系统。Youtube在最近一年做了不少尝试，虽说把系统推上线了，但是收益怎样不好说。而且，从另外一个角度看，做强化学习里面还是有不少Trick在，那些收益到底是系统带来的，还是Trick带来的，真还不太好说。所以，综合而言，目前看在强化学习做推荐投入，貌似还是一笔不太合算的买卖。当然，长远看，可能还是很有潜力的，但是貌似这个潜力还需要新的技术突破去推动和挖掘。</p><h3 id="典型工作-8">典型工作</h3><ol type="1"><li>Youtube: Top-K Off-Policy Correction for a REINFORCE Recommender System</li><li>Youtube: Reinforcement Learning for Slate-based Recommender Systems: A Tractable Decomposition and Practical Methodology</li></ol><h2 id="多目标优化"><strong>多目标优化</strong></h2><p><strong>推荐系统的多目标优化（点击，互动，时长等多个目标同时优化）严格来说不仅仅是趋势，而是目前很多公司的研发现状。</strong>对于推荐系统来说，不同的优化目标可能存在互相拉后腿的现象，比如互动和时长，往往拉起一个指标另外一个就会明显往下掉，而多目标旨在平衡不同目标的相互影响，尽量能够做到所有指标同步上涨，即使很难做到，也尽量做到在某个优化目标上涨的情况下，不拉低或者将尽量少拉低其它指标。多目标优化对于实用化的推荐系统起到了举足轻重的作用，这里其实是有很多工作可以做的，而如果多目标优化效果好，对于业务效果的推动作用也非常大。总而言之，多目标优化是值得推荐系统相关研发人员重点关注的技术方向。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-82cb7023099e6ea9196a78056ee909d2_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>从技术角度讲，多目标优化最关键的有两个问题。</p><ol type="1"><li><strong>第一个问题是多个优化目标的模型结构问题；</strong></li><li><strong>第二个问题是不同优化目标的重要性如何界定的问题。</strong></li></ol><p>既然存在多个优化目标，最简单直接的方式，也是目前最常用的方式是：每个优化目标独立优化，比如点击目标训练一个模型，互动目标训练一个模型，时长目标训练一个模型，各自优化，然后每个目标独立给实例预测打分，给每个目标设定权重值，各个目标打分加权求和线性融合，或者引入权重指数及根据目标关系引入非线性融合。<strong>这是目前最常见的落地方案。因为目标之间独立优化，模型是通过分数融合来实现多目标的，所以可以把这种多目标方式称作“Share-Nothing”结构。这个结构实现和优化方式很简单。</strong></p><p>与Share-Nothing结构相比，其实我们是可以让不同优化目标共享一部分参数的，一旦引入不同目标或者任务的参数共享，我们就踏入了Transfer Learning的领地了。那么为什么要共享参数呢？一方面出于计算效率考虑，不同目标共享结构能够提升计算效率；另外一点，假设我们有两类任务或者目标，其中一个目标的训练数据很充分，而另外一个目标的训练数据比较少；如果独立优化，训练数据少的目标可能很难获得很好的效果；如果两个任务相关性比较高的话，其实我们可以通过共享参数，达到把大训练数据任务的知识迁移给训练数据比较少的任务的目的，这样可以极大提升训练数据量比较少的任务的效果。<strong>Share-Bottom结构是个非常典型的共享参数的多目标优化结构，核心思想是在比如网络的底层参数，所有任务共享参数，而上层网络，不同任务各自维护自己独有的一部分参数，这样就能达成通过共享参数实现知识迁移的目的。</strong>但是，Share-Bottom结构有他的缺点：如果两个任务不那么相关的话，因为强制共享参数，所以可能任务之间相互干扰，会拉低不同目标的效果。MMOE针对Share-Bottom结构的局限进行了改进，核心思想也很简单，就是把底层全部共享的参数切分成小的子网络，不同任务根据自己的特点，学习配置不同权重的小网络来进行参数共享。这样做的话，即使是两个任务不太相关，可以通过不同的配置来达到模型解耦的目的，而如果模型相关性强，可以共享更多的子网络。明显这样的组合方式更灵活，所以对于MMOE来说，无论是相关还是不相关的任务，它都可以达到我们想要的效果。</p><p>上面介绍的是典型的不同多目标的模型结构，各自有其适用场景和特点。而假设我们选定了模型结构，仍然存在一个很关键的问题：不同优化目标权重如何设定？当然，我们可以根据业务要求，强制制定一些权重，比如视频网站可能更重视时长或者完播率等指标，那就把这个目标权重设置大一些。但是，我们讲过，有些任务之间的指标优化是负相关的，提升某个目标的权重，有可能造成另外一些指标的下跌。所以，如何设定不同目标权重，能够尽量减少相互之间的负面影响，就非常重要。这块貌似目前并没有特别简单实用的方案，很多实际做法做起来还是根据经验拍一些权重参数上线AB测试，费时费力。<strong>而如何用模型自动寻找最优权重参数组合就是一个非常有价值的方向，目前最常用的方式是采用帕累托最优的方案来进行权重组合寻优，这是从经济学引入的技术方案，未来还有很大的发展空间。</strong></p><h3 id="典型工作-9">典型工作</h3><ol type="1"><li>MMOE：Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</li><li>帕累托最优：A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation</li></ol><h2 id="多模态信息融合"><strong>多模态信息融合</strong></h2><blockquote><p>所谓模态，指的是不同类型的或者模态形式的信息存在形式，比如文本、图片、视频、音频、互动行为、社交关系等，都是信息不同的存在模态形式。</p></blockquote><p>​ 如果类比一下的话，就仿佛我们人类感知世界，也是用不同的感官来感知不同的信息类型的，比如视觉、听觉、味觉、触觉等等，就是接受不同模态类型的信息，而大脑会把多模态信息进行融合，来接受更全面更综合的世界知识。<strong>类似的，如何让机器学习模型能够接受不同模态类型的信息，并做知识和信息互补，更全面理解实体或者行为。</strong>这不仅仅是推荐领域的技术发现趋势，也是人工智能几乎所有方向都面临的重大发展方向，所以这个方向特别值得重视。</p><p>​ 多模态融合，<strong>从技术手段来说，本质上是把不同模态类型的信息，通过比如Embedding编码，映射到统一的语义空间内，使得不同模态的信息，表达相同语义的信息完全可类比。</strong>比如说自然语言说的单词“苹果”，和一张苹果的图片，应该通过一定的技术手段，对两者进行信息编码，比如打出的embedding，相似度是很高的，这意味着不同模态的知识映射到了相同的语义空间了。这样，你可以通过文本的苹果，比如搜索包含苹果的照片，诸如此类，可以玩出很多新花样。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-d48347e383a32c18785a9f504196cb91_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>在推荐场景下，多模态融合其实不是个很有难度的算法方向，大的技术框架仍然遵循目前主流的技术框架，比如DNN Ranking。为了体现多模态集成的目标，可以在User侧或者Item侧，把多模态信息作为新的特征融入，比如加入CNN特征抽取器，把商品图片的特征抽取出来，作为商品侧的一种新特征，不同模态的融入，很可能意味着找到对应的特征抽取器，以新特征的方式融入，而有监督学习的学习目标会指导特征抽取器抽出那些有用的特征。所以，你可以看到，如果在推荐里融入多模态，从算法层面看，并不难，它的难点其实在它处；本质上，多模态做推荐，如果说难点的话，难在工程效率。因为目前很多模态的信息抽取器，比如图片的特征抽取，用深层ResNet或者ReceptionNet，效果都很好，但是因为网络层深太深，抽取图片特征的速度问题就是多模态落地面临的主要问题。所以，本质上，在推荐领域应用多模态，看上去其实是个工程效率问题，而非复杂的算法问题。而且，如果融合多模态的话，离开DNN模型，基本是不现实的。在这点上，可以比较充分体现DNN模型相对传统模型的绝对技术优势。</p><p><strong>多模态信息融合，不仅仅是排序端的一个发展方向，在召回侧也是一样的，比如用用户点击过的图片，作为图片类型的新召回路，或者作为模型召回的新特征。</strong>明显这种多模态融合是贯穿了推荐领域各个技术环节的。</p><h3 id="典型工作-10">典型工作</h3><ol type="1"><li>DNN召回：Collaborative Multi-modal deep learning for the personalized product retrieval in Facebook Marketplace</li><li>排序：Image Matters: Visually modeling user behaviors using Advanced Model Server</li></ol><h2 id="长期兴趣短期兴趣分离"><strong>长期兴趣／短期兴趣分离</strong></h2><p>对于推荐系统而言，准确描述用户兴趣是非常重要的。目前常用的描述用户兴趣的方式主要有两类。一类是以用户侧特征的角度来表征用户兴趣，也是最常见的；另外一类是以用户发生过行为的物品序列作为用户兴趣的表征。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-e859baf16914fdbec31ca005401ed095_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>我们知道，用户兴趣其实是可以继续细分的，一种典型的分法就是划分为长期兴趣和短期兴趣。长期兴趣代表用户长久的比较稳定的偏好；而短期兴趣具有不断变化等特点。两者综合，可以从稳定性和变化性这个维度来表征用户偏好。</p><p>最近推荐系统在排序侧模型的演进方向来说，把用户长期兴趣和短期兴趣分离并各自建立模型是个技术小趋势。那么用什么信息作为用户的短期兴趣表征？什么信息作为用户的长期兴趣表征呢？各自又用什么模型来集成这些信息呢？这是这个趋势的三个关键之处。</p><p>目前的常用做法是：用户短期兴趣往往使用用户点击（或购买，互动等其它行为类型）过的物品序列来表征，尤其对于比较活跃的用户，用点击序列更能体现短期的含义，因为出于工程效率的考虑，如果用户行为序列太长，往往不会都拿来使用，而是使用最近的K个行为序列中的物品，来表征用户兴趣，而这明显更含有短期的含义；因为点击序列具备序列性和时间属性，所以对于这类数据，用那些能够刻画序列特性或者物品局部相关性的模型比较合适，比如RNN／CNN和Transformer都比较适合用来对用户短期兴趣建模。</p><p>而用户长期兴趣如何表征呢？我们换个角度来看，其实传统的以特征作为用户兴趣表征的方法，其中部分特征就是从用户长期兴趣出发来刻画的，比如群体人群属性，是种间接刻画用户长期兴趣的方法，再比如类似用户兴趣标签，是种用用户行为序列物品的统计结果来表征用户长期兴趣的方法。这些方法当然可以用来刻画用户长期兴趣，但是往往粒度太粗，所以我们其实需要一个比较细致刻画用户长期兴趣的方式和方法。目前在对长短期兴趣分离的工作中，关于如何刻画用户长期兴趣，往往还是用非常简单的方法，就是用UID特征来表征用户的长期兴趣，通过训练过程对UID进行Embedding编码，以此学习到的UID Embedding作为用户长期兴趣表征，而用户行为序列物品作为用户短期兴趣表征。当然，UID如果用一些其它手段比如矩阵分解获得的Embedding初始化，也是很有帮助的。</p><p>总而言之，用户长期兴趣和短期兴趣的分离建模，应该还是有意义的。长期兴趣目前建模方式还比较简单，这里完全可以引入一些新方法来进行进一步的兴趣刻画，而且有很大的建模空间。</p><h3 id="典型工作-11">典型工作：</h3><ol type="1"><li>Neural News Recommendation with Long- and Short-term User Representations</li><li>Sequence-Aware Recommendation with Long-Term and Short-Term Attention Memory Networks</li></ol><h1 id="重排技术演进趋势"><strong>重排技术演进趋势</strong></h1><p>在重排环节，常规的做法，这里是个策略出没之地，就是集中了各种业务和技术策略。比如为了更好的推荐体验，这里会加入去除重复、结果打散增加推荐结果的多样性、强插某种类型的推荐结果等等不同类型的策略。</p><p>按理说，这块没什么可讲的。<strong>但是，如果从技术发展趋势角度看，重排阶段上模型，来代替各种花样的业务策略，是个总体的大趋势。</strong></p><h2 id="list-wise重排序">List Wise重排序</h2><p>关于List Wise排序，可以从两个角度来说，一个是优化目标或损失函数；一个是推荐模块的模型结构。</p><p>推荐系统里Learning to Rank做排序，我们知道常见的有三种优化目标：Point Wise、Pair Wise和List Wise。所以我们首先应该明确的一点是：List Wise它不是指的具体的某个或者某类模型，而是指的模型的优化目标或者损失函数定义方式，理论上各种不用的模型都可以使用List Wise损失来进行模型训练。最简单的损失函数定义是Point Wise，就是输入用户特征和单个物品特征，对这个物品进行打分，物品之间的排序，就是谁应该在谁前面，不用考虑。明显这种方式无论是训练还是在线推理，都非常简单直接效率高，但是它的缺点是没有考虑物品直接的关联，而这在排序中其实是有用的。Pair Wise损失在训练模型时，直接用两个物品的顺序关系来训练模型，就是说优化目标是物品A排序要高于物品B，类似这种优化目标。其实Pair Wise的Loss在推荐领域已经被非常广泛得使用，比如BPR损失，就是典型且非常有效的Pair Wise的Loss Function，经常被使用，尤其在隐式反馈中，是非常有效的优化目标。List Wise的Loss更关注整个列表中物品顺序关系，会从列表整体中物品顺序的角度考虑，来优化模型。在推荐中，List Wise损失函数因为训练数据的制作难，训练速度慢，在线推理速度慢等多种原因，尽管用的还比较少，但是因为更注重排序结果整体的最优性，所以也是目前很多推荐系统正在做的事情。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/v2-79f10fab12c1e74d02e3d1c2908e180e_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>从模型结构上来看。因为重排序模块往往是放在精排模块之后，而精排已经对推荐物品做了比较准确的打分，所以往往重排模块的输入是精排模块的Top得分输出结果，也就是说，是有序的。而精排模块的打分或者排序对于重排模块来说，是非常重要的参考信息。于是，这个排序模块的输出顺序就比较重要，而能够考虑到输入的序列性的模型，自然就是重排模型的首选。我们知道，最常见的考虑时序性的模型是RNN和Transformer，所以经常把这两类模型用在重排模块，这是很自然的事情。一般的做法是：排序Top结果的物品有序，作为RNN或者Transformer的输入，RNN或者Transformer明显可以考虑在特征级别，融合当前物品上下文，也就是排序列表中其它物品，的特征，来从列表整体评估效果。RNN或者Transformer每个输入对应位置经过特征融合，再次输出预测得分，按照新预测的得分重新对物品排序，就完成了融合上下文信息，进行重新排序的目的。</p><p>尽管目前还没看到CNN做重排的方法，但是从机制上来说，明显CNN也是比较适合用来做重排环节模型的，感兴趣的同学可以试一试。当然，前面说的强化学习，也是非常适合用在List Wise优化的，目前也有不少相关工作出现。</p><h3 id="典型工作-12">典型工作</h3><ol type="1"><li>Personalized Re-ranking for Recommendation</li><li>Learning a Deep Listwise Context Model for Ranking Refinement</li></ol>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
          <category> recommend system </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
            <tag> recommend system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简介</title>
      <link href="/blog_cn/2020/09/12/reinforcement_learning/%E7%AE%80%E4%BB%8B/"/>
      <url>/blog_cn/2020/09/12/reinforcement_learning/%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>强化学习是机器学习的一个分支。而机器学习可以简单的分为强化学习、监督学习与无监督学习等。在解决某一个具体任务的时候，我们常常会采用多种技术的结合。所以这里我将会复习和整理一下强化学习的部分内容，后面也会针对深度学习进行整理。</p><p>下面是音乐测试</p><p>下面简单介绍一下这一系列文章。</p>]]></content>
      
      
      <categories>
          
          <category> reinforcement learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> introduction </tag>
            
            <tag> reinforcement learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习入门</title>
      <link href="/blog_cn/2020/09/12/reinforcement_learning/courses/NKU_RL_COURSE/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/"/>
      <url>/blog_cn/2020/09/12/reinforcement_learning/courses/NKU_RL_COURSE/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>随便写写吧</p>]]></content>
      
      
      <categories>
          
          <category> reinforcement learning </category>
          
          <category> course </category>
          
          <category> nku_gx </category>
          
      </categories>
      
      
        <tags>
            
            <tag> introduction </tag>
            
            <tag> reinforcement learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo_Github建站备忘录</title>
      <link href="/blog_cn/2020/09/12/hexo_usage/Hexo+Github%E5%BB%BA%E7%AB%99%E5%A4%87%E5%BF%98%E5%BD%95/"/>
      <url>/blog_cn/2020/09/12/hexo_usage/Hexo+Github%E5%BB%BA%E7%AB%99%E5%A4%87%E5%BF%98%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><h1 id="如何在hexo的博文中引用自己的文章">如何在Hexo的博文中引用自己的文章</h1><p>在用Hexo来写博文时，有时需要应用自己写的另一篇文章。如果用标准的Markdown的引用语法来写，就必须知道Hexo将博文转换以后的命令规则，比如默认的规则是”/年/月/日/文章名”, 但这样做显然缺乏灵活性和可维护性。</p><p>其实，我们可以使用Hexo内置的标签语法来文章对内部博文的引用，语法如下：</p><a id="more"></a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% post_link 文件名(不要后缀) 文章别名(可选) %&#125;</span><br></pre></td></tr></table></figure><p>其中文件名指的是博文的文件名，例如你的博客中有一篇文件名为HelloWorld.md的博文，那你就可以使用:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% post_link HelloWorld %&#125;</span><br></pre></td></tr></table></figure><p>特别注意如果有文件夹应该类似下面这么写(post的索引以_posts为根目录的)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FM模型召回：&#123;% post_link recommend_system/推荐系统召回四模型之：全能的FM模型 %&#125;</span><br></pre></td></tr></table></figure><p>来引用，Hexo会自动讲HelloWorld这篇博文的标题(title)显示在文章中，并带上正确的链接。当然，你也可以给链接使用一个另外的名字，比如”我的HelloWorld”, 那你就可以向下面这样用:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% post_link HelloWorld 我的HelloWorld %&#125;</span><br></pre></td></tr></table></figure><h1 id="如何写一篇博文">如何写一篇博文</h1><ol type="1"><li><code>hexo post 'name of your blog'</code></li><li>hexo g 本地生成</li><li>hexo d 上传到github，部署</li><li>hexo sever --debug 可以先看看有没有报错</li></ol><h1 id="hexo-next主题开启字数统计及阅读时长">Hexo Next主题开启字数统计及阅读时长</h1><blockquote><p>注：Next主题版本 v6.3.0，以前的版本好像不是这么配置的</p></blockquote><h2 id="安装-hexo-symbols-count-time">安装 hexo-symbols-count-time</h2><blockquote><p>注：只需要在hexo下安装此插件（ yarn npm 随意）</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm add hexo-symbols-count-time</span><br></pre></td></tr></table></figure><h2 id="配置">配置</h2><h3 id="hexo-_config.yaml主文件夹那个">hexo _config.yaml(主文件夹那个)</h3><blockquote><p>这是显示的基础配置，next主题初始配置默认显示了，只需要hexo这边配置即可，注：修改此配置需要重启服务才能更新</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">symbols_count_time:</span><br><span class="line">  symbols: true # 文章字数</span><br><span class="line">  time: true # 阅读时长</span><br><span class="line">  total_symbols: true # 所有文章总字数</span><br><span class="line">  total_time: true # 所有文章阅读中时长</span><br></pre></td></tr></table></figure><h3 id="next-_config.yaml主题下面那个">next _config.yaml(主题下面那个)</h3><blockquote><p>修改此配置无需要重启服务即可更新</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">symbols_count_time:</span><br><span class="line">  separated_meta: true  # 是否换行显示 字数统计 及 阅读时长</span><br><span class="line">  item_text_post: true  # 文章 字数统计 阅读时长 使用图标 还是 文本表示</span><br><span class="line">  item_text_total: false # 博客底部统计 字数统计 阅读时长 使用图标 还是 文本表示</span><br><span class="line">  awl: 4</span><br><span class="line">  wpm: 275</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FM模型在推荐系统中的应用</title>
      <link href="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/"/>
      <url>/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-71291ff4772c08f1bc15be2c1d6a3b34_1440w.jpg" alt="v2-71291ff4772c08f1bc15be2c1d6a3b34_1440w"><figcaption aria-hidden="true">v2-71291ff4772c08f1bc15be2c1d6a3b34_1440w</figcaption></figure><p>既然你点开这篇文章了，我假设你是在某司做推荐系统的算法工程师。这个假设的正确率我估计大约在20%左右，因为根据我的经验，80%的算法工程师是很博爱的，只要标题里带有“模型／算法／深度学习／震惊/美女….”等词汇，他们都会好奇地点开看三秒，然后失望地关掉，技术性越强的反而越容易被关掉，很可能撑不过三秒。我说得没错吧？嘿嘿。为了骗点击，关于本文标题，其实我内心冲动里最想写下的震惊部风格标题是这样的：“连女神级美女程序媛看了都震惊！FM模型居然能够做这么大规模推荐系统的召回！！！”，然后打开文章后，文章配上的背景音乐缓缓地传来“路灯下昏黄的剪影,越走越漫长的林径…….”</p><a id="more"></a><p>嗯，好吧，我承认连我自己也忍不了上面的场景，主要是这首歌我还挺喜欢的，单曲循环快半个月了，标题风格比较毁歌的意境。请收拾好您此刻看到上述标题后接近崩溃的心情，不开玩笑了。让我再次活回到幻想中，就勉强假设你是位推荐算法工程师吧，您坚持说您不是？别谦虚，您很快就是了，请立即辞职去申请相关工作……如果您真的是推荐工程师，那么首先我想揪住您问个问题：一说起推荐模型或者推荐场景下的排序模型，您脑子里第一个念头冒出的模型是哪个或哪几个？</p><p>如果你第一念头冒出来的仍然是SVD／矩阵分解啥的，那么明显你还停留在啃书本的阶段，实践经验不足；如果你第一念头是LR模型或者GBDT模型，这说明你是具备一定实践经验的算法工程师，但是知识更新不足。现在都9102年了，我们暂且把Wide&amp;Deep/DeepFM这些模型抛开不提，因为在大规模场景下想要把深度推荐模型高性价比地用好发挥作用其实并不容易。我们退而求其次，如果现在您仍然不能在日常工作中至少尝试着用FM模型来搞事情，那只能说明一定概率下（30%到90%？），您是在技术方面对自我没有太高要求的算法工程师，未来您的技术之路走起来，我猜可能会比较辛苦和坎坷，这里先向身处2025年的另一位您道声辛苦啦。这是我对您的算法工程师之路的一个预测，至于这个预测准不准，往后若干年的经历以及时间会告诉您正确答案，当然我个人觉得付出的这个代价可能有点高。</p><p>假设你第一念头是在排序阶段使用FM模型、GBDT+LR模型、DNN模型，这说明你算是紧追技术时代发展脉络的技术人员，很好。那么，单独给你准备的更专业的新问题来了，请问：树上七只猴…..嗯，跑偏了，其实我想问的是：我们日常看到的推荐系统长什么样子，我相信你脑子里很清楚，但是能否打破常规？比如下列两个不太符合常规做法的技术问题，您可以考虑考虑：</p><p>第一个问题：我们知道在个性化推荐系统里，第一个环节一般是召回阶段，而召回阶段工业界目前常规的做法是多路召回，每一路召回可能采取一个不同的策略。那么打破常规的思考之一是：<strong>是否我们能够使用一个统一的模型，将多路召回改造成单模型单路召回策略？</strong>如果不能，那是为什么？如果能，怎么做才可以？这样做有什么好处和坏处？</p><p>第二个问题：我们同样知道，目前实用化的工业界的推荐系统通常由两个环节构成，召回阶段和排序阶段，那么为什么要这么划分？它们各自的职责是什么？打破常规的另外一个思考是：<strong>是否存在一个模型，这个模型可以将召回阶段和排序阶段统一起来，就是把两阶段推荐环节改成单模型单环节推荐流程</strong>？就是说靠一个模型一个阶段把传统的两阶段推荐系统做的事情一步到位做完？如果不能，为什么不能？如果能，怎么做才可以？什么样的模型才能担当起这种重任呢？而在现实世界里是否存在这个模型？这个思路真的可行吗?</p><p>上面列的两个非常规问题，18年年末我自己也一直在思考，有些初步的思考结论，所以计划写四篇文章形成一个专题，主题集中在推荐系统的统一召回模型方面，也就是第一个问题，同时兼谈下第二个问题，每篇文章会介绍一个或者一类模型，本文介绍的是FM模型。这个系列，我春节期间写完了3篇，等我四篇都写完后，会陆续发出来，供感兴趣的“点开看三秒”同学参考。</p><p>不过这里需要强调一点：关于这两个问题，因为非常规，网上也也没有见到过类似的问题，说法及解决方案，所以没什么依据，文章写的只是我个人的思考结果，是否真能顺利落地以及落地效果存疑，还请谨慎参考。不过，我觉得从目前算法的发展趋势以及硬件条件的快速发展情况来看，单阶段推荐模型从理论上是可行的。我会陆续给出几个方案，建议从事中小型推荐业务的同学可以快速尝试一下。</p><p>下面进入正题，我会先简单介绍下推荐系统整体架构以及多路召回的基本模式，然后说明下FM模型，之后探讨FM模型是否能够解决上面提到的两个非常规问题。</p><h2 id="工业推荐系统整体架构">工业推荐系统整体架构</h2><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-979ee06266d5d9b21664219d37a4f164_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>一个典型的工业级推荐系统整体架构可以参考上图，一般分为<strong>在线部分，近线部分和离线部分</strong>。</p><p>对于在线部分来说，一般要经历几个阶段。首先通过召回环节，将给用户推荐的物品降到千以下规模；如果召回阶段返回的物品还是太多，可以加入粗排阶段，这个阶段是可选的，粗排可以通过一些简单排序模型进一步减少往后续环节传递的物品；再往后是精排阶段，这里可以使用复杂的模型来对少量物品精准排序。对某个用户来说，即使精排推荐结果出来了，一般并不会直接展示给用户，可能还要上一些业务策略，比如去已读，推荐多样化，加入广告等各种业务策略。之后形成最终推荐结果，将结果展示给用户。</p><p>对于近线部分来说，主要目的是实时收集用户行为反馈，并选择训练实例，实时抽取拼接特征，并近乎实时地更新在线推荐模型。这样做的好处是用户的最新兴趣能够近乎实时地体现到推荐结果里。</p><p>对于离线部分而言，通过对线上用户点击日志的存储和清理，整理离线训练数据，并周期性地更新推荐模型。对于超大规模数据和机器学习模型来说，往往需要高效地分布式机器学习平台来对离线训练进行支持。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-cf5154bab9edd7e83ca9976789a6c423_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>因为粗排是可选的，对于大多数推荐系统来说，通常在线部分的主体分为两个阶段就够，第一个阶段是召回，第二个阶段是排序。因为个性化推荐需要给每个用户展现不同的信息流或者物品流，而对于每个用户来说，可供推荐的物品，在具备一定规模的公司里，是百万到千万级别，甚至上亿。所以对于每一个用户，如果对于千万级别物品都使用先进的模型挨个进行排序打分，明显速度上是算不过来的，资源投入考虑这么做也不划算。从这里可以看出，召回阶段的主要职责是：从千万量级的候选物品里，采取简单模型将推荐物品候选集合快速筛减到千级别甚至百级别，这样将候选集合数量降下来，之后在排序阶段就可以上一些复杂模型，细致地对候选集进行个性化排序。</p><p>从上面在线推荐两阶段任务的划分，我们可以看出，召回阶段因为需要计算的候选集合太大，所以要想速度快，就只能上简单模型，使用少量特征，保证泛化能力，尽量让用户感兴趣的物品在这个阶段能够找回来；而排序阶段核心目标是要精准，因为它处理的物品数据量小，所以可以采用尽可能多的特征，使用比较复杂的模型，一切以精准为目标。</p><h2 id="多路召回">多路召回</h2><p>目前工业界推荐系统的召回阶段一般是怎么做的呢？可以用一句江湖气很重的话来总结，请您系好安全带坐稳，怕吓到您，这句话就是：“一只穿云箭，千军万马来相见”。听起来霸气十足是吧？我估计看过古惑仔电影的都熟悉这句话，黑帮集结打群架的时候喜欢引用这句名言，以增加气势，自己给自己打气。如果和推荐系统对应起来理解，这里的“穿云箭”就是召回系统，而千军万马就是各路花式召回策略。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-4a73106e581ad1d547343197752e028d_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>目前工业界的推荐系统，在召回阶段，一般都采取多路召回策略。上图展示了一个简化版本的例子，以微博信息流排序为例，不同业务召回路数不太一样，但是常用的召回策略，基本都会包含，比如兴趣标签，兴趣Topic，兴趣实体，协同过滤，热门，相同地域等，多者几十路召回，少者也有7／8路召回。</p><p>对于每一路召回，会拉回K条相关物料，这个K值是个超参，需要通过线上AB测试来确定合理的取值范围。如果你对算法敏感的话，会发现这里有个潜在的问题，如果召回路数太多，对应的超参就多，这些超参组合空间很大，如何设定合理的各路召回数量是个问题。另外，如果是多路召回，这个超参往往不太可能是用户个性化的，而是对于所有用户，每一路拉回的数量都是固定的，这里明显有优化空间。按理说，不同用户也许对于每一路内容感兴趣程度是不一样的，更感兴趣的那一路就应该多召回一些，所以如果能把这些超参改为个性化配置是很好的，但是多路召回策略下，虽然也不是不能做，但是即使做，看起来还是很Trick的。有什么好办法能解决这个问题吗？有，本文后面会讲。</p><hr><h2 id="推荐模型简介">推荐模型简介</h2><h3 id="什么是fm模型">什么是FM模型</h3><p>什么是FM模型呢？我隐约意识到这个问题在很多人看起来好像有点过于简单，因为一说起FM，开车的朋友们估计都熟悉，比如FM1039交通台家喻户晓，最近应该经常听到交通台这么提醒大家吧：“…春节返程高峰，北京市第三交通委提醒您：道路千万条，安全第一条……”</p><p>一想到有可能很多人这么理解FM，我的眼泪就不由自主流了下来，同时对他们在心理上有种莫名的亲切感，为什么呢？不是说“缩写不规范，亲人两行泪”么。下面我郑重地给各位介绍下，FM英文全称是“Factorization Machine”，简称FM模型，中文名“因子分解机”。</p><p>FM模型其实有些年头了，是2010年由Rendle提出的，但是真正在各大厂大规模在CTR预估和推荐领域广泛使用，其实也就是最近几年的事。</p><p>FM模型比较简单，网上介绍的内容也比较多，细节不展开说它了。不过我给个个人判断：我觉得FM是推荐系统工程师应该熟练掌握和应用的必备算法，即使你看很多DNN版本的排序模型，你应该大多数情况会看到它的影子，原因其实很简单：特征组合对于推荐排序是非常非常重要的，而FM这个思路已经很简洁优雅地体现了这个思想了（主要是二阶特征组合）。DNN模型一样离不开这个特点，而MLP结构是种低效率地捕获特征组合的结构，所以即使是深度模型，目前一样还离不开类似FM这个能够直白地直接去组合特征的部分。这是你会反复发现它的原因所在，当然也许是它本人，也许不一定是它本人，但是一定是它的变体。</p><p>既然谈到这里了，那顺手再多谈谈推荐排序模型。目前具备实用化价值的DNN版本的CTR模型一般采用MLP结构，看着远远落后CV/NLP的特征抽取器的发展水平，很容易让人产生如下感觉：CTR的DNN模型还处于深度学习原始社会阶段。那这又是为什么呢？因为CNN的特性天然不太适合推荐排序这个场景（为什么？您可以思考一下。为了预防某些具备某种独特个性特征的同学拿个别例子说事情，我先提一句：请不要跟我说某个已有的看上去比较深的CNN CTR模型，你自己试过效果如何再来说。这算是我的预防性回怼或者是假设性回怼，哈哈）。RNN作为捕捉用户行为序列，利用时间信息的辅助结构还行，但是也不太适合作为CTR预估或者推荐排序的主模型（为什么？您可以思考一下，关于这点，我的看法以后有机会会提）。好像剩下的选择不多了（Transformer是很有希望的，去年年中左右，我觉得Self attention应该是个能很好地捕捉特征组合（包括二阶／三阶…多阶）的工具，于是，我们微博也尝试过用self attention和transformer作为CTR的主体排序模型，非业务数据测试的，当时测试效果和DeepFM等主流模型效果差不太多。我现在回头看，很可能是哪些细节没做对，当时觉得没有特别的效果优势，于是没再继续尝试这个思路。当然貌似18年下半年已经冒出几篇用Transformer做CTR排序模型的论文了，我个人非常看好这个CTR模型进化方向），于是剩下的选择貌似只有MLP了，意思是：对于CTR或者推荐排序领域来说，不是它不想进入模型共产主义阶段，是大门关得太紧，它进不去，于是只能在MLP这个门槛徘徊。在深度学习大潮下，从模型角度看，确实跟很多领域比，貌似推荐领域远远落后，这个是事实。我觉得主要原因是它自身的领域特点造成的，它可能需要打造适合自身特点的DNN排序模型。就像图像领域里有Resnet时刻，NLP里面有Bert时刻，我觉得推荐排序深度模型目前还没有，现在和未来也需要这个类似的高光时刻，而这需要一个针对它特性改造出的新结构，对此我是比较乐观的，我预感这个时刻一年之内还无法出现，但是很可能已经在路上，距离我们不远了。</p><p>又说远了，本来我们主题是召回，说到排序模型里去了，我往主车道走走。上面本来是要强调好好学好好用FM模型的。下面我从两个角度来简单介绍下FM模型，一个角度是从特征组合模型的进化角度来讲；另外一个角度从协同过滤模型的进化角度来讲。FM模型就处于这两类模型进化的交汇口。</p><h3 id="从lr到svm再到fm模型">从LR到SVM再到FM模型</h3><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-bc6a391f231d93e4f7895931b2b4dd4e_1440w-9973338.jpg" alt="v2-bc6a391f231d93e4f7895931b2b4dd4e_1440w"><figcaption aria-hidden="true">v2-bc6a391f231d93e4f7895931b2b4dd4e_1440w</figcaption></figure><p>LR模型是CTR预估领域早期最成功的模型，大多工业推荐排序系统采取LR这种“线性模型+人工特征组合引入非线性”的模式。因为LR模型具有简单方便易解释容易上规模等诸多好处，所以目前仍然有不少实际系统仍然采取这种模式。但是，LR模型最大的缺陷就是人工特征工程，耗时费力费人力资源，那么能否将特征组合的能力体现在模型层面呢？</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-ac4ddbb05780015aff1567a590b46cc3_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>其实想达到这一点并不难，如上图在计算公式里加入二阶特征组合即可，任意两个特征进行组合，可以将这个组合出的特征看作一个新特征，融入线性模型中。而组合特征的权重可以用来表示，和一阶特征权重一样，这个组合特征权重在训练阶段学习获得。其实这种二阶特征组合的使用方式，和多项式核SVM是等价的。虽然这个模型看上去貌似解决了二阶特征组合问题了，但是它有个潜在的问题：它对组合特征建模，泛化能力比较弱，尤其是在大规模稀疏特征存在的场景下，这个毛病尤其突出，比如CTR预估和推荐排序，这些场景的最大特点就是特征的大规模稀疏。所以上述模型并未在工业界广泛采用。那么，有什么办法能够解决这个问题吗？</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-b7764d67b0d5b5ef791848a74316c2aa_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>于是，FM模型此刻可以闪亮登场了。如上图所示，FM模型也直接引入任意两个特征的二阶特征组合，和SVM模型最大的不同，在于特征组合权重的计算方法。FM对于每个特征，学习一个大小为k的一维向量，于是，两个特征<span class="math inline">\(x_i\)</span>和<span class="math inline">\(x_j\)</span> 的特征组合的权重值，通过特征对应的向量<span class="math inline">\(v_i\)</span>和 和 <span class="math inline">\(v_j\)</span> 的内积$ v_i v_j $来表示。这本质上是在对特征进行embedding化表征，和目前非常常见的各种实体embedding本质思想是一脉相承的，但是很明显在FM这么做的年代（2010年），还没有现在能看到的各种眼花缭乱的embedding的形式与概念。所以FM作为特征embedding，可以看作当前深度学习里各种embedding方法的老前辈。当然，FM这种模式有它的前辈模型吗？有，等会会谈。其实，和目前的各种深度DNN排序模型比，它仅仅是少了2层或者3层MLP隐层，用来直接对多阶特征非线性组合建模而已，其它方面基本相同。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-6f3901d8235f7f4e5abfab77787cc0dd_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>那么为什么说FM的这种特征embedding模式，在大规模稀疏特征应用环境下比较好用？为什么说它的泛化能力强呢？参考上图说明。即使在训练数据里两个特征并未同时在训练实例里见到过，意味着 $x_i <span class="math inline">\(和\)</span>x_j$ 一起出现的次数为0，如果换做SVM的模式，是无法学会这个特征组合的权重的。但是因为FM是学习单个特征的embedding，并不依赖某个特定的特征组合是否出现过，所以只要特征 <span class="math inline">\(x_i\)</span>和其它任意特征组合出现过，那么就可以学习自己对应的embedding向量。于是，尽管 $x_i $ 和 <span class="math inline">\(x_j\)</span>这个特征组合没有看到过，但是在预测的时候，如果看到这个新的特征组合，因为 $x_i <span class="math inline">\(和\)</span> x_j$ 都能学会自己对应的embedding，所以可以通过内积算出这个新特征组合的权重。这是为何说FM模型泛化能力强的根本原因。</p><p>其实本质上，这也是目前很多花样的embedding的最核心特点，就是从0/1这种二值硬核匹配，切换为向量软匹配，使得原先匹配不上的，现在能在一定程度上算密切程度了，具备很好的泛化性能。</p><h3 id="从mf到fm模型">从MF到FM模型</h3><p>FM我们大致应该知道是怎么个意思了，这里又突然冒出个MF，长得跟FM貌似还有点像，那么MF又是什么呢？它跟FM又有什么关系？</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-31443ffa8253db401b22d8d5c1692f8f_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>MF（Matrix Factorization，矩阵分解）模型是个在推荐系统领域里资格很深的老前辈协同过滤模型了。核心思想是通过两个低维小矩阵（一个代表用户embedding矩阵，一个代表物品embedding矩阵）的乘积计算，来模拟真实用户点击或评分产生的大的协同信息稀疏矩阵，本质上是编码了用户和物品协同信息的降维模型。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-e22ed4e234d8e7f3e68ea81479d830ee_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>当训练完成，每个用户和物品得到对应的低维embedding表达后，如果要预测某个 <span class="math inline">\(User_i\)</span>对<span class="math inline">\(Item_j\)</span> 的评分的时候，只要它们做个内积计算 <span class="math inline">\(User_i \cdot Item_j\)</span>,这个得分就是预测得分。看到这里，让你想起了什么吗？</p><p>身为推荐算法工程师，我假设你对它还是比较熟悉的，更多的就不展开说了，相关资料很多，我们重点说MF和FM的关系问题。</p><p>MF和FM不仅在名字简称上看着有点像，其实他们本质思想上也有很多相同点。那么，MF和FM究竟是怎样的关系呢？</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-05fa3df9ff4c33fa323053265564e86d_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>本质上，MF模型是FM模型的特例，MF可以被认为是只有User ID 和Item ID这两个特征Fields的FM模型，MF将这两类特征通过矩阵分解，来达到将这两类特征embedding化表达的目的。而FM则可以看作是MF模型的进一步拓展，除了User ID和Item ID这两类特征外，很多其它类型的特征，都可以进一步融入FM模型里，它将所有这些特征转化为embedding低维向量表达，并计算任意两个特征embedding的内积，就是特征组合的权重，如果FM只使用User ID 和Item ID，你套到FM公式里，看看它的预测过程和MF的预测过程一样吗？</p><p>从谁更早使用特征embedding表达这个角度来看的话，很明显，和FM比起来，MF才是真正的前辈，无非是特征类型比较少而已。而FM继承了MF的特征embedding化表达这个优点，同时引入了更多Side information作为特征，将更多特征及Side information embedding化融入FM模型中。所以很明显FM模型更灵活，能适应更多场合的应用范围。</p><p>鉴于MF和FM以上错综复杂剪不断理还乱的关系，我推论出下面的观点（个人意见）：</p><p>其一：在你有使用MF做协同过滤的想法的时候，暂时压抑一下这种冲动，可以优先考虑引入FM来做的，而非传统的MF，因为可以在实现等价功能的基础上，很方便地融入其它任意你想加入的特征，把手头的事情做得更丰富多彩。</p><p>其二：从实际大规模数据场景下的应用来讲，在排序阶段，绝大多数只使用ID信息的模型是不实用的，没有引入Side Information，也就是除了User ID／Item ID外的很多其它可用特征的模型，是不具备实战价值的。原因很简单，大多数真实应用场景中，User/Item有很多信息可用，而协同数据只是其中的一种，引入更多特征明显对于更精准地进行个性化推荐是非常有帮助的。而如果模型不支持更多特征的便捷引入，明显受限严重，很难真正实用，这也是为何矩阵分解类的方法很少看到在Ranking阶段使用，通常是作为一路召回形式存在的原因。</p><h2 id="fm模型">FM模型</h2><h3 id="简单谈谈算法的效率问题">简单谈谈算法的效率问题</h3><p>从FM的原始数学公式看，因为在进行二阶（2-order）特征组合的时候，假设有n个不同的特征，那么二阶特征组合意味着任意两个特征都要进行交叉组合，所以可以直接推论得出：FM的时间复杂度是n的平方。但是如果故事仅仅讲到这里，FM模型是不太可能如此广泛地被工业界使用的。因为现实生活应用中的n往往是个非常巨大的特征数，如果FM是n平方的时间复杂度，那估计基本就没人带它玩了。</p><p>对于一个实用化模型来说，效果是否足够好只是一个方面，计算效率是否够高也很重要，这两点是一个能被广泛使用算法的一枚硬币的两面，缺其中任何一个可能都不能算是优秀的算法。如果在两者之间硬要分出谁更重要的话，怎么选？</p><p>这里插入个题外话，是关于如何做选择的。这个话题如果你深入思考的话，会发现很可能是个深奥的哲学问题。在说怎么选之前，我先复述两则关于选择的笑话，有两个版本，男版和女版的。</p><p>男版是这样的：“一个兄弟跟我说他最近很困惑，有三个姑娘在追他，一直犹豫不决，到底应该选哪个当女朋友呢？一个温柔贤惠，一个聪明伶俐，另外一个肤白貌美。太难选…..三天后当我再次遇到他的时候，他说他做出了选择，选了那个胸最大的！”</p><p>女版是这样的：“一个姐妹跟我说她很困惑，最近有三个优秀的男人在追她，一直犹豫不决，到底应该嫁给谁呢？一个努力上进，一个高大帅气，另外一个脾气好顾家。实在太难选…..三天后当我再次遇到她的时候，她说她做出了选择，选了那个最有钱的！”</p><p>参考这个模版，算法选择版应该是这样的：“一个算法工程师一直犹豫不决该选哪个模型去上线，他有三个优秀算法可选，一个算法理论优雅；一个算法效果好；另外一个算法很时髦，实在太难做决定…..三天后当我再遇见他的时候，他说他们算法总监让他上了那个跑得最快的！”</p><p>怎么样？生活或者工作中的选择确实是个很玄妙的哲学问题吧？这个算法版的关于选择的笑话，应该已经回答了上面那个还没给答案的问题了吧？在数据量特别大的情况下，如果在效果好和速度快之间做选择，很多时候跑得快的简单模型会胜出，这是为何LR模型在CTR预估领域一直被广泛使用的原因。</p><p>而FFM模型则是反例，我们在几个数据集合上测试过，FFM模型作为排序模型，效果确实是要优于FM模型的，但是FFM模型对参数存储量要求太多，以及无法能做到FM的运行效率，如果中小数据规模做排序没什么问题，但是数据量一旦大起来，对资源和效率的要求会急剧升高，这是严重阻碍FFM模型大规模数据场景实用化的重要因素。</p><p>再顺手谈谈DNN排序模型，现在貌似看着有很多版本的DNN排序模型，但是考虑到上面讲的运算效率问题，你会发现太多所谓效果好的模型，其实不具备实用价值，算起来太复杂了，效果好得又很有限，超大规模训练或者在线 Serving速度根本跟不上。除非，你们公司有具备相当强悍实力的工程团队，能够进行超大数据规模下的大规模性能优化，那当我上面这句话没说。</p><p>我对排序模型，如果你打算推上线真用起来的话，建议是，沿着这个序列尝试：FM--&gt;DeepFM。你看着路径有点短是吗？确实比较短。如果DeepFM做不出效果，别再试着去尝试更复杂的模型了，还是多从其它方面考虑考虑优化方案为好。有些复杂些的模型，也许效果确实好一些，在个别大公司也许真做上线了，但是很可能效果好不是算法的功劳，是工程能力强等多个因素共同导致的，人家能做，你未必做的了。至于被广泛尝试的Wide &amp;Deep，我个人对它有偏见，所以直接被我跳过了。当然，如果你原始线上版本是LR，是可以直接先尝试Wide&amp;Deep的，但是即使如此，要我做升级方案，我给的建议会是这个序列：LR—&gt;FM--&gt;DeepFM—&gt;干点其他的。</p><h3 id="如何优化fm的计算效率">如何优化FM的计算效率</h3><p>再说回来，FM如今被广泛采用并成功替代LR模型的一个关键所在是：它可以通过数学公式改写，把表面貌似是 <span class="math inline">\(O(kn^2)\)</span> 的复杂度降低到 <span class="math inline">\(O(kn)\)</span> ，其中n是特征数量，k是特征的embedding size，这样就将FM模型改成了和LR类似和特征数量n成线性规模的时间复杂度了，这点非常好。</p><p>那么，如何改写原始的FM数学公式，让其复杂度降下来呢？因为原始论文在推导的时候没有给出详细说明，我相信不少人看完估计有点懵，所以这里简单解释下推导过程，数学公式帕金森病患者可以直接跳过下面内容往后看，这并不影响你理解本文的主旨。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-092434df66566c831d545685f895237e_1440w.jpg" alt="v2-092434df66566c831d545685f895237e_1440w"><figcaption aria-hidden="true">v2-092434df66566c831d545685f895237e_1440w</figcaption></figure><p>上图展示了整个推导过程，我相信如果数学基础不太扎实的同学看着会有点头疼，转换包括四个步骤，下面分步骤解释下。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-747fec2b2c6623d2f8d8dd3cffa7b9ac_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第一个改写步骤及为何这么改写参考上图，比较直观，不解释了；</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-a7216c469922212e766a53be314b4793_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第二步转换更简单，更不用解释了。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-9ce1dd7c7bdcd53b0ca3425de4915756_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第三步转换不是太直观，可能需要简单推导一下，很多人可能会卡在这一步，所以这里解释解释。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-28e572eb15a4e0c485d9de195bf43b4a_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>其实吧，如果把k维特征向量内积求和公式抽到最外边后，公式就转成了上图这个公式了（不考虑最外边k维求和过程的情况下）。它有两层循环，内循环其实就是指定某个特征的第f位（这个f是由最外层那个k指定的）后，和其它任意特征对应向量的第f位值相乘求和；而外循环则是遍历每个的第f位做循环求和。这样就完成了指定某个特征位f后的特征组合计算过程。最外层的k维循环则依此轮循第f位，于是就算完了步骤三的特征组合。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-a37142ec47a45533d1a850adf5cd174f_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>对上一页公式图片展示过程用公式方式，再一次改写（参考上图），其实就是两次提取公共因子而已，这下应该明白了吧？要是还不明白，那您的诊断结果是数学公式帕金森晚期，跟我一个毛病，咱俩病友同病相怜，我也没辙了。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-ba68c8900c8b3b9dc5799367bfacbc37_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第四步公式变换，意思参考上图，这步也很直白，不解释。</p><p>于是，通过上述四步的公式改写，可以看出在实现FM模型时，时间复杂度就降低到了 <span class="math inline">\(O(kn)\)</span> 了，而虽说看上去n还有点大，但是其实真实的推荐数据的特征值是极为稀疏的，就是说大量xi其实取值是0，意味着真正需要计算的特征数n是远远小于总特征数目n的，无疑这会进一步极大加快FM的运算效率。</p><p>这里需要强调下改写之后的FM公式的第一个平方项，怎么理解这个平方项的含义呢？这里其实蕴含了后面要讲的使用FM模型统一多路召回的基本思想，所以这里特殊提示一下。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-ba68c8900c8b3b9dc5799367bfacbc37_1440w-20200913130620788.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>参考上图，你体会下这个计算过程。它其实等价于什么？</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-eb7aa1a8a4bdf795f198253446ad365a_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>这个平方项，它等价于将FM的所有特征项的embedding向量累加，之后求内积。我再问下之前问过的问题：“我们怎样利用FM模型做统一的召回？”这个平方项的含义对你有启发吗？你可以仔细想想它们之间的关联。</p><hr><h2 id="如何利用fm模型做统一的召回模型">如何利用FM模型做统一的召回模型</h2><p>上文书提到过，目前工业界推荐系统在召回阶段，大多数采用了多路召回策略，比如典型的召回路有：基于用户兴趣标签的召回；基于协同过滤的召回；基于热点的召回；基于地域的召回；基于Topic的召回；基于命名实体的召回等等，除此外还有很多其它类型的召回路。</p><p>现在我们来探讨下第一个问题：在召回阶段，能否用一个统一的模型把多路召回？就是说改造成利用单个模型，单路召回的模式？具体到这篇文章，就是说能否利用FM模型来把多路召回统一起来？</p><p>在回答上述问题之前，我估计你会提出疑问：目前大家用多路召回用的好好的，为啥要多此一举，用一个模型把多路召回统一起来呢？这个问题非常好，我们确实应该先看这么做的必要性。</p><h3 id="统一召回和多路召回优缺点比较">统一召回和多路召回优缺点比较</h3><p>我们先来说明下统一召回和多路召回各自的优缺点，我觉得使用统一召回模式，相对多路召回有如下优点：</p><p>首先，采用多路召回，每一路召回因为采取的策略或者模型不同，所以各自的召回模型得分不可比较，比如利用协同过滤召回找到的候选Item得分，与基于兴趣标签这一路召回找到的候选Item得分，完全是不可比较的。这也是为何要用第二阶段Ranking来将分数统一的原因。而如果采取统一的召回模型，比如FM模型，那么不论候选项Item来自于哪里，它们在召回阶段的得分是完全可比的。</p><p>其次，貌似在目前“召回+Ranking”两阶段推荐模型下，多路召回分数不可比这个问题不是特别大，因为我们可以依靠Ranking阶段来让它们可比即可。但是其实多路召回分数不可比会直接引发一个问题：对于每一路召回，我们应该返回多少个Item是合适的呢？如果在多路召回模式下，这个问题就很难解决。既然分数不可比，那么每一路召回多少候选项K就成为了超参，需要不断调整这个参数上线做AB测试，才能找到合适的数值。而如果召回路数特别多，于是每一路召回带有一个超参K，就是这一路召回多少条候选项，这样的超参组合空间是非常大的。所以到底哪一组超参是最优的，就很难定。其实现实情况中，很多时候这个超参都是拍脑袋上线测试，找到最优的超参组合概率是很低的。</p><p>而如果假设我们统一用FM模型来做召回，其实就不存在上面这个问题。这样，我们可以在召回阶段做到更好的个性化，比如有的用户喜欢看热门的内容，那么热门内容在召回阶段返回的比例就高，而其它内容返回比例就低。所以，可以认为各路召回的这组超参数就完全依靠FM模型调整成个性化的了，很明显这是使用单路单模型做召回的一个特别明显的好处。</p><p>再次，对于工业界大型的推荐系统来说，有极大的可能做召回的技术人员和做Ranking的技术人员是两拨人。这里隐含着一个潜在可能会发生的问题，比如召回阶段新增了一路召回，但是做Ranking的哥们不知道这个事情，在Ranking的时候没有把能体现新增召回路特性的特征加到Ranking阶段的特征中。这样体现出来的效果是：新增召回路看上去没什么用，因为即使你找回来了，而且用户真的可能点击，但是在排序阶段死活排不上去。也就是说，在召回和排序之间可能存在信息鸿沟的问题，因为目前召回和排序两者的表达模式差异很大，排序阶段以特征为表达方式，召回则以“路／策略／具体模型”为表达方式，两者之间差异很大，是比较容易产生上述现象的。</p><p>但是如果我们采用FM模型来做召回的话，新增一路召回就转化为新增特征的问题，而这一点和Ranking阶段在表现形式上是相同的，对于召回和排序两个阶段来说，两者都转化成了新增特征问题，所以两个阶段的改进语言体系统一，就不太容易出现上述现象。</p><p>上面三点，是我能想到的采用统一召回模型，相对多路召回的几个好处。但是是不是多路召回一定不如统一召回呢？其实也不是，很明显多路召回这种策略，上线一个新召回方式比较灵活，对线上的召回系统影响很小，因为不同路召回之间没有耦合关系。但是如果采用统一召回，当想新增一种召回方式的时候，表现为新增一种或者几种特征，可能需要完全重新训练一个新的FM模型，整个召回系统重新部署上线，灵活性比多路召回要差。</p><p>上面讲的是必要性，讲完了必要性，我们下面先探讨如何用FM模型做召回，然后再讨论如何把多路召回改造成单路召回，这其实是两个不同的问题。</p><h3 id="如何用fm模型做召回模型">如何用FM模型做召回模型</h3><p>如果要做一个实用化的统一召回模型，要考虑的因素有很多，比如Context上下文特征怎么处理，实时反馈特征怎么加入等。为了能够更清楚地说明，我们先从极简模型说起，然后逐步加入必须应该考虑的元素，最后形成一个实用化的统一召回模型。</p><p>不论是简化版本FM召回模型，还是复杂版本，首先都需要做如下两件事情：</p><p>第一，离线训练。这个过程跟在排序阶段采用FM模型的离线训练过程是一样的，比如可以使用线上收集到的用户点击数据来作为训练数据，线下训练一个完整的FM模型。在召回阶段，我们想要的其实是：每个特征和这个特征对应的训练好的embedding向量。这个可以存好待用。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-30e4ad00c3824b9ee9417db3eb8b0c66_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第二，如果将推荐系统做个很高层级的抽象的话，可以表达成学习如下形式的映射函数： <span class="math display">\[y = F(User,Item,Context)\]</span> 意思是，我们利用用户（User）相关的特征，物品(Item)相关的特征，以及上下文特征（Context,比如何时何地用的什么牌子手机登陆等等）学习一个映射函数F。学好这个函数后，当以后新碰到一个Item，我们把用户特征，物品特征以及用户碰到这个物品时的上下文特征输入F函数，F函数会告诉我们用户是否对这个物品感兴趣。如果他感兴趣，就可以把这个Item作为推荐结果推送给用户。</p><p>说了这么多，第二个我们需要做的事情是：把特征划分为三个子集合，用户相关特征集合，物品相关特征集合以及上下文相关的特征集合。而用户历史行为类特征，比如用户过去点击物品的特征，可以当作描述用户兴趣的特征，放入用户相关特征集合内。至于为何要这么划分，后面会讲。</p><p>做完上述两项基础工作，我们可以试着用FM模型来做召回了。</p><h3 id="极简版fm召回模型">极简版FM召回模型</h3><p>我们先来构建一个极简的FM召回模型，首先，我们先不考虑上下文特征，晚点再说。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-779770c210f6af7144bb81f88ac8957d_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第一步，对于某个用户，我们可以把属于这个用户子集合的特征，查询离线训练好的FM模型对应的特征embedding向量，然后将n个用户子集合的特征embedding向量累加，形成用户兴趣向量U，这个向量维度和每个特征的维度是相同的。</p><p>类似的，我们也可以把每个物品，其对应的物品子集合的特征，查询离线训练好的FM模型对应的特征embedding向量，然后将m个物品子集合的特征embedding向量累加，形成物品向量I，这个向量维度和每个特征的维度也是是相同的。</p><p>对于极简版FM召回模型来说，用户兴趣向量U可以离线算好，然后更新线上的对应内容；物品兴趣向量I可以类似离线计算或者近在线计算，问题都不大。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-f7faa46fc88d36677a6311f64ce98beb_1440w-9973707.jpg" alt="v2-f7faa46fc88d36677a6311f64ce98beb_1440w"><figcaption aria-hidden="true">v2-f7faa46fc88d36677a6311f64ce98beb_1440w</figcaption></figure><p>第二步，对于每个用户以及每个物品，我们可以利用步骤一中的方法，将每个用户的兴趣向量离线算好，存入在线数据库中比如Redis（用户ID及其对应的embedding），把物品的向量逐一离线算好，存入Faiss(Facebook开源的embedding高效匹配库)数据库中。</p><p>当用户登陆或者刷新页面时，可以根据用户ID取出其对应的兴趣向量embedding，然后和Faiss中存储的物料embedding做内积计算，按照得分由高到低返回得分Top K的物料作为召回结果。提交给第二阶段的排序模型进行进一步的排序。这里Faiss的查询速度至关重要，至于这点，后面我们会单独说明。</p><p>这样就完成了一个极简版本FM召回模型。但是这个版本的FM召回模型存在两个问题。</p><p>问题一：首先我们需要问自己，这种累加用户embedding特征向量以及累加物品embedding特征向量，之后做向量内积。这种算法符合FM模型的原则吗？和常规的FM模型是否等价？</p><p>我们来分析一下。这种做法其实是在做用户特征集合U和物品特征集合I之间两两特征组合，是符合FM的特征组合原则的，考虑下列公式是否等价就可以明白了：</p><p><span class="math inline">\(\sum_iU_i\cdot\sum_jI_j\)</span></p><p><span class="math inline">\(\sum_i {\sum_j{U_i \cdot I_j}}\)</span></p><p>其实两者是等价的，建议您可以推导一下（这其实不就是上面在介绍FM公式改写的第三步转换吗？当然，跟完全版本的FM比，我们没有考虑U和I特征集合内部任意两个特征的组合，等会会说这个问题）。</p><p>也可以这么思考问题：在上文我们说过，FM为了提升计算效率，对公式进行了改写，改写后的高效计算公式的第一个平方项其实等价于：把所有特征embedding向量逐位累加成一个求和向量V，然后自己和自己做个内积操作&lt;V,V&gt;。这样等价于根据FM的原则计算了任意两个特征的二阶特征组合了。而上面描述的方法，和标准的FM的做法其实是一样的，区别无非是将特征集合划分为两个子集合U和I，分别代表用户相关特征及物品相关特征。而上述做法其实等价于在用户特征和物品特征之间做两两特征组合，只是少了U内部之间特征，及I内部特征之间的特征组合而已。一般而言，其实我们不需要做U内部特征之间以及I内部特征之间的特征组合，对最终效果影响很小。于是，沿着这个思考路径，我们也可以推导出上述做法基本和FM标准计算过程是等价的。</p><p>第二个问题是：这个版本FM是个简化版本模型，因为它没考虑场景上下文特征，那么如果再将上下文特征引入，此时应该怎么做呢？</p><h3 id="加入场景上下文特征">加入场景上下文特征</h3><p>上面叙述了如何根据FM模型做一个极简版本的召回模型，之所以说极简，因为我们上面说过，抽象的推荐系统除了用户特征及物品特征外，还有一类重要特征，就是用户发生行为的场景上下文特征（比如什么时间在什么地方用的什么设备在刷新），而上面版本的召回模型并没有考虑这一块。</p><p>之所以把上下文特征单独拎出来，是因为它有自己的特点，有些上下文特征是近乎实时变化的，比如刷新微博的时间，再比如对于美团嘀嘀这种对地理位置特别敏感的应用，用户所处的地点可能随时也在变化，而这种变化在召回阶段就需要体现出来。所以，上下文特征是不太可能像用户特征离线算好存起来直接使用的，而是用户在每一次刷新可能都需要重新捕获当前的特征值。动态性强是它的特点。</p><p>而考虑进来上下文特征，如果我们希望构造和标准的FM等价的召回模型，就需要多考虑两个问题：</p><p>问题一：既然部分上下文特征可能是实时变化的，无法离线算好，那么怎么融入上文所述的召回计算框架里？</p><p>问题二：我们需要考虑上下文特征C和用户特征U之间的特征组合，也需要考虑C和物品特征I之间的特征组合。上下文特征有时是非常强的特征。那么，如何做能够将这两对特征组合考虑进来呢？</p><p>我们可以这么做：</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-bf02449ca535ec43d947e8143af52400_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>首先，由于上下文特征的动态性，所以给定用户UID后，可以在线查询某个上下文特征对应的embedding向量，然后所有上下文向量求和得到综合的上下文向量C。这个过程其实和U及I的累加过程是一样的，区别无非是上下文特征需要在线实时计算。而一般而言，场景上下文特征数都不多，所以在线计算，速度方面应可接受。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-5b83293c5109b1a840b85de766997cd4_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>然后，将在线算好的上下文向量C和这个用户的事先算好存起来的用户兴趣向量U进行内积计算<span class="math inline">\(Score=U\cdot C\)</span>。这个数值代表用户特征和上下文特征的二阶特征组合得分，算好备用。至于为何这个得分能够代表FM中的两者（U和C）的特征组合，其实道理和上面讲的U和I做特征组合道理是一样的。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-6cb269fc88976c0c918e764ac553f29e_1440w.jpg" alt="v2-6cb269fc88976c0c918e764ac553f29e_1440w"><figcaption aria-hidden="true">v2-6cb269fc88976c0c918e764ac553f29e_1440w</figcaption></figure><p>再然后，将U和C向量累加求和，利用（U+C）去Faiss通过内积方式取出Top K物品，这个过程和极简版是一样的，无非查询向量由U换成了（U+C）。通过这种方式取出的物品同时考虑到了用户和物品的特征组合&lt;U,I&gt;，以及上下文和物品的特征组合&lt;C,I&gt;。道理和之前讲的内容是类似的。</p><p>假设返回的Top K物品都带有内积的得分Score1，再考虑上一步&lt;U,C&gt;的得分Score，将两者相加对物品重排序（&lt;U,C&gt;因为跟物品无关，所以其实不影响物品排序，但是会影响最终得分，FM最外边的Sigmoid输出可能会因为加入这个得分而发生变化），就得到了最终结果，而这个最终结果考虑了U/I/C两两之间的特征组合。</p><p>于是我们通过这种手段，构造出了一个完整的FM召回模型。这个召回模型通过构造user embedding，Context embedding和Item embedding，以及充分利用类似Faiss这种高效embedding计算框架，就构造了高效执行的和FM计算等价的召回系统。</p><h3 id="如何将多路召回融入fm召回模型">如何将多路召回融入FM召回模型</h3><p>上文所述是如何利用FM模型来做召回，下面我们讨论下如何将多路召回统一到FM召回模型里来。</p><p>我们以目前不同类型推荐系统中共性的一些召回策略来说明这个问题，以信息流推荐为例子，传统的多路召回阶段通常包含以下策略：协同过滤，兴趣分类，兴趣标签，兴趣Topic，兴趣实体，热门物品，相同地域等。这些不同角度的召回策略都是较为常见的。</p><figure><img src="/blog_cn/2020/09/12/recommend_system/FM%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/v2-00eb67435deac9df8ad0536804b10d65_1440w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>我们再将上述不同的召回路分为两大类，可以把协同过滤作为一类，其它的作为一类，协同过滤相对复杂，我们先说下其它类别。</p><p>对于比如兴趣分类，兴趣标签，热门，地域等召回策略，要把这些召回渠道统一到FM模型相对直观，只需要在训练FM模型的时候，针对每一路的特性，在用户特征端和物品特征端新增对应特征即可。比如对于地域策略，我们可以把物品所属地域（比如微博所提到的地域）和用户的感兴趣地域都作为特征加入FM模型即可。兴趣标签，Topic，兴趣实体等都是类似的。所以大多数情况下，在多路召回模式下你加入新的一路召回，在FM统一召回策略下，对应地转化成了新增特征的方式。</p><p>然后我们再说协同过滤这路召回。其实本质上也是将一路召回转化为新加特征的模式。我们上文在介绍FM模型和MF模型关系的时候提到过：本质上MF模型这种典型的协同过滤策略，是FM模型的一个特例，可以看作在FM模型里只有User ID和Item ID这两类（Fields）特征的情形。意思是说，如果我们将user ID和Item ID作为特征放入FM模型中进行训练，那么FM模型本身就是包含了协同过滤的思想的。当然，对于超大规模的网站，用户以亿计，物品可能也在千万级别，如果直接把ID引入特征可能会面临一些工程效率问题以及数据稀疏的问题。对于这个问题，我们可以采取类似在排序阶段引入ID时的ID 哈希等降维技巧来进行解决。</p><p>所以综合来看，在多路召回下的每一路召回策略，绝大多数情况下，可以在FM召回模型模式中转化为新增特征的方式。</p><p>在具体实施的时候，可以沿着这个路径逐步替换线上的多路召回：先用FM模型替换一路召回，线上替换掉；再新加入某路特征，这样上线，就替换掉了两路召回；如此往复逐渐把每一路召回统一到一个模型里。这是比较稳的一种替换方案。当然如果你是个猛人，直接用完整的FM召回模型一步替换掉线上的各路召回，也，未尝不可。只要小流量AB测试做好也没啥。</p><h3 id="fm模型能否将召回和排序阶段一体化">FM模型能否将召回和排序阶段一体化</h3><p>前文有述，之所以目前常见的工业推荐系统会分为召回排序两个阶段，是因为这两个阶段各司其职，职责分明。召回主要考虑泛化性并把候选物品集合数量降下来；排序则主要负责根据用户特征／物品特征／上下文特征对物品进行精准排名。</p><p>那么，我们现在可以来审视下本文开头提出的第二个问题了：FM模型能否将常见的两阶段模型一体化？即是否能将实用化的推荐系统通过FM召回模型简化为单阶段模型？意思是推荐系统是否能够只保留FM召回这个模块，扔掉后续的排序阶段，FM召回按照得分排序直接作为推荐结果返回。我们可以这么做吗？</p><p>这取决于FM召回模型是否能够一并把原先两阶段模型的两个职责都能承担下来。这句话的意思是说，FM召回模型如果直接输出推荐结果，那么它的速度是否足够快？另外，它的精准程度是否可以跟两阶段模型相媲美？不会因为少了第二阶段的专门排序环节，而导致推荐效果变差？如果上面两个问题的答案都是肯定的，那么很明显FM模型就能够将现有的两阶段推荐过程一体化。</p><p>我们分头来分析这个问题的答案：准确性和速度。先从推荐精准度来说明，因为如果精准度没有办法维持，那么速度再快也没什么意义。</p><p>所以现在的第一个子问题是：FM召回模型推荐结果的质量，是否能够和召回+排序两阶段模式接近？</p><p>我们假设一个是FM统一召回模型直接输出排序结果；而对比模型是目前常见的多路召回+FM模型排序的配置。从上文分析可以看出，尽管FM召回模型为了速度够快，做了一些模型的变形，但是如果对比的两阶段模型中的排序阶段也采取FM模型的话，我们很容易推理得到如下结论：如果FM召回模型采用的特征和两阶段模型的FM排序模型采用相同的特征，那么两者的推荐效果是等价的。这意味着：只要目前的多路召回都能通过转化为特征的方式加入FM召回模型，而且FM排序阶段采用的特征在FM召回模型都采用。那么两者推荐效果是类似的。这意味着，从理论上说，是可以把两阶段模型简化为一阶段模型的。</p><p>既然推理的结论是推荐效果可以保证，那么我们再来看第二个问题：只用FM召回模型做推荐，速度是否足够快？</p><p>我们假设召回阶段FM模型对User embedding和Item embedding的匹配过程采用Facebook的Faiss系统，其速度快慢与两个因素有关系：</p><ol type="1"><li>物品库中存储的Item数量多少，Item数量越多越慢；</li><li>embedding大小，embedding size越大，速度越慢；</li></ol><p>微博机器学习团队18年将Faiss改造成了分布式版本，并在业务易用性方面增加了些新功能，之前我们测试的查询效率是：假设物品库中存储100万条微博embedding数据，而embedding size=300的时候，TPS在600左右，平均每次查询小于13毫秒。而当库中微博数量增长到200万条，embedding size=300的时候，TPS在400左右，平均查询时间小于20毫秒。这意味着如果是百万量级的物品库，embedding size在百级别，一般而言，通过Faiss做embedding召回速度是足够实用化的。如果物品库大至千万量级，理论上可以通过增加Faiss的并行性，以及减少embedding size来获得可以接受的召回速度。</p><p>当然，上面测试的是纯粹的Faiss查询速度，而事实上，我们需要在合并用户特征embedding的时候，查询用户特征对应的embedding数据，而这块问题也不太大，因为绝大多数用户特征是静态的，可以线下合并进入用户embedding，Context特征和实时特征需要线上在线查询对应的embedding，而这些特征数量占比不算太大，所以速度应该不会被拖得太慢。</p><p>综上所述，FM召回模型从理论分析角度，其无论在实用速度方面，还是推荐效果方面，应该能够承载目前“多路召回+FM排序”两阶段推荐模式的速度及效果两方面功能，所以推论它是可以将推荐系统改造成单模型单阶段模式的。</p><p>当然，上面都是分析结果，并非实测，所以不能确定实际应用起来也能达到上述理论分析的效果。</p><h2 id="总结"><strong>总结</strong></h2><p>最后我简单总结一下，目前看貌似利用FM模型可以做下面两个事情：</p><p>首先，我们可以利用FM模型将传统的多路召回策略，改为单模型单召回的策略，传统的新增一路召回，可以转换为给FM召回模型新增特征的方式；</p><p>其次，理论上，我们貌似可以用一个FM召回模型，来做掉传统的“多路召回+排序”的两项工作，可行的原因上文有分析。</p>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
          <category> recommend system </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
            <tag> recommend system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能发展趋势</title>
      <link href="/blog_cn/2020/09/12/recommend_system/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/"/>
      <url>/blog_cn/2020/09/12/recommend_system/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="https://cdn.jsdelivr.net/npm/meting/dist/Meting.min.js"></script><p>人工智能最近几年发展得如火如荼，学术界、工业界、投资界各方一起发力，硬件、算法与数据共同发展，不仅仅是大型互联网公司，包括大量创业公司以及传统行业的公司都开始涉足人工智能行业。尽管最近一年在资本市场趋冷的大环境下，AI 热度有所下降，但从长远来看，人工智能在各行各业获得越来越广泛的应用一定是社会发展最大的趋势之一。</p><a id="more"></a><p>从AI基础设施来说，人工智能专用芯片的研发方兴未艾，不仅包括英伟达GPU、谷歌TPU，国内的阿里、百度、华为等巨头公司，以及大量创业公司，都在AI芯片方面加快布局，随着AI应用进一步渗透到IOT等方向，相信对专用芯片的需求会越来越广泛。而作为各种AI应用开发工具的AI框架，也在之前的百花齐放式发展中逐步收敛，目前形成了PyTorch引领学术界，TensorFlow主导工业界的双雄局面；而随着中台概念的日益兴起，国内大型互联网公司也正在以AI中台的面貌推出各自的高层开发框架，大量AI创业公司则逐步转向金融、安防等垂直行业深耕细作的模式。</p><p>从AI技术进展的角度来看，有几个明显的技术趋势已日益凸显。首先，随着以智能手机为代表的移动终端计算存储能力快速加强，端AI与边缘计算技术正在快速发展与普及，如何在应用效果尽可能高的前提下，将模型做小做精致做快，是这个发展方向的关键点。其次，传统机器学习严重依赖训练数据的规模与质量，这制约了领域技术的快速发展，而最近的明显趋势是由最常见的监督学习向半监督、自监督甚至无监督机器学习转向，如何用尽量少的有标训练数据让机器自主学会更多的知识，是大有前景的发展方向；第三，AutoML正在快速地渗透到各个AI应用领域，从最早的图像领域，目前已经拓展到NLP、推荐搜索、GAN等多个领域，随着AutoML技术的逐渐成熟，搜索网络结构成本越来越低，相信会有更多的领域模型会由机器来设计，而不是目前的算法专家主导的局面，这个技术趋势基本是确定无疑的。再者，随着5G等传输技术的快速发展，视频、图片类应用快速成为最主流的APP消费场景，而机器学习技术如何更好地融合文本、图片、视频、用户行为等各种不同模态的信息，来达到更好的应用效果，相信也会越来越重要。另外，如何让机器能够生成高质量的图片、视频、文本等生成领域，最近两年也出现了大量有效新技术比如图像领域的GAN以及文本领域的GPT2等模型，而这种具备创造性的生成领域，虽然之前由于受到技术发展水平限制，大家投入的精力不多，随着相关技术日益成熟，这块相信也会越来越重要。</p><p>从AI应用领域发展趋势来讲，最主要的几个AI方向比如自然语言处理、图像视频处理及搜索推荐方向，最近一年来技术发展各自精彩纷呈，又呈现出不同的发展格局。</p><p>自然语言领域在最近两年发生了天翻地覆的技术变革，进入了技术井喷的快速发展期，而这一巨变的引发者是由Bert为代表的预训练模型及新型特征抽取器Transformer的快速发展与普及带来的。从Bert的应用来看，已经在包含对话系统、机器阅读理解、搜索、文本分类….等几乎大多数NLP应用领域快速应用，并在部分应用领域取得了突破性的效果提升；作为刚提出一年多的新型研究范式，我们目前对Transformer和Bert为何有效的理解还比较浅显，同时Bert模型还有很多值得深入改进的方向，比如生成模型、训练方法优化、长文档处理、多模态融合…..等，都需要进一步更深入的研究。最近一年也陆续出现了大量效果突出的改进模型，比如XLNet、RoBERTa、ALBert、Google T5等一系列改进。相信随着大家对Bert的理解逐渐深入，对Bert模型的快速改进以及更多领域更好的应用效果会成为NLP领域的常态，我们在不远的未来会看到NLP领域更多新模型的出现，以及这些新技术推动实际应用场景的快速进步。</p><p>图像处理领域是AI的另一应用主战场，但是，除了近年来深度学习、ResNet两大图像处理领域的巨大技术革新外，最近两年来，CV领域并未有特别巨大的技术革新与进步，目前进入技术平稳发展期。归功于基础技术的快速进步，很多CV应用已相对成熟，所以近年来我们体会更多的是各种前沿技术在各个行业的应用落地与实践。</p><p>对于推荐与搜索等具备较长工业化发展历史的AI应用领域，深度学习在最近两年已经在各种互联网公司比较广泛地获得了尝试和应用。尽管并未像NLP与图像领域那样，深度学习相对传统模型获得突飞猛进的技术突破，而且对于比如推荐领域DNN模型的效果到底如何在学术上还存在争议，但是相信这些领域如果能够正确借鉴其它AI领域的技术进展，会在未来两年内出现令人惊喜的效果突出的技术进化。</p><p>综合而言，AI技术发展整体进入快车道，不同领域又各有特色、发展阶段以及各自的精彩。可以坚信的一点是：相信AI会日益渗透到我们生活的方方面面，帮助我们生活得更轻松更美好！</p>]]></content>
      
      
      <categories>
          
          <category> notes </category>
          
          <category> artificial intelligence </category>
          
      </categories>
      
      
        <tags>
            
            <tag> notes </tag>
            
            <tag> artificial intelligence </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
